{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-dreambooth-beta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kohya Dreambooth - VRAM 12GB"
      ],
      "metadata": {
        "id": "slgjeYgd6pWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted to Google Colab based on [Kohya Guide](https://note.com/kohya_ss/n/nbf7ce8d80f29#c9d7ee61-5779-4436-b4e6-9053741c46bb)<br>\n",
        "Adapted again from [bmaltais's Kohya Archive](https://github.com/bmaltais/kohya_ss)<br>\n",
        "Adapted to Google Colab by [Linaqruf](https://github.com/Linaqruf)<br>\n",
        "Inference cell adapted from [ShivamShrirao's Dreambooth](https://colab.research.google.com/github/ShivamShrirao/diffusers/blob/main/examples/dreambooth/DreamBooth_Stable_Diffusion.ipynb)<br>\n",
        "You can find latest notebook update [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-dreambooth-stable.ipynb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Kohya Trainer"
      ],
      "metadata": {
        "id": "tTVqCAgSmie4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone Kohya Trainer\n",
        "%cd /content/\n",
        "!git clone https://github.com/Linaqruf/kohya-trainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing Dependencies\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "Install_Python_3_9_6 = True #@param{'type':'boolean'}\n",
        "\n",
        "if Install_Python_3_9_6 == True:\n",
        "  #install python 3.9\n",
        "  !sudo apt-get update -y\n",
        "  !sudo apt-get install python3.9\n",
        "\n",
        "  #change alternatives\n",
        "  !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "  !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "  #check python version\n",
        "  !python --version\n",
        "  #3.9.6\n",
        "  !sudo apt-get install python3.9-distutils && wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py\n",
        "  \n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install -r requirements.txt\n",
        "!pip install -U gallery-dl\n",
        "!pip install tensorflow\n",
        "\n",
        "#install xformers\n",
        "if Install_Python_3_9_6 == True:\n",
        "  %pip install -q https://github.com/daswer123/stable-diffusion-colab/raw/main/xformers%20prebuild/T4/python39/xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl\n",
        "else:\n",
        "  %pip install -qq https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.14/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n"
      ],
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set config for `!Accelerate`\n",
        "#@markdown #Hint\n",
        "\n",
        "#@markdown 1. **In which compute environment are you running?** ([0] This machine, [1] AWS (Amazon SageMaker)): `0`\n",
        "#@markdown 2. **Which type of machine are you using?** ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU [4] MPS): `0`\n",
        "#@markdown 3. **Do you want to run your training on CPU only (even if a GPU is available)?** [yes/NO]: `NO`\n",
        "#@markdown 4. **Do you want to use DeepSpeed?** [yes/NO]: `NO`\n",
        "#@markdown 5. **What GPU(s) (by id) should be used for training on this machine as a comma-seperated list?** [all] = `all`\n",
        "#@markdown 6. **Do you wish to use FP16 or BF16 (mixed precision)?** [NO/fp16/bf16]: `fp16`\n",
        "%cd /content/kohya-trainer\n",
        "!accelerate config"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RnjHb4wgD7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folders configuration\n",
        "\n",
        "Refer to the note to understand how to create the folder structure. In short it should look like:\n",
        "\n",
        "```\n",
        "<arbitrary folder name>\n",
        "|- <arbitrary class folder name>\n",
        "    |- <repeat count>_<class>\n",
        "|- <arbitrary training folder name>\n",
        "   |- <repeat count>_<token> <class>\n",
        "```\n",
        "\n",
        "Example for `asd dog` where `asd` is the token word and `dog` is the class. In this example the regularization `dog` class images contained in the folder will be repeated only 1 time and the `asd dog` images will be repeated 20 times:\n",
        "\n",
        "```\n",
        "my_asd_dog_dreambooth\n",
        "|- reg_dog\n",
        "    |- 1_dog\n",
        "       `- reg_image_1.png\n",
        "       `- reg_image_2.png\n",
        "       ...\n",
        "       `- reg_image_256.png\n",
        "|- train_dog\n",
        "    |- 20_asd dog\n",
        "       `- dog1.png\n",
        "       ...\n",
        "       `- dog8.png\n",
        "```"
      ],
      "metadata": {
        "id": "En9UUwGNMRMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.isdir('/content/dreambooth'):\n",
        "  pass\n",
        "else:\n",
        "  !mkdir /content/dreambooth\n",
        "\n",
        "#@title Create train and reg folder based on description above\n",
        "#@markdown #Create reg folder\n",
        "reg_count = 1 #@param {type: \"integer\"}\n",
        "reg_class =\"kasakai_hikaru\" #@param {type: \"string\"}\n",
        "reg_folder = str(reg_count) + \"_\" + reg_class\n",
        "\n",
        "#@markdown #Create train folder\n",
        "train_count = 3300 #@param {type: \"integer\"}\n",
        "train_token = \"sls\" #@param {type: \"string\"}\n",
        "train_class = \"kasakai_hikaru\" #@param {type: \"string\"}\n",
        "train_folder = str(train_count) + \"_\" + train_token + \"_\" + train_class\n",
        "\n",
        "!mkdir \"/content/dreambooth/reg_{reg_class}\"\n",
        "!mkdir \"/content/dreambooth/reg_{reg_class}/{reg_folder}\"\n",
        "!mkdir \"/content/dreambooth/train_{train_class}\"\n",
        "!mkdir \"/content/dreambooth/train_{train_class}/{train_folder}\"\n"
      ],
      "metadata": {
        "id": "-CVfXAJMSqRi",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77b8451-138b-4a88-8224-3244ad1b0465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Datasets"
      ],
      "metadata": {
        "id": "Pz9A2bu1Cq73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare Regularization Images\n",
        "#@markdown Download regularization images provided by community\n",
        "category = \"waifu-regularization-3.3k\" #@param [\"\", \"waifu-regularization-3.3k\", \"husbando-regularization-3.5k\"]\n",
        "#@markdown Or you can use the file manager on the left panel to upload (drag and drop) to `reg_images` folder (it uploads faster)\n",
        "def reg_images(url, name):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} \"{url}\" -O /content/dreambooth/reg_{reg_class}/{reg_folder}/{name}.zip\n",
        "\n",
        "if category != \"\":\n",
        "  if category == \"waifu-regularization-3.3k\":\n",
        "    reg_images(\"https://huggingface.co/datasets/waifu-research-department/regularization/resolve/main/waifu-regularization-3.3k.zip\", \"waifu-regularization-3.3k\")\n",
        "    !unzip /content/dreambooth/reg_{reg_class}/{reg_folder}/waifu-regularization-3.3k.zip -d /content/dreambooth/reg_{reg_class}/{reg_folder}\n",
        "    !rm /content/dreambooth/reg_{reg_class}/{reg_folder}/waifu-regularization-3.3k.zip\n",
        "  else:\n",
        "    reg_images(\"https://huggingface.co/datasets/waifu-research-department/regularization/resolve/main/husbando-regularization-3.5k.zip\", \"husbando-regularization-3.5k\")\n",
        "    !unzip /content/dreambooth/reg_{reg_class}/{reg_folder}/husbando-regularization-3.5k.zip -d  /content/dreambooth/reg_{reg_class}/{reg_folder}\n",
        "    !rm /content/dreambooth/reg_{reg_class}/{reg_folder}/husbando-regularization-3.5k.zip\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "R9JZSOuSzXe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare Train Images\n",
        "#@markdown **How this work?**\n",
        "\n",
        "#@markdown By using **gallery-dl** we can scrap or bulk download images on Internet, on this notebook we will scrap images from Danbooru using tag1 and tag2 as target scraping.\n",
        "#@title Booru Scraper\n",
        "%cd /content\n",
        "\n",
        "tag = \"kasakai_hikaru\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "\n",
        "booru = \"Gelbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "\n",
        "if tag2 is not \"\":\n",
        "  tag = tag + \"+\" + tag2\n",
        "else:\n",
        "  tag = tag\n",
        "\n",
        "output_dir = \"/content/dreambooth/train_\"+ train_class +\"/\"+ train_folder\n",
        "\n",
        "if booru == \"Danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tag}\" -D \"{output_dir}\"\n",
        "elif booru == \"Gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tag}\" -D \"{output_dir}\"\n",
        "else:\n",
        "  pass\n",
        "\n",
        "#@markdown Or you can use the file manager on the left panel to upload (drag and drop) to `train_images` folder. \n",
        "\n",
        "#@markdown The output directory will be on `/content/dreambooth/reg_{reg_class}/{reg_folder}`. We also will use this folder as target folder for training next step.\n",
        "\n"
      ],
      "metadata": {
        "id": "Kt1GzntK_apb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`NEW` Detect Anime Face and Rotate\n",
        "This segment based on [this guide](https://note.com/kohya_ss/n/nad3bce9a3622)"
      ],
      "metadata": {
        "id": "E9ZxrCm4S8cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:\n",
        "\n",
        "```powershell\n",
        "!python detect_face_rotate.py --src_dir src --dst_dir dst --rotate\n",
        "```\n",
        "The image is rotated so that the character's face is roughly upright as shown below, and the face coordinates (center X, center Y, width, height) are added to the file name. The DreamBooth learning script uses this information to augment.\n",
        "\n",
        "**Face-centered cropping with original image size in mind**\n",
        "\n",
        "Specifying the cropped image size with the --crop_size option and the --resize_fit option resizes the short side of the image to fit the teacher data size and crops the image so that the face is centered on the long side (ignoring the face size).\n",
        "\n",
        "```powershell\n",
        "!python detect_face_rotate.py --src_dir src --dst_dir dst --rotate --crop_size 512,512 --resize_fit\n",
        "```\n",
        "\n",
        "**Uniform face-size cropping**\n",
        "\n",
        "If you specify the cropping image size with the --crop_size option and the face size with the --resize_face_size option, the image is resized so that the face is that size and then cropped with the specified size centered on the face.\n",
        "For example, in the following example\n",
        "\n",
        "```powershell\n",
        "!python detect_face_rotate.py --src_dir src --dst_dir dst --rotate --crop_size 512,512 --resize_face_size 192\n",
        "```\n",
        "\n",
        "**Or you can just skip these steps below and do augmentation while training instead.**\n",
        "\n",
        "New args for `detect face and rotate`\n",
        "```powershell\n",
        "!accelerate train_db_fixed_v12.py\n",
        "    --face_crop_aug_range=2.0,3.0 \\\n",
        "    --flip_aug \\\n",
        "    --color_aug \n",
        "```\n",
        "<!-- You can add it manually, note that you need to remove this args first or you will get error\n",
        "```powershell\n",
        "!accelerate train_db_fixed_v12.py\n",
        "    --cache_latents \\\n",
        "    --enable_bucket \\\n",
        "``` -->"
      ],
      "metadata": {
        "id": "7BBiH3bkg88d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Anime Face Detector\n",
        "%cd /content\n",
        "if Install_Python_3_9_6 == True:\n",
        "  !sudo apt-get install python3.9-dev\n",
        "else:\n",
        "  !sudo apt-get install python3.7-dev\n",
        "\n",
        "# installation\n",
        "!pip install openmim\n",
        "!mim install mmcv-full\n",
        "!mim install mmdet\n",
        "!mim install mmpose\n",
        "!pip install anime-face-detector\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AO_K4umgOlIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Anime Face Augmentation\n",
        "%cd /content/kohya-trainer\n",
        "import shutil\n",
        "\n",
        "train_data =\"/content/dreambooth/train_kasakai_hikaru/3300_sls_kasakai_hikaru\" #@param {'type':'string'}\n",
        "tmp = \"/content/dreambooth/tmp\"\n",
        "\n",
        "if os.path.isdir(tmp):\n",
        "  !rm -rf {tmp}\n",
        "  shutil.move (train_data, tmp)\n",
        "  !mkdir {train_data}\n",
        "else:\n",
        "  shutil.move (train_data, tmp)\n",
        "  !mkdir {train_data}\n",
        "\n",
        "!python detect_face_rotate.py --src_dir {tmp} --dst_dir {train_data} --rotate\n",
        "\n",
        "#@markdown Args list:\n",
        "#@markdown - `--src_dir` : directory to load images\n",
        "#@markdown - `--dst_dir` : directory to save images\n",
        "#@markdown - `--rotate` : rotate images to align faces\n",
        "#@markdown - `--resize_fit` : resize to fit smaller side\n",
        "#@markdown - `--resize_face_size` : resize image before cropping by face size\n",
        "#@markdown - `--crop_size` : resize image before cropping by face size\n",
        "#@markdown - `--debug` : debug mode"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Med6ivroMqe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`(NEW)` Waifu Diffusion 1.4 Autotagger"
      ],
      "metadata": {
        "id": "SoPUJaTpTusz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Weight\n",
        "%cd /content/kohya-trainer/\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def huggingface_dl(url, weight):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/kohya-trainer/wd14tagger-weight/{weight}\n",
        "\n",
        "def download_weight():\n",
        "  !mkdir /content/kohya-trainer/wd14tagger-weight/\n",
        "  huggingface_dl(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/wd14tagger-weight/wd14Tagger.zip\", \"wd14Tagger.zip\")\n",
        "  \n",
        "  !unzip /content/kohya-trainer/wd14tagger-weight/wd14Tagger.zip -d /content/kohya-trainer/wd14tagger-weight\n",
        "\n",
        "  # Destination path \n",
        "  destination = '/content/kohya-trainer/wd14tagger-weight'\n",
        "\n",
        "  if os.path.isfile('/content/kohya-trainer/tag_images_by_wd14_tagger.py'):\n",
        "    # Move the content of \n",
        "    # source to destination \n",
        "    shutil.move(\"tag_images_by_wd14_tagger.py\", destination) \n",
        "  else:\n",
        "    pass\n",
        "\n",
        "download_weight()"
      ],
      "metadata": {
        "id": "WDSlAEHzT2Im",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Autotagger\n",
        "%cd /content/kohya-trainer/wd14tagger-weight\n",
        "\n",
        "!python tag_images_by_wd14_tagger.py --batch_size 4 {train_data}\n",
        "\n",
        "#@markdown Args list:\n",
        "#@markdown - `--train_data_dir` : directory for training images\n",
        "#@markdown - `--model` : model path to load\n",
        "#@markdown - `--tag_csv` : csv file for tag\n",
        "#@markdown - `--thresh` : threshold of confidence to add a tag\n",
        "#@markdown - `--batch_size` : batch size in inference\n",
        "#@markdown - `--model` : model path to load\n",
        "#@markdown - `--caption_extension` : extension of caption file\n",
        "#@markdown - `--debug` : debug mode\n"
      ],
      "metadata": {
        "id": "hibZK5NPTjZQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Pre-trained Model \n",
        "%cd /content/kohya-trainer\n",
        "!mkdir checkpoint\n",
        "\n",
        "#@title Install Pre-trained Model \n",
        "\n",
        "installModels=[]\n",
        "\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available pretrained model to download:\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/modelsfw-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp16.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp32.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\" \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \\\n",
        "            \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Animesfw-final-pruned\", \\\n",
        "             \"Anything-V3.0-pruned-fp16\", \\\n",
        "             \"Anything-V3.0-pruned-fp32\", \\\n",
        "             \"Anything-V3.0-pruned\", \\\n",
        "             \"Stable-Diffusion-v1-4\", \\\n",
        "             \"Stable-Diffusion-v1-5-pruned-emaonly\" \\\n",
        "             \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "modelName = \"Anything-V3.0-pruned-fp32\" #@param [\"\", \"Animefull-final-pruned\", \"Animesfw-final-pruned\", \"Anything-V3.0-pruned-fp16\", \"Anything-V3.0-pruned-fp32\", \"Anything-V3.0-pruned\", \"Stable-Diffusion-v1-4\", \"Stable-Diffusion-v1-5-pruned-emaonly\", \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "\n",
        "#@markdown ### Custom model\n",
        "#@markdown The model URL should be a direct download link.\n",
        "customName = \"\" #@param {'type': 'string'}\n",
        "customUrl = \"\"#@param {'type': 'string'}\n",
        "\n",
        "if customName == \"\" or customUrl == \"\":\n",
        "  pass\n",
        "else:\n",
        "  installModels.append((customName, customUrl))\n",
        "\n",
        "if modelName != \"\":\n",
        "  # Map model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy -O \"/content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\" \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt \"{url}\"\n",
        "  else:\n",
        "    user_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    !wget -c --header={user_header} \"{url}\" -O /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  for model in installModels:\n",
        "    install(model[0], model[1])\n",
        "install_checkpoint()\n",
        "\n"
      ],
      "metadata": {
        "id": "SoucgZQ6jgPQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Training\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNbl3O_NSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training begin\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'integer'}\n",
        "pre_trained_model_path =\"Linaqruf/anything-v3.0\" #@param {'type':'string'}\n",
        "train_data_dir = \"/content/dreambooth/train_kasakai_hikaru\" #@param {'type':'string'}\n",
        "reg_data_dir = \"/content/dreambooth/reg_kasakai_hikaru\" #@param {'type':'string'}\n",
        "output_dir =\"/content/dreambooth\" #@param {'type':'string'}\n",
        "train_batch_size = 1  #@param {type: \"slider\", min: 1, max: 10}\n",
        "resolution = \"512,512\" #@param [\"512,512\", \"768,768\"] {allow-input: false}\n",
        "learning_rate =\"2e-6\" #@param {'type':'string'}\n",
        "mixed_precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "max_train_steps = 5000 #@param {'type':'integer'}\n",
        "save_precision = \"fp16\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs = 10 #@param {'type':'integer'}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "!accelerate launch --num_cpu_threads_per_process {num_cpu_threads_per_process} /content/kohya-trainer/db_script_archive/train_db_fixed_v12.py \\\n",
        "    --pretrained_model_name_or_path={pre_trained_model_path} \\\n",
        "    --train_data_dir={train_data_dir} \\\n",
        "    --reg_data_dir={reg_data_dir} \\\n",
        "    --output_dir={output_dir} \\\n",
        "    --prior_loss_weight=1.0 \\\n",
        "    --resolution={resolution} \\\n",
        "    --train_batch_size={train_batch_size}\\\n",
        "    --learning_rate={learning_rate}\\\n",
        "    --max_train_steps={max_train_steps}  \\\n",
        "    --use_8bit_adam \\\n",
        "    --xformers \\\n",
        "    --mixed_precision={mixed_precision} \\\n",
        "    --gradient_checkpointing \\\n",
        "    --save_every_n_epochs={save_every_n_epochs} \\\n",
        "    --enable_bucket \\\n",
        "    --cache_latents \n",
        "    # --mem_eff_attn \\\n",
        "    # --face_crop_aug_range=2.0,3.0 \\\n",
        "    # --flip_aug \\\n",
        "    # --color_aug \n"
      ],
      "metadata": {
        "id": "X_Rd3Eh07xlA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert trained model to ckpt\n",
        "\n",
        "#@markdown This cell will convert output weight to checkpoint file so it can be used in Web UI like Auto1111's\n",
        "WEIGHTS_DIR = \"/content/dreambooth/last\" #@param {'type':'string'}\n",
        "#@markdown Run conversion.\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "#@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
        "fp16 = True #@param {type: \"boolean\"}\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rM5o1gUu97yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None\n",
        "\n",
        "#@markdown Can set random seed here for reproducibility.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 123123 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "\n",
        "#@title Run for generating images.\n",
        "\n",
        "prompt = \"hatsune miku\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cKn2ARpLAI0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Miscellaneous"
      ],
      "metadata": {
        "id": "vqfgyL-thgdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount to Google Drive\n",
        "mount_drive= False #@param {'type':'boolean'}\n",
        "\n",
        "if mount_drive== True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OuRqOSp2eU6t",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Huggingface_hub Integration"
      ],
      "metadata": {
        "id": "QtVP2le8PL2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instruction:\n",
        "0. Of course you need a Huggingface Account first\n",
        "1. Create huggingface token, go to `Profile > Access Tokens > New Token > Create a new access token` with the `Write` role.\n",
        "2. All cells below are checked `opt-out` by default so you need to uncheck it if you want to running the cells."
      ],
      "metadata": {
        "id": "tbKgmh_AO5NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login to Huggingface hub\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "#@markdown Prepare your Huggingface token\n",
        "\n",
        "saved_token= \"save-your-write-token-here\" #@param {'type': 'string'}\n",
        "\n",
        "if opt_out == False:\n",
        " \n",
        "  from huggingface_hub import notebook_login\n",
        "  notebook_login()\n",
        "\n"
      ],
      "metadata": {
        "id": "Da7awoqAPJ3a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Commit trained model to Huggingface"
      ],
      "metadata": {
        "id": "jypUkLWc48R_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instruction:\n",
        "0. Create huggingface repository for model\n",
        "1. Clone your model to this colab session\n",
        "2. Move these necessary file to your repository to save your trained model to huggingface\n",
        "\n",
        ">in `content/kohya-trainer/fine-tuned`\n",
        "- File `epoch-nnnnn.ckpt` and/or\n",
        "- File `last.ckpt`, \n",
        "\n",
        "4. Commit your model to huggingface"
      ],
      "metadata": {
        "id": "TvZgRSmKVSRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Model\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  Repository_url = \"https://huggingface.co/Linaqruf/alphanime-diffusion\" #@param {'type': 'string'}\n",
        "  !git clone {Repository_url}\n",
        "else:\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "182Law9oUiYN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Commit to Huggingface\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  #@markdown Go to your model path\n",
        "  model_path= \"alphanime-diffusion\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown Your path look like /content/**model_path**\n",
        "  #@markdown ___\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "\n",
        "  email= \"your-email\" #@param {'type': 'string'}\n",
        "  name= \"your-name\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m= \"this is commit message\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd \"/content/{model_path}\"\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "87wG7QIZbtZE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}