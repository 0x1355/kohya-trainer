{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/dev/kohya-LoRA-dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=linaqruf.lora-dreambooth)\n",
        "#Kohya LoRA Dreambooth"
      ],
      "metadata": {
        "id": "slgjeYgd6pWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted to Google Colab based on [kohya-ss/sd-script](https://github.com/kohya-ss/sd-scripts)<br>\n",
        "Adapted to Google Colab by [Linaqruf](https://github.com/Linaqruf)<br>\n",
        "You can find latest notebook update [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# I. Install Kohya Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.1. Clone Kohya Trainer\n",
        "#@markdown Clone Kohya Trainer from GitHub and check for updates. Use textbox below if you want to checkout other branch or old commit. Leave it empty to stay the HEAD on main.\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# Check GPU Availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Define path\n",
        "root_dir = \"/content\"\n",
        "%store root_dir\n",
        "repo_dir = str(root_dir)+\"/kohya-trainer\"\n",
        "%store repo_dir\n",
        "tools_dir = str(root_dir)+\"/kohya-trainer/tools\"\n",
        "%store tools_dir \n",
        "finetune_dir = str(root_dir)+\"/kohya-trainer/finetune\"\n",
        "%store finetune_dir\n",
        "training_dir = str(root_dir)+\"/dreambooth\"\n",
        "%store training_dir\n",
        "\n",
        "# Define identifier\n",
        "branch = \"\" #@param {type: \"string\"}\n",
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "def clone_repo():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir(repo_dir):\n",
        "    %cd {repo_dir}\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    if branch != \"\":\n",
        "      !git pull origin {branch} \n",
        "    else:\n",
        "      !git pull\n",
        "  else:\n",
        "    !git clone {repo_url}\n",
        "\n",
        "def checkout_repo(branch_or_commit):\n",
        "  %cd {repo_dir}\n",
        "  !git checkout {branch_or_commit}\n",
        "\n",
        "# Clone or update the Kohya Trainer repository\n",
        "clone_repo()\n",
        "\n",
        "# Checkout to the specified branch or commit\n",
        "if branch != \"\":\n",
        "  checkout_repo(branch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.2. Installing Dependencies\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "#@markdown This will install required Python packages\n",
        "\n",
        "# Define variable\n",
        "accelerate_config = str(repo_dir)+\"/accelerate_config/config.yaml\"\n",
        "%store accelerate_config\n",
        "install_xformers = True #@param {'type':'boolean'}\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "def install_dependencies():\n",
        "  !pip -qqqq install --upgrade gallery-dl\n",
        "  !pip -qqqq install --upgrade --no-cache-dir gdown\n",
        "  !apt -qqqq install liblz4-tool aria2\n",
        "  !pip -qqqq install imjoy-elfinder\n",
        "  !pip -qqqq install --upgrade -r requirements.txt\n",
        "\n",
        "  if install_xformers:\n",
        "    !pip -qqqq install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  from accelerate.utils import write_basic_config\n",
        "  if not os.path.exists(accelerate_config):\n",
        "    write_basic_config(save_location = accelerate_config) # Write a config file\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "# Install dependencies\n",
        "install_dependencies()\n",
        "\n",
        "#@markdown After Accelerate updated its version to 0.15.0, you can't manually input the config using\n",
        "#@markdown `!accelerate config` in Google Colab. Instead, a `config.yaml` file will be generated by\n",
        "#@markdown the `write_basic_config()` function. You can find the file [here](/content/kohya-trainer/accelerate_config/config.yaml) after installation.\n",
        "#@markdown if you want to modify it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Sign-in to Cloud Service"
      ],
      "metadata": {
        "id": "qt9EJv5gQXuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 1.3.1. Login to Huggingface hub\n",
        "from huggingface_hub import login\n",
        "%store -r\n",
        "\n",
        "#@markdown 1. Of course, you need a Huggingface account first.\n",
        "#@markdown 2. To create a huggingface token, go to [this link](https://huggingface.co/settings/tokens), then `create new token` or copy available token with the `Write` role.\n",
        "\n",
        "write_token = \"your-write-token-here\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n",
        "\n",
        "%store write_token\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rl2zERHbBQ9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 1.3.2. Mount Drive\n",
        "from google.colab import drive\n",
        "\n",
        "mount_drive = True #@param {type: \"boolean\"}\n",
        "\n",
        "if mount_drive:\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sKL38-WmQsLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.4. Open Special `File Explorer` for Colab\n",
        "#@markdown This will work real-time even though you're running other cells\n",
        "%store -r\n",
        "\n",
        "import threading\n",
        "from google.colab import output\n",
        "from imjoy_elfinder.app import main\n",
        "\n",
        "# start imjoy-elfinder server\n",
        "thread = threading.Thread(target=main, args=[[\"--root-dir=/content\", \"--port=8765\"]])\n",
        "thread.start()\n",
        "\n",
        "open_in_new_tab = True #@param {type:\"boolean\"}\n",
        "\n",
        "if open_in_new_tab:\n",
        "  # open imjoy-elfinder in a new tab\n",
        "  output.serve_kernel_port_as_window(8765)\n",
        "else:\n",
        "  # view the \n",
        "  output.serve_kernel_port_as_iframe(8765, height='500')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZmIRAxgEQESm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gob9_OwTlwh"
      },
      "source": [
        "# II. Pretrained Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 2.1. Download Available Model \n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "installModels = []\n",
        "installv2Models = []\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available model to download:\n",
        "\n",
        "#@markdown ### SD1.x model\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\", \\\n",
        "            \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.5-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Rasgeath/self_made_sauce/resolve/main/Kani-anime-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_nsfw.safetensors\", \\\n",
        "            \"https://huggingface.co/gsdf/Counterfeit-V2.0/resolve/main/Counterfeit-V2.0fp16.safetensors\", \\\n",
        "            \"https://huggingface.co/closertodeath/dpepteahands3/resolve/main/dpepteahand3.ckpt\", \\\n",
        "            \"https://huggingface.co/prompthero/openjourney-v2/resolve/main/openjourney-v2.ckpt\", \\\n",
        "            \"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/resolve/main/dreamlike-diffusion-1.0.ckpt\", \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Anything-v3-1\", \\\n",
        "             \"Anything-v4-5-pruned\", \\\n",
        "             \"Kani-anime-pruned\", \\\n",
        "             \"AbyssOrangeMix2-nsfw\", \\\n",
        "             \"Counterfeit-v2\", \\\n",
        "             \"DpepTeaHands3\", \\\n",
        "             \"OpenJourney-v2\", \\\n",
        "             \"Dreamlike-diffusion-v1-0\", \\\n",
        "             \"Stable-Diffusion-v1-5\"]\n",
        "modelName = \"Anything-v3-1\"  #@param [\"\", \"Animefull-final-pruned\", \"Anything-v3-1\", \"Anything-v4-5-pruned\", \"Kani-anime-pruned\", \"AbyssOrangeMix2-nsfw\", \"Counterfeit-v2\", \"DpepTeaHands3\", \"OpenJourney-v2\", \"Dreamlike-diffusion-v1-0\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "#@markdown ### SD2.x model\n",
        "v2ModelUrl = [\"\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\", \\\n",
        "              \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\"]\n",
        "v2ModelList = [\"\", \\\n",
        "              \"stable-diffusion-2-1-base\", \\\n",
        "              \"stable-diffusion-2-1-768v\", \\\n",
        "              \"waifu-diffusion-1-4-anime-e2\", \\\n",
        "              \"plat-diffusion-v1-3-1\"]\n",
        "v2ModelName = \"\" #@param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"waifu-diffusion-1-4-anime-e2\", \"plat-diffusion-v1-3-1\"]\n",
        "\n",
        "# Check if user has selected a model\n",
        "if modelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if v2ModelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  if url.endswith(\".ckpt\"):\n",
        "    ext = \"ckpt\"\n",
        "  else:\n",
        "    ext = \"safetensors\"\n",
        "     \n",
        "  hf_token = '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' \n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {root_dir}/pre_trained_model -o {checkpoint_name}.{ext} \"{url}\"\n",
        "\n",
        "def install_checkpoint():\n",
        "  # Iterate through list of models to install\n",
        "  for model in installModels:\n",
        "    # Call install function for each model\n",
        "    install(model[0], model[1])\n",
        "\n",
        "  # Iterate through list of models to install\n",
        "  for v2model in installv2Models:\n",
        "    # Call install function for each v2model\n",
        "    install(v2model[0], v2model[1])\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wmnsZwClN1XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 2.2. Download Custom Model\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "#@markdown ### Custom model\n",
        "modelUrl = \"\" #@param {'type': 'string'}\n",
        "dst = str(root_dir)+\"/pre_trained_model\"\n",
        "\n",
        "if not os.path.exists(dst):\n",
        "    os.makedirs(dst)\n",
        "\n",
        "def install(url):\n",
        "  base_name = os.path.basename(url)\n",
        "\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    %cd {dst}\n",
        "    !gdown --fuzzy {url}\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in url:\n",
        "      url = url.replace('/blob/', '/resolve/')\n",
        "    #@markdown Change this part with your own huggingface token if you need to download your private model\n",
        "    hf_token = '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' #@param {type:\"string\"}\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst} -o {base_name} {url}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst} -o {base_name} {url}\n",
        "\n",
        "install(modelUrl)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3LWn6GzNQ4j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SoucgZQ6jgPQ"
      },
      "outputs": [],
      "source": [
        "#@title ## 2.3. Download Available VAE\n",
        "%store -r \n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "installVae = []\n",
        "#@markdown ### Available VAE\n",
        "#@markdown Select one of the VAEs to download, select `none` for not download VAE:\n",
        "vaeUrl = [\"\", \\\n",
        "          \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\", \\\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\", \\\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "vaeList = [\"none\", \\\n",
        "           \"anime.vae.pt\", \\\n",
        "           \"waifudiffusion.vae.pt\", \\\n",
        "           \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"anime.vae.pt\" #@param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "def install(vae_name, url):\n",
        "  hf_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -o vae/{vae_name} \"{url}\"\n",
        "\n",
        "def install_vae():\n",
        "  if vaeName != \"none\":\n",
        "    for vae in installVae:\n",
        "      install(vae[0], vae[1])\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "install_vae()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# IV. Data Acquisition\n",
        "\n",
        "You can either upload your dataset to this notebook or use the image scraper below to bulk download images from Danbooru.\n",
        "\n",
        "If you want to use your own dataset, you can upload to colab `local files`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.1. Define Train Data Directory\n",
        "#@markdown Define where your train data will be located. This cell will also create a folder based on your input. \n",
        "#@markdown This folder will be used as the target folder for scraping, tagging, bucketing, and training in the next cell.\n",
        "\n",
        "%store -r\n",
        "\n",
        "train_folder_directory = \"/content/dreambooth/train_data\" #@param {type: \"string\"}\n",
        "%store train_folder_directory\n",
        "train_parent_directory = os.path.dirname(train_folder_directory)\n",
        "reg_folder_directory = f\"{train_parent_directory}/reg_data\"\n",
        "%store reg_folder_directory\n",
        "\n",
        "dataset_repeats = 1 #@param {type: \"integer\"}\n",
        "train_concept = \"mksks\" #@param {type: \"string\"}\n",
        "train_class = \"\" #@param {type: \"string\"}\n",
        "#@markdown You can run this cell multiple time to add new concepts\n",
        "\n",
        "if train_class:\n",
        "  train_folder = str(dataset_repeats) + \"_\" + train_concept + \" \" + train_class\n",
        "else:\n",
        "  train_folder = str(dataset_repeats) + \"_\" + train_concept\n",
        "  \n",
        "train_data_dir = f\"{train_folder_directory}/{train_folder}\"\n",
        "\n",
        "if not os.path.isdir(reg_folder_directory):\n",
        "  os.mkdir(reg_folder_directory)\n",
        "\n",
        "if not os.path.isdir(train_folder_directory):\n",
        "  os.mkdir(train_folder_directory)\n",
        "\n",
        "if not os.path.isdir(train_data_dir):\n",
        "  os.mkdir(train_data_dir)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kh7CeDqK4l3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4209e1d-b2a9-4df6-fa59-faf761ad8b62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'train_folder_directory' (str)\n",
            "Stored 'reg_folder_directory' (str)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 4.2. Download and Extract Zip (.zip)\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "%store -r\n",
        "\n",
        "#@markdown ### Define Zipfile URL or Zipfile Path\n",
        "zipfile_url_or_path = \"https://huggingface.co/datasets/Linaqruf/your-dataset-name/resolve/main/hito-komoru_dataset.zip\" #@param {'type': 'string'}\n",
        "zipfile_dst = str(root_dir)+\"/zip_file.zip\"\n",
        "extract_to = \"\" #@param {'type': 'string'}\n",
        "\n",
        "if extract_to != \"\":\n",
        "  if not os.path.exist(extract_to):\n",
        "    os.makedirs(extract_to)\n",
        "else:\n",
        "  extract_to = train_data_dir\n",
        "\n",
        "#@markdown This will ignore `extract_to` path and automatically extracting to `train_data_dir`\n",
        "is_dataset = True #@param{'type':'boolean'}\n",
        "\n",
        "#@markdown Tick this if you want to extract all files directly to `extract_to` folder, and automatically delete the zip to save the memory\n",
        "auto_unzip_and_delete = True #@param{'type':'boolean'}\n",
        "\n",
        "dirname = os.path.dirname(zipfile_dst)\n",
        "basename = os.path.basename(zipfile_dst)\n",
        "\n",
        "try:\n",
        "  if zipfile_url_or_path.startswith(\"/content\"):\n",
        "    zipfile_dst = zipfile_url_or_path\n",
        "    if auto_unzip_and_delete == False:\n",
        "      if is_dataset:\n",
        "        extract_to = train_data_dir\n",
        "      !unzip -j {zipfile_dst} -d \"{extract_to}\"\n",
        "  elif zipfile_url_or_path.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy  {zipfile_url_or_path}\n",
        "  elif zipfile_url_or_path.startswith(\"magnet:?\"):\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 {zipfile_url_or_path}\n",
        "  elif zipfile_url_or_path.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in zipfile_url_or_path:\n",
        "      zipfile_url_or_path = zipfile_url_or_path.replace('/blob/', '/resolve/')\n",
        "\n",
        "    hf_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dirname} -o {basename} {zipfile_url_or_path}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dirname} -o {basename} {zipfile_url_or_path}\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while downloading the file:\", e)\n",
        "\n",
        "if is_dataset:\n",
        "  extract_to = train_data_dir\n",
        "\n",
        "if auto_unzip_and_delete:\n",
        "  !unzip -j {zipfile_dst} -d \"{extract_to}\"\n",
        "\n",
        "  # directory to check for files\n",
        "  # JSON files to move\n",
        "  files_to_move = (\"meta_cap.json\", \\\n",
        "                   \"meta_cap_dd.json\", \\\n",
        "                   \"meta_lat.json\", \\\n",
        "                   \"meta_clean.json\")\n",
        "\n",
        "  # check each file in the directory\n",
        "  for filename in os.listdir(extract_to):\n",
        "      # get the full file path\n",
        "      file_path = os.path.join(extract_to, filename)\n",
        "      if filename in files_to_move:\n",
        "          # move the file to the parent directory\n",
        "          shutil.move(file_path, os.path.dirname(extract_to))\n",
        "  \n",
        "  path_obj = Path(zipfile_dst)\n",
        "  zipfile_name = path_obj.parts[-1]\n",
        "  \n",
        "  if os.path.isdir(zipfile_dst):\n",
        "    print(\"\\nThis zipfile doesn't exist or has been deleted \\n\")\n",
        "  else:\n",
        "    os.remove(zipfile_dst)\n",
        "    print(f\"\\n{zipfile_name} has been deleted\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eFFHVTWNZGbp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "37c64428-397d-4576-fef7-6ac14b53236b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "01/30 17:19:48 [\u001b[1;31mERROR\u001b[0m] CUID#7 - Download aborted. URI=https://huggingface.co/datasets/Linaqruf/your-dataset-name/resolve/main/hito-komoru_dataset.zip\n",
            "Exception: [AbstractCommand.cc:351] errorCode=3 URI=https://huggingface.co/datasets/Linaqruf/your-dataset-name/resolve/main/hito-komoru_dataset.zip\n",
            "  -> [HttpSkipResponseCommand.cc:218] errorCode=3 Resource not found\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "50ddb5|\u001b[1;31mERR\u001b[0m |       0B/s|/content/zip_file.zip\n",
            "\n",
            "Status Legend:\n",
            "(ERR):error occurred.\n",
            "\n",
            "aria2 will resume download if the transfer is restarted.\n",
            "If there are any errors, then see the log file. See '-l' option in help/man page for details.\n",
            "unzip:  cannot find or open /content/zip_file.zip, /content/zip_file.zip.zip or /content/zip_file.zip.ZIP.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ae26b8811a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nThis zipfile doesn't exist or has been deleted \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{zipfile_name} has been deleted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/zip_file.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A0t1dfnU5Xkq"
      },
      "outputs": [],
      "source": [
        "#@title ## 4.3. Simple Booru Scraper\n",
        "#@markdown Use gallery-dl to scrape images from a booru site using the specified tags\n",
        "import os\n",
        "import html\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "# Set configuration options\n",
        "booru = \"Gelbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "tag1 = \"hito_komoru\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "download_tags = False #@param {type: \"boolean\"}\n",
        "# Construct the search query\n",
        "if tag2 != \"\":\n",
        "  tags = tag1 + \"+\" + tag2\n",
        "else:\n",
        "  tags = tag1\n",
        "\n",
        "if download_tags == True:\n",
        "  write_tags = \"--write-tags\"\n",
        "else:\n",
        "  write_tags = \"\"\n",
        "\n",
        "# Scrape images from the specified booru site using the given tags\n",
        "if booru.lower() == \"danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tags}\" {write_tags} -D \"{train_data_dir}\"\n",
        "elif booru.lower() == \"gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tags}\" {write_tags} -D \"{train_data_dir}\"\n",
        "else:\n",
        "  print(f\"Unknown booru site: {booru}\")\n",
        "\n",
        "if download_tags == True: \n",
        "  # Get a list of all the .txt files in the folder\n",
        "  files = [f for f in os.listdir(train_data_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "  # Loop through each file\n",
        "  for file in files:\n",
        "      file_path = os.path.join(train_data_dir, file)\n",
        "\n",
        "      # Read the contents of the file\n",
        "      with open(file_path, \"r\") as f:\n",
        "          contents = f.read()\n",
        "\n",
        "      # Decode HTML entities and replace _ with a space\n",
        "      contents = html.unescape(contents)\n",
        "      contents = contents.replace(\"_\", \" \")\n",
        "\n",
        "      # Split the contents on newline characters and join with commas\n",
        "      contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "      # Write the modified contents back to the file\n",
        "      with open(file_path, \"w\") as f:\n",
        "          f.write(contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VI. Data Preprocessing"
      ],
      "metadata": {
        "id": "zUiL2sLg7swG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 6.1. Data Cleaning\n",
        "#@markdown This will delete unnecessary files and unsupported media like `.mp4`, `.webm`, and `.gif`\n",
        "%store -r\n",
        "\n",
        "import os\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "\n",
        "#@markdown I recommend to `keep_metadata` especially if you're doing resume training and you have metadata and bucket latents file from previous training like `.npz`, `.txt`, `.caption`, and `json`.\n",
        "keep_metadata = True #@param {'type':'boolean'}\n",
        "\n",
        "# List of supported file types\n",
        "if keep_metadata == True:\n",
        "  supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".caption\", \".npz\", \".txt\", \".json\"]\n",
        "else:\n",
        "  supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\"]\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for item in test:\n",
        "    # Extract the file extension from the file name\n",
        "    file_ext = os.path.splitext(item)[1]\n",
        "    # If the file extension is not in the list of supported types, delete the file\n",
        "    if file_ext not in supported_types:\n",
        "        # Print a message indicating the name of the file being deleted\n",
        "        print(f\"Deleting file {item} from {train_data_dir}\")\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(train_data_dir, item))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ug648uiOvUZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 6.2. Data Annotation\n",
        "%cd {finetune_dir}\n",
        "\n",
        "#@markdown We're using [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) for image captioning and [Waifu Diffusion 1.4 Tagger](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) for image tagging like danbooru.\n",
        "\n",
        "start_labeling = \"WD_1_4_Tagger\" #@param [\"BLIP_Captioning\", \"WD_1_4_Tagger\"]\n",
        "\n",
        "#@markdown BLIP Captioning example: <br>\n",
        "#@markdown `a girl with long hair holding a cellphone`\n",
        "\n",
        "#@markdown Waifu Diffusion 1.4 Tagger example : <br>\n",
        "#@markdown `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background, shirt, black_hair, white_background, closed_mouth, choker, hair_over_one_eye, head_tilt, grey_eyes, black_shirt, floating_hair, black_choker, eyes_visible_through_hair, portrait`\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "if start_labeling == \"BLIP_Captioning\":\n",
        "  !python make_captions.py \\\n",
        "    \"{train_data_dir}\" \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .caption\n",
        "elif start_labeling == \"WD_1_4_Tagger\":\n",
        "  !python tag_images_by_wd14_tagger.py \\\n",
        "    \"{train_data_dir}\" \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .txt\n",
        "else:\n",
        "  pass\n",
        "    "
      ],
      "metadata": {
        "cellView": "form",
        "id": "nvPyH-G_Qdha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VII. Training Model\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNbl3O_NSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.1. Define Important folder\n",
        "from google.colab import drive\n",
        "%store -r\n",
        "\n",
        "v2 = False #@param {type:\"boolean\"}\n",
        "v_parameterization = False #@param {type:\"boolean\"}\n",
        "project_name = \"masabodo\" #@param {type:\"string\"}\n",
        "pretrained_model_name_or_path = \"/content/pre_trained_model/Anything-v3-1.safetensors\" #@param {type:\"string\"}\n",
        "vae = \"\"  #@param {type:\"string\"}\n",
        "#@markdown You need to register parent folder and not where `train_data_dir` located\n",
        "train_folder_directory = \"/content/dreambooth/train_data\" #@param {'type':'string'}\n",
        "%store train_folder_directory\n",
        "reg_folder_directory = \"/content/dreambooth/reg_data\" #@param {'type':'string'}\n",
        "%store reg_folder_directory\n",
        "output_dir = \"/content/dreambooth/output\" #@param {'type':'string'}\n",
        "resume_path =\"\"\n",
        "\n",
        "#@markdown This will ignore `output_dir` defined above, and changed to `/content/drive/MyDrive/fine_tune/output` by default\n",
        "output_to_drive = False #@param {'type':'boolean'}\n",
        "\n",
        "if output_to_drive:\n",
        "  output_dir = \"/content/drive/MyDrive/dreambooth/output\"\n",
        "\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    drive.mount('/content/drive')  \n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "#V2 Inference\n",
        "inference_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/\"\n",
        "\n",
        "if v2 and not v_parameterization:\n",
        "  inference_url += \"v2-inference.yaml\"\n",
        "if v2 and v_parameterization:\n",
        "  inference_url += \"v2-inference-v.yaml\"\n",
        "\n",
        "try:\n",
        "  if v2:\n",
        "    !wget {inference_url} -O {output_dir}/{project_name}.yaml\n",
        "    print(\"File successfully downloaded\")\n",
        "except:\n",
        "  print(\"There was an error downloading the file. Please check the URL and try again.\")"
      ],
      "metadata": {
        "id": "H_Q23fUEJhnC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.2. Define Specific LoRA Training parameter\n",
        "%store -r\n",
        "\n",
        "#@markdown ## LoRA - Low Rank Adaptation Dreambooth\n",
        "\n",
        "#@markdown If you're following `https://rentry.org/lora_train` guide, they set `network_dim` to `128`, you can change it yourself or use default parameter\n",
        "network_dim = 128 #@param {'type':'number'}\n",
        "#@markdown For LoRA weight scaling. Not sure what this is, but if you want to get the same result before update, you need to set `network_alpha` the same as `network_dim`.\n",
        "network_alpha = 128 #@param {'type':'number'}\n",
        "network_module = \"networks.lora\"\n",
        "\n",
        "#@markdown `Specify network_weights for resume training`\n",
        "network_weights = \"\" #@param {'type':'string'}\n",
        "\n",
        "#@markdown When neither `--network_train_unet_only` nor `--network_train_text_encoder_only` is specified (default), both Text Encoder and U-Net LoRA modules are enabled.\n",
        "network_train_on = \"both\" #@param ['both','unet_only', 'text_encoder_only'] {'type':'string'}\n",
        "\n",
        "#@markdown Some people recommend to set `text_encoder_lr` at lower learning rate such as `5e-5`\n",
        "unet_lr = 1e-4 #@param {'type':'number'}\n",
        "text_encoder_lr = 5e-5 #@param {'type':'number'}\n",
        "lr_scheduler = \"constant\" #@param  [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"] {allow-input: false}\n",
        "\n",
        "#@markdown You dont need to change this part below if you're not using `cosine_with_restart`\n",
        "lr_scheduler_num_cycles = 1 #@param {'type':'number'}\n",
        "lr_scheduler_power = 1 #@param {'type':'number'}\n",
        "\n",
        "#@markdown Tick if you dont want to save metadata in output model\n",
        "no_metadata = False #@param {type:\"boolean\"}\n",
        "training_comment = \"this comment will stored to metadata\" #@param {'type':'string'}\n",
        "\n",
        "print(\"Load network module :\", network_module)\n",
        "print(f\"{network_module} dim set to :\", network_dim)\n",
        "print(f\"{network_module} alpha set to :\", network_alpha)\n",
        "\n",
        "if network_weights == \"\":\n",
        "  print(\"No LoRA weight loaded\")\n",
        "else:\n",
        "  if os.path.exists(network_weights):\n",
        "    print(\"Load LoRA weight: \", network_weights)\n",
        "  else:\n",
        "    print(f\"{network_weights} didn't exist\")\n",
        "    network_weights =\"\"\n",
        "\n",
        "if network_train_on == \"unet_only\":\n",
        "  print(\"Enable LoRA for U-Net\")\n",
        "  print(\"Disable LoRA for Text Encoder\")\n",
        "  print(\"UNet learning rate: \", unet_lr)\n",
        "elif network_train_on == \"text_encoder_only\":\n",
        "  print(\"Disable LoRA for U-Net\")\n",
        "  print(\"Enable LoRA for Text Encoder\")\n",
        "  print(\"Text encoder learning rate: \", text_encoder_lr)\n",
        "else:\n",
        "  print(\"Enable LoRA for U-Net\")\n",
        "  print(\"Enable LoRA for Text Encoder\")\n",
        "  print(\"UNet learning rate: \", unet_lr)\n",
        "  print(\"Text encoder learning rate: \", text_encoder_lr)\n",
        "\n",
        "print(\"Learning rate Scheduler:\", lr_scheduler)\n",
        "if lr_scheduler == \"cosine_with_restarts\":\n",
        "  print(\"- num cycles: \", lr_scheduler_num_cycles)\n",
        "  print(\"- power: \", lr_scheduler_power)\n",
        "\n",
        "if not no_metadata:\n",
        "  if training_comment: \n",
        "    print(\"Training comment:\", training_comment)\n",
        "else:\n",
        "  print(\"Metadata won't be saved\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5P-QVvHMUrFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "import textwrap\n",
        "import yaml\n",
        "\n",
        "%store -r\n",
        "\n",
        "#@title ## 7.3. Start LoRA Dreambooth\n",
        "#@markdown ### Define Parameter\n",
        "\n",
        "train_batch_size = 4 #@param {type:\"number\"}\n",
        "num_epochs = 1 #@param {type:\"number\"}\n",
        "caption_extension = '.txt' #@param {'type':'string'}\n",
        "mixed_precision = \"fp16\" #@param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "save_precision = \"fp16\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_n_epochs_type = \"save_n_epoch_ratio\" #@param [\"save_every_n_epochs\", \"save_n_epoch_ratio\"] {allow-input: false}\n",
        "save_n_epochs_type_value = 5 #@param {type:\"number\"}\n",
        "save_model_as = \"safetensors\" #@param [\"ckpt\", \"pt\", \"safetensors\"] {allow-input: false}\n",
        "resolution = 512 #@param {type:\"number\"}\n",
        "max_token_length = 225 #@param {type:\"number\"}\n",
        "clip_skip = 2 #@param {type:\"number\"}\n",
        "use_8bit_adam = True #@param {type:\"boolean\"}\n",
        "gradient_checkpointing = False #@param {type:\"boolean\"}\n",
        "gradient_accumulation_steps = 1 #@param {type:\"number\"}\n",
        "seed = 0 #@param {type:\"number\"}\n",
        "logging_dir = \"/content/dreambooth/logs\"\n",
        "log_prefix = project_name\n",
        "additional_argument = \"--shuffle_caption --xformers --enable_bucket --cache_latents\" #@param {type:\"string\"}\n",
        "print_hyperparameter = True #@param {type:\"boolean\"}\n",
        "prior_loss_weight =1.0\n",
        "%cd {repo_dir}\n",
        "\n",
        "train_command=f\"\"\"\n",
        "accelerate launch --config_file={accelerate_config} --num_cpu_threads_per_process=8 train_network.py \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "  --network_dim={network_dim} \\\n",
        "  --network_alpha={network_alpha} \\\n",
        "  --network_module={network_module} \\\n",
        "  {\"--network_weights=\" + network_weights if network_weights else \"\"} \\\n",
        "  {\"--network_train_unet_only\" if network_train_on == \"unet_only\" else \"\"} \\\n",
        "  {\"--network_train_text_encoder_only\" if network_train_on == \"text_encoder_only\" else \"\"} \\\n",
        "  {\"--unet_lr=\" + format(unet_lr) if unet_lr else \"\"} \\\n",
        "  {\"--text_encoder_lr=\" + format(text_encoder_lr) if text_encoder_lr else \"\"} \\\n",
        "  {\"--no_metadata\" if no_metadata else \"\"} \\\n",
        "  {\"--training_comment=\" + \"training_comment\" if training_comment and not no_metadata else \"\"} \\\n",
        "  --lr_scheduler={lr_scheduler} \\\n",
        "  {\"--lr_scheduler_num_cycles=\" + format(lr_scheduler_num_cycles) if lr_scheduler == \"cosine_with_restarts\" else \"\"} \\\n",
        "  {\"--lr_scheduler_power=\" + format(lr_scheduler_power) if lr_scheduler == \"cosine_with_restarts\" else \"\"} \\\n",
        "  --pretrained_model_name_or_path={pretrained_model_name_or_path} \\\n",
        "  {\"--vae=\" + vae if vae else \"\"} \\\n",
        "  --caption_extension={caption_extension} \\\n",
        "  --train_data_dir={train_folder_directory} \\\n",
        "  --reg_data_dir={reg_folder_directory} \\\n",
        "  --output_dir={output_dir} \\\n",
        "  --prior_loss_weight={prior_loss_weight} \\\n",
        "  {\"--resume=\" + resume_path if resume_path else \"\"} \\\n",
        "  {\"--output_name=\" + project_name if project_name else \"\"} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --save_precision={save_precision} \\\n",
        "  {\"--save_every_n_epochs=\" + format(save_n_epochs_type_value) if save_n_epochs_type==\"save_every_n_epochs\" else \"\"} \\\n",
        "  {\"--save_n_epoch_ratio=\" + format(save_n_epochs_type_value) if save_n_epochs_type==\"save_n_epoch_ratio\" else \"\"} \\\n",
        "  --save_model_as={save_model_as} \\\n",
        "  --resolution={resolution} \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --max_token_length={max_token_length} \\\n",
        "  {\"--use_8bit_adam\" if use_8bit_adam else \"\"} \\\n",
        "  --max_train_epochs={num_epochs} \\\n",
        "  {\"--seed=\" + format(seed) if seed > 0 else \"\"} \\\n",
        "  {\"--gradient_checkpointing\" if gradient_checkpointing else \"\"} \\\n",
        "  {\"--gradient_accumulation_steps=\" + format(gradient_accumulation_steps) } \\\n",
        "  {\"--clip_skip=\" + format(clip_skip) if v2 == False else \"\"} \\\n",
        "  --logging_dir={logging_dir} \\\n",
        "  --log_prefix={log_prefix} \\\n",
        "  {additional_argument}\n",
        "  \"\"\"\n",
        "\n",
        "debug_params = [\"v2\", \\\n",
        "                \"v_parameterization\", \\\n",
        "                \"network_dim\", \\\n",
        "                \"network_alpha\", \\\n",
        "                \"network_module\", \\\n",
        "                \"network_weights\", \\\n",
        "                \"network_train_on\", \\\n",
        "                \"unet_lr\", \\\n",
        "                \"text_encoder_lr\", \\\n",
        "                \"no_metadata\", \\\n",
        "                \"training_comment\", \\\n",
        "                \"lr_scheduler\", \\\n",
        "                \"lr_scheduler_num_cycles\", \\\n",
        "                \"lr_scheduler_power\", \\\n",
        "                \"pretrained_model_name_or_path\", \\\n",
        "                \"vae\", \\\n",
        "                \"caption_extension\", \\\n",
        "                \"train_folder_directory\", \\\n",
        "                \"reg_folder_directory\", \\\n",
        "                \"output_dir\", \\\n",
        "                \"prior_loss_weight\", \\\n",
        "                \"resume_path\", \\\n",
        "                \"project_name\", \\\n",
        "                \"mixed_precision\", \\\n",
        "                \"save_precision\", \\\n",
        "                \"save_n_epochs_type\", \\\n",
        "                \"save_n_epochs_type_value\", \\\n",
        "                \"save_model_as\", \\\n",
        "                \"resolution\", \\\n",
        "                \"train_batch_size\", \\\n",
        "                \"max_token_length\", \\\n",
        "                \"use_8bit_adam\", \\\n",
        "                \"num_epochs\", \\\n",
        "                \"seed\", \\\n",
        "                \"gradient_checkpointing\", \\\n",
        "                \"gradient_accumulation_steps\", \\\n",
        "                \"clip_skip\", \\\n",
        "                \"logging_dir\", \\\n",
        "                \"log_prefix\", \\\n",
        "                \"additional_argument\"]\n",
        "\n",
        "if print_hyperparameter:\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Hyperparameter\", \"Value\"]\n",
        "    for params in debug_params:\n",
        "        if params != \"\":\n",
        "            if globals()[params] == \"\":\n",
        "                value = \"False\"\n",
        "            else:\n",
        "                value = globals()[params]\n",
        "            table.add_row([params, value])\n",
        "    table.align = \"l\"\n",
        "    print(table)\n",
        "\n",
        "    arg_list = train_command.split()\n",
        "    mod_train_command = {'command': arg_list}\n",
        "    \n",
        "    train_folder = os.path.dirname(output_dir)\n",
        "    \n",
        "    # save the YAML string to a file\n",
        "    with open(str(train_folder)+'/dreamboothlora_cmd.yaml', 'w') as f:\n",
        "        yaml.dump(mod_train_command, f)\n",
        "\n",
        "f = open(\"./train.sh\", \"w\")\n",
        "f.write(train_command)\n",
        "f.close()\n",
        "!chmod +x ./train.sh\n",
        "!./train.sh"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GIvfcS1pOrGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIII. Testing"
      ],
      "metadata": {
        "id": "reMcN0bM_o53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 8.1 Validating LoRA Weights\n",
        "\n",
        "#@markdown Now you can check if your LoRA trained properly.\n",
        "network_weights = \"/content/dreambooth/output/masabodo.safetensors\" #@param {'type':'string'}\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "def main(file):\n",
        "  print(f\"loading: {file}\")\n",
        "  if os.path.splitext(file)[1] == '.safetensors':\n",
        "    sd = load_file(file)\n",
        "  else:\n",
        "    sd = torch.load(file, map_location='cuda')\n",
        "\n",
        "  values = []\n",
        "\n",
        "  keys = list(sd.keys())\n",
        "  for key in keys:\n",
        "    if 'lora_up' in key or 'lora_down' in key:\n",
        "      values.append((key, sd[key]))\n",
        "  print(f\"number of LoRA modules: {len(values)}\")\n",
        "\n",
        "  for key, value in values:\n",
        "    value = value.to(torch.float32)\n",
        "    print(f\"{key},{torch.mean(torch.abs(value))},{torch.min(torch.abs(value))}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main(network_weights)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rt7CKCog_4tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 8.2 Inference\n",
        "%store -r\n",
        "\n",
        "#@markdown LoRA Config\n",
        "network_weights = \"/content/dreambooth/output/masabodo.safetensors\" #@param {'type':'string'}\n",
        "network_module = \"networks.lora\"\n",
        "network_mul = 0.6 #@param {'type':'number'}\n",
        "\n",
        "#@markdown Other Config\n",
        "v2 = False #@param {type:\"boolean\"}\n",
        "v_parameterization = False #@param {type:\"boolean\"}\n",
        "prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\" #@param {type: \"string\"}\n",
        "negative = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type: \"string\"}\n",
        "model = \"/content/pre_trained_model/Anything-v3-1.safetensors\" #@param {type: \"string\"}\n",
        "vae = \"\" #@param {type: \"string\"}\n",
        "outdir = \"/content/tmp\" #@param {type: \"string\"}\n",
        "scale = 12 #@param {type: \"slider\", min: 1, max: 40}\n",
        "sampler = \"ddim\" #@param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "steps = 28 #@param {type: \"slider\", min: 1, max: 100}\n",
        "precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "width = 512 #@param {type: \"integer\"}\n",
        "height = 768 #@param {type: \"integer\"}\n",
        "images_per_prompt = 4 #@param {type: \"integer\"}\n",
        "batch_size = 4 #@param {type: \"integer\"}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 40}\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "\n",
        "final_prompt = f\"{prompt} --n {negative}\"\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "!python gen_img_diffusers.py \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "  --network_module={network_module} \\\n",
        "  --network_weight={network_weights} \\\n",
        "  --network_mul={network_mul} \\\n",
        "  --ckpt={model} \\\n",
        "  --outdir={outdir} \\\n",
        "  --xformers \\\n",
        "  {\"--vae=\" + vae if vae else \"\"} \\\n",
        "  --{precision} \\\n",
        "  --W={width} \\\n",
        "  --H={height} \\\n",
        "  {\"--seed=\" + format(seed) if seed > 0 else \"\"} \\\n",
        "  --scale={scale} \\\n",
        "  --sampler={sampler} \\\n",
        "  --steps={steps} \\\n",
        "  --max_embeddings_multiples=3 \\\n",
        "  --batch_size={batch_size} \\\n",
        "  --images_per_prompt={images_per_prompt} \\\n",
        "  {\"--clip_skip=\" + format(clip_skip) if v2 == False else \"\"} \\\n",
        "  --prompt=\"{final_prompt}\"\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FKBrTDPrcNjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 8.3. Visualize loss graph (Optional)\n",
        "training_logs_path = \"/content/dreambooth/logs\" #@param {type : \"string\"}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {training_logs_path}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TLSQslfFcQde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IX. Extras"
      ],
      "metadata": {
        "id": "N6ckzE2GWudi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 9.1. Compressing model or dataset\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "zip_module = \"zipfile\" #@param [\"zipfile\", \"shutil\", \"pyminizip\", \"zip\"]\n",
        "directory_to_zip = '/content/dreambooth/output' #@param {type: \"string\"}\n",
        "output_filename = '/content/output.zip' #@param {type: \"string\"}\n",
        "password = \"\" #@param {type: \"string\"}\n",
        "\n",
        "if zip_module == \"zipfile\":\n",
        "    with zipfile.ZipFile(output_filename, 'w') as zip:\n",
        "        for directory_to_zip, dirs, files in os.walk(directory_to_zip):\n",
        "            for file in files:\n",
        "                zip.write(os.path.join(directory_to_zip, file))\n",
        "elif zip_module == \"shutil\":\n",
        "    shutil.make_archive(output_filename, 'zip', directory_to_zip)\n",
        "elif zip_module == \"pyminizip\":\n",
        "    !pip install pyminizip\n",
        "    import pyminizip\n",
        "    for root, dirs, files in os.walk(directory_to_zip):\n",
        "        for file in files:\n",
        "            pyminizip.compress(os.path.join(root, file), \"\", os.path.join(\"*\",output_filename), password, 5)\n",
        "elif zip_module == \"zip\":\n",
        "    !zip -rv -q -j {output_filename} {directory_to_zip}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rLdEpPKTbI1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X. Deployment"
      ],
      "metadata": {
        "id": "nyIl9BhNXKUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 10.1. Define your Huggingface Repo\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown #### If your model/dataset repo didn't exist, it will automatically create your repo.\n",
        "model_name = \"your-model-name\" #@param{type:\"string\"}\n",
        "dataset_name = \"your-dataset-name\" #@param{type:\"string\"}\n",
        "make_this_model_private = True #@param{type:\"boolean\"}\n",
        "\n",
        "model_repo = user['name']+\"/\"+model_name.strip()\n",
        "datasets_repo = user['name']+\"/\"+dataset_name.strip()\n",
        "\n",
        "if model_name != \"\":\n",
        "  try:\n",
        "      validate_repo_id(model_repo)\n",
        "      api.create_repo(repo_id=model_repo, \n",
        "                      private=make_this_model_private)\n",
        "      print(\"Model Repo didn't exists, creating repo\")\n",
        "      print(\"Model Repo: \",model_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Model Repo: {model_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "if dataset_name != \"\":\n",
        "  try:\n",
        "      validate_repo_id(datasets_repo)\n",
        "      api.create_repo(repo_id=datasets_repo,\n",
        "                      repo_type=\"dataset\",\n",
        "                      private=make_this_model_private)\n",
        "      print(\"Dataset Repo didn't exists, creating repo\")\n",
        "      print(\"Dataset Repo\",datasets_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Dataset repo: {datasets_repo} exists, skipping create repo\\n\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTXsM170GUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2. Upload with `hf_hub`"
      ],
      "metadata": {
        "id": "yUNkWbMHcbiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 10.2.1. Upload LoRA\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown #### This will be uploaded to model repo\n",
        "\n",
        "model_path = \"/content/dreambooth/output/masabodo.safetensors\" #@param {type :\"string\"}\n",
        "path_in_repo = \"masabodo.safetensors\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"feat: upload lora model\" #@param {type :\"string\"}\n",
        "\n",
        "def upload_model(model_paths, is_folder :bool):\n",
        "  path_obj = Path(model_paths)\n",
        "  trained_model = path_obj.parts[-1]\n",
        "  \n",
        "  if is_folder == True:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "    \n",
        "    api.upload_folder(\n",
        "        folder_path=model_paths,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\"\n",
        "        )\n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/tree/main\\n\")\n",
        "  else: \n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "            \n",
        "    api.upload_file(\n",
        "        path_or_fileobj=model_paths,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        )\n",
        "        \n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/blob/main/\"+trained_model+\"\\n\")\n",
        "      \n",
        "def upload():\n",
        "    if model_path.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
        "      upload_model(model_path, False)\n",
        "    else:\n",
        "      upload_model(model_path, True)\n",
        "\n",
        "upload()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CIeoJA-eO-8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 10.2.2. Upload Dataset\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown #### This will be compressed to zip and  uploaded to datasets repo, leave it empty if not necessary\n",
        "train_data_path = \"/content/dreambooth/train_style/5_mksks style\" #@param {type :\"string\"}\n",
        "#@markdown ##### `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/dreambooth/logs\" #@param {type :\"string\"}\n",
        "#@markdown #### Delete zip after upload\n",
        "delete_zip = True #@param {type :\"boolean\"}\n",
        "\n",
        "if project_name !=\"\":\n",
        "  tmp_dataset = \"/content/dreambooth/\"+project_name+\"_dataset\"\n",
        "else:\n",
        "  tmp_dataset = \"/content/dreambooth/tmp_dataset\"\n",
        "\n",
        "dataset_zip = tmp_dataset + \".zip\"\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"feat: upload lora dataset\" #@param {type :\"string\"}\n",
        "\n",
        "os.makedirs(tmp_dataset)\n",
        "\n",
        "def upload_dataset(dataset_paths, is_zip : bool):\n",
        "  path_obj = Path(dataset_paths)\n",
        "  dataset_name = path_obj.parts[-1]\n",
        "\n",
        "  if is_zip:\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=dataset_paths,\n",
        "        path_in_repo=dataset_name,\n",
        "        repo_id=datasets_repo,\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=commit_message,\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/blob/main/\"+dataset_name+\"\\n\")\n",
        "  else:\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=dataset_paths,\n",
        "        path_in_repo=dataset_name,\n",
        "        repo_id=datasets_repo,\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\",\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+dataset_name+\"\\n\")\n",
        "  \n",
        "def zip_file(tmp):\n",
        "    zipfiles = tmp + \".zip\" \n",
        "    with zipfile.ZipFile(zipfiles, 'w') as zip:\n",
        "      for tmp, dirs, files in os.walk(tmp):\n",
        "          for file in files:\n",
        "              zip.write(os.path.join(tmp, file))\n",
        "\n",
        "def move(src_path, dst_path, is_metadata: bool):\n",
        "  files_to_move = [\"meta_cap.json\", \\\n",
        "                   \"meta_cap_dd.json\", \\\n",
        "                   \"meta_lat.json\", \\\n",
        "                   \"meta_clean.json\", \\\n",
        "                   \"meta_final.json\"]\n",
        "\n",
        "  if os.path.exists(src_path):\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "  if is_metadata:\n",
        "    parent_meta_path = os.path.dirname(src_path)\n",
        "\n",
        "    for filename in os.listdir(parent_meta_path):\n",
        "      file_path = os.path.join(parent_meta_path, filename)\n",
        "      if filename in files_to_move:\n",
        "        shutil.move(file_path, dst_path)\n",
        "\n",
        "def upload():\n",
        "  if train_data_path !=\"\":\n",
        "    move(train_data_path, tmp_dataset, False)\n",
        "    zip_file(tmp_dataset)\n",
        "    upload_dataset(dataset_zip, True)\n",
        "    \n",
        "  if logs_path !=\"\":\n",
        "    upload_dataset(logs_path, False)\n",
        "\n",
        "upload()\n",
        "\n",
        "if delete_zip:\n",
        "  os.remove(dataset_zip)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IW-hS9jnmf-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3. Commit using Git (Alternative)"
      ],
      "metadata": {
        "id": "CKZpg4keWS5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 10.3.1. Clone Repository\n",
        "\n",
        "clone_model = True #@param {'type': 'boolean'}\n",
        "clone_dataset = True #@param {'type': 'boolean'}\n",
        "\n",
        "!git lfs install --skip-smudge\n",
        "!export GIT_LFS_SKIP_SMUDGE=1\n",
        "\n",
        "if clone_model:\n",
        "  !git clone https://huggingface.co/{model_repo} /content/{model_name}\n",
        "clone_dataset\n",
        "  !git clone https://huggingface.co/datasets/{datasets_repo} /content/{dataset_name}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6nBlrOrytO9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 10.3.2. Commit using Git \n",
        "%cd {root_dir}\n",
        "\n",
        "#@markdown Tick which repo you want to commit\n",
        "commit_model = True #@param {'type': 'boolean'}\n",
        "commit_dataset = True #@param {'type': 'boolean'}\n",
        "\n",
        "#@markdown Set **git commit identity**\n",
        "email = \"your-email-here\" #@param {'type': 'string'}\n",
        "name = \"your-username-here\" #@param {'type': 'string'}\n",
        "#@markdown Set **commit message**\n",
        "commit_m = \"feat: upload model and dataset\" #@param {'type': 'string'}\n",
        "\n",
        "!git config --global user.email \"{email}\"\n",
        "!git config --global user.name \"{name}\"\n",
        "\n",
        "def commit(repo_folder, commit_message):\n",
        "  %cd {root_dir}/{repo_folder}\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git commit -m \"{commit_message}\"\n",
        "  !git push\n",
        "\n",
        "commit(model_name, commit_m)\n",
        "commit(dataset_name, commit_m)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7bJev4PzOFFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}