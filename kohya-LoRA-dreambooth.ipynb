{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kohya LoRA Dreambooth"
      ],
      "metadata": {
        "id": "slgjeYgd6pWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted to Google Colab based on [kohya-ss/sd-script](https://github.com/kohya-ss/sd-scripts)<br>\n",
        "Adapted to Google Colab by [Linaqruf](https://github.com/Linaqruf)<br>\n",
        "You can find latest notebook update [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Install Kohya Trainer"
      ],
      "metadata": {
        "id": "tTVqCAgSmie4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.1. Clone Kohya Trainer\n",
        "#@markdown Clone the Kohya Trainer repository from GitHub and check for updates\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "def clone_kohya_trainer():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir('/content/kohya-trainer'):\n",
        "    %cd /content/kohya-trainer\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/Linaqruf/kohya-trainer\n",
        "\n",
        "# Clone or update the Kohya Trainer repository\n",
        "clone_kohya_trainer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.2. Installing Dependencies\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "import os\n",
        "\n",
        "Install_xformers = True #@param {'type':'boolean'}\n",
        "  \n",
        "def install_dependencies():\n",
        "  #@markdown This will install required Python packages\n",
        "  !pip install --upgrade -r requirements.txt\n",
        "  !pip install -U gallery-dl\n",
        "  !pip install imjoy_elfinder\n",
        "\n",
        "  if Install_xformers:\n",
        "    !pip install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "# Install dependencies\n",
        "install_dependencies()\n",
        "\n",
        "#@markdown After Accelerate updated its version to 0.15.0, you can't manually input the config using\n",
        "#@markdown `!accelerate config` in Google Colab. Instead, a `config.yaml` file will be generated by\n",
        "#@markdown the `write_basic_config()` function. You can find the file [here](/content/kohya-trainer/accelerate_config/config.yaml) after installation.\n",
        "#@markdown if you want to modify it.\n",
        "\n",
        "from accelerate.utils import write_basic_config\n",
        "accelerate_config = \"/content/kohya-trainer/accelerate_config/config.yaml\"\n",
        "write_basic_config(save_location = accelerate_config) # Write a config file"
      ],
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Sign-in to Cloud Service"
      ],
      "metadata": {
        "id": "qt9EJv5gQXuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 1.3.1. Login to Huggingface hub\n",
        "from huggingface_hub import login\n",
        "\n",
        "#@markdown 1. Of course, you need a Huggingface account first.\n",
        "#@markdown 2. To create a huggingface token, go to [this link](https://huggingface.co/settings/tokens), then `create new token` or copy available token with the `Write` role.\n",
        "\n",
        "write_token = \"YOUR-TOKEN-HERE\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rl2zERHbBQ9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 1.3.2. Mount Drive\n",
        "from google.colab import drive\n",
        "\n",
        "mount_drive = True #@param {type: \"boolean\"}\n",
        "\n",
        "if mount_drive:\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sKL38-WmQsLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.4. Install Special File Explorer for Colab\n",
        "#@markdown this will work real-time even though you're running other cells\n",
        "\n",
        "import threading\n",
        "from google.colab import output\n",
        "from imjoy_elfinder.app import main\n",
        "\n",
        "# start imjoy-elfinder server\n",
        "thread = threading.Thread(target=main, args=[[\"--root-dir=/content\", \"--port=8765\"]])\n",
        "thread.start()\n",
        "\n",
        "open_in_new_tab = True #@param {type:\"boolean\"}\n",
        "\n",
        "if open_in_new_tab:\n",
        "  # open imjoy-elfinder in a new tab\n",
        "  output.serve_kernel_port_as_window(8765)\n",
        "else:\n",
        "  # view the \n",
        "  output.serve_kernel_port_as_iframe(8765, height='500')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1d98CZtHrizz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gob9_OwTlwh"
      },
      "source": [
        "# II. Pretrained Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SoucgZQ6jgPQ"
      },
      "outputs": [],
      "source": [
        "#@title ## 2.1. Install Pretrained Model \n",
        "%cd /content/\n",
        "import os\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists('pre_trained_model'):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs('pre_trained_model')\n",
        "\n",
        "#@title Install Pre-trained Model \n",
        "\n",
        "installModels = []\n",
        "installVae = []\n",
        "installVaeArgs = []\n",
        "installv2Models = []\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available pretrained model to download:\n",
        "#@markdown ### SD1.x model\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3-better-vae/resolve/main/any-v3-fp32-better-vae.ckpt\", \\\n",
        "            \"https://huggingface.co/Rasgeath/self_made_sauce/resolve/main/Kani-anime-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/hesw23168/SD-Elysium-Model/resolve/main/Elysium_Anime_V2.ckpt\", \\\n",
        "            \"https://huggingface.co/prompthero/openjourney-v2/resolve/main/openjourney-v2.ckpt\", \\\n",
        "            \"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/resolve/main/dreamlike-diffusion-1.0.ckpt\", \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Anything-V3\", \\\n",
        "             \"Anything-V3-better-vae\", \\\n",
        "             \"Kani-anime\", \\\n",
        "             \"Elysium-anime-V2\", \\\n",
        "             \"OpenJourney-V2\", \\\n",
        "             \"Dreamlike-diffusion-V1-0\", \\\n",
        "             \"Stable-Diffusion-v1-5\"]\n",
        "modelName = \"Anything-V3-better-vae\" #@param [\"\", \"Animefull-final-pruned\", \"Anything-V3\", \"Anything-V3-better-vae\", \"Kani-anime\", \"Elysium-anime-V2\", \"OpenJourney-V2\", \"Dreamlike-diffusion-V1-0\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "#@markdown ### SD2.x model\n",
        "v2ModelUrl = [\"\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e1.ckpt\"]\n",
        "v2ModelList = [\"\", \\\n",
        "              \"stable-diffusion-2-1-base\", \\\n",
        "              \"stable-diffusion-2-1-768v\", \\\n",
        "              \"waifu-diffusion-1-4-anime-e-1\"]\n",
        "v2ModelName = \"\" #@param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"waifu-diffusion-1-4-anime-e-1\"]\n",
        "\n",
        "#@markdown ### Custom model\n",
        "#@markdown The model URL should be a direct download link.\n",
        "\n",
        "customName = \"\" #@param {'type': 'string'}\n",
        "customUrl = \"\" #@param {'type': 'string'}\n",
        "#@markdown Change this part with your own huggingface token to download private model\n",
        "hf_token = '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' #@param {type:\"string\"}\n",
        "user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "#@markdown Select one of the VAEs to download, select `none` for not download VAE:\n",
        "vaeUrl = [\"\", \\\n",
        "          \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animevae/animevae.pt\", \\\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\", \\\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "vaeList = [\"none\", \\\n",
        "           \"anime.vae.pt\", \\\n",
        "           \"waifudiffusion.vae.pt\", \\\n",
        "           \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"none\" #@param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "# Check if user has specified a custom model\n",
        "if customName != \"\" and customUrl != \"\":\n",
        "  # Add custom model to list of models to install\n",
        "  installModels.append((customName, customUrl))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if modelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if v2ModelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "def install_aria():\n",
        "  # Install aria2 if it is not already installed\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  if url.endswith(\".ckpt\"):\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name) + \".ckpt\"\n",
        "  elif url.endswith(\".safetensors\"):\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name) + \".safetensors\"\n",
        "  elif url.endswith(\".pt\"):\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name)\n",
        "  else:\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name) + \".ckpt\"\n",
        "\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    # Use gdown to download file from Google Drive\n",
        "    !gdown --fuzzy -O  {dst} \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    # Use aria2c to download file from magnet link\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o {dst} \"{url}\"\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    # Use wget to download file from Hugging Face\n",
        "    !wget -c --header={user_header} \"{url}\" -O {dst}\n",
        "  else:\n",
        "    # Use wget to download file from URL\n",
        "    !wget -c \"{url}\" -O {dst}\n",
        "\n",
        "def install_checkpoint():\n",
        "  # Iterate through list of models to install\n",
        "  for model in installModels:\n",
        "    # Call install function for each model\n",
        "    install(model[0], model[1])\n",
        "\n",
        "  # Iterate through list of models to install\n",
        "  for v2model in installv2Models:\n",
        "    # Call install function for each v2model\n",
        "    install(v2model[0], v2model[1])\n",
        "    \n",
        "  if vaeName != \"none\":\n",
        "    for vae in installVae:\n",
        "      install(vae[0], vae[1])\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "# Call install_checkpoint function to download all models in the list\n",
        "install_checkpoint()\n",
        "\n",
        "# Troubleshooting\n",
        "\n",
        "file_path = \"/content/pre_trained_model/waifudiffusion.vae.pt.ckpt\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    # File exists, so rename it\n",
        "    new_file_path = \"/content/pre_trained_model/waifudiffusion.vae.pt\"\n",
        "    os.rename(file_path, new_file_path)\n",
        "else:\n",
        "    # File does not exist, so do nothing\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. Dreambooth Folder Configuration\n",
        "\n",
        "Refer to this note to understand how to create the folder structure. In short it should look like:\n",
        "\n",
        "```\n",
        "<arbitrary folder name>\n",
        "|- <arbitrary class folder name>\n",
        "    |- <repeat count>_<class>\n",
        "|- <arbitrary training folder name>\n",
        "   |- <repeat count>_<token> <class>\n",
        "```\n",
        "\n",
        "Example for `asd dog` where `asd` is the token word and `dog` is the class. In this example the regularization `dog` class images contained in the folder will be repeated only 1 time and the `asd dog` images will be repeated 20 times:\n",
        "\n",
        "```\n",
        "my_asd_dog_dreambooth\n",
        "|- reg_dog\n",
        "    |- 1_dog\n",
        "       `- reg_image_1.png\n",
        "       `- reg_image_2.png\n",
        "       ...\n",
        "       `- reg_image_256.png\n",
        "|- train_dog\n",
        "    |- 20_asd dog\n",
        "       `- dog1.png\n",
        "       ...\n",
        "       `- dog8.png\n",
        "```"
      ],
      "metadata": {
        "id": "d5NJjdXR40ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.1. Create Reg folder \n",
        "# Import the os and shutil modules\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Change the current working directory to /content\n",
        "%cd /content\n",
        "\n",
        "# Define the dreambooth_directory variable\n",
        "dreambooth_directory = \"/content/dreambooth\"\n",
        "\n",
        "# Check if the dreambooth directory already exists\n",
        "if os.path.isdir(dreambooth_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(dreambooth_directory)\n",
        "\n",
        "#@markdown ### Define the reg_folder variable\n",
        "reg_count = 1 #@param {type: \"integer\"}\n",
        "reg_class =\"illustration\" #@param {type: \"string\"}\n",
        "reg_folder = str(reg_count) + \"_\" + reg_class\n",
        "\n",
        "# Define the reg_directory variable\n",
        "reg_directory = f\"{dreambooth_directory}/reg_{reg_class}\"\n",
        "\n",
        "# Check if the reg directory already exists\n",
        "if os.path.isdir(reg_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(reg_directory)\n",
        "\n",
        "# Define the reg_folder_directory variable\n",
        "reg_folder_directory = f\"{reg_directory}/{reg_folder}\"\n",
        "\n",
        "# Check if the reg_folder directory already exists\n",
        "if os.path.isdir(reg_folder_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(reg_folder_directory)"
      ],
      "metadata": {
        "id": "-CVfXAJMSqRi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.2. Create train folder \n",
        "\n",
        "#@markdown ### Define the train_folder variable\n",
        "train_count = 5 #@param {type: \"integer\"}\n",
        "train_token = \"masabodo\" #@param {type: \"string\"}\n",
        "train_class = \"illustration\" #@param {type: \"string\"}\n",
        "#@markdown You can run this cell multiple time to add new concepts\n",
        "\n",
        "train_folder = str(train_count) + \"_\" + train_token + \" \" + train_class\n",
        "\n",
        "# Define the train_directory variable\n",
        "train_directory = f\"{dreambooth_directory}/train_{train_class}\"\n",
        "\n",
        "# Check if the train directory already exists\n",
        "if os.path.isdir(train_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(train_directory)\n",
        "\n",
        "# Define the train_folder_directory variable\n",
        "train_folder_directory = f\"{train_directory}/{train_folder}\"\n",
        "\n",
        "# Check if the train_folder directory already exists\n",
        "if os.path.isdir(train_folder_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(train_folder_directory)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kh7CeDqK4l3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.1. Define Reg and Train Data Directory\n",
        "#@markdown Define where your train data will be located based on folder you created above.\n",
        "#@markdown This folder will be used as the target folder for scraping, tagging, bucketing, and training in the next cell. You can re-run this cell everytime you want to do data preprocessing from other concept \n",
        "\n",
        "import os\n",
        "\n",
        "train_data_dir = \"/content/dreambooth/train_illustration/5_masabodo illustration\" #@param {'type' : 'string'}\n",
        "reg_data_dir = \"/content/dreambooth/reg_illustration/1_illustration\" #@param {'type' : 'string'}\n",
        "\n",
        "print(f\"Your train data directory : {train_data_dir}\")\n",
        "print(f\"Your reg data directory : {reg_data_dir}\")\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C1OKUn9Rs_aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# IV. Data Acquisition\n",
        "\n",
        "You can either upload your dataset to this notebook or use the image scraper below to bulk download images from Danbooru.\n",
        "\n",
        "If you want to use your own dataset, you can upload to colab `local files`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 4.1. Clone Dataset Repository (Optional)\n",
        "#@markdown *Optional but can be useful for resume training process, because you will need that `last-state` folder*\n",
        "%cd /content/\n",
        "\n",
        "#@markdown ### Define Parameters\n",
        "repository_url = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-dataset\"  #@param {'type': 'string'}\n",
        "\n",
        "#@markdown ### Leave it empty if your datasets is on `main` branch\n",
        "branch = \"\" #@param {'type': 'string'}\n",
        "\n",
        "!git lfs install\n",
        "if branch != \"\":\n",
        "  !git clone --branch {branch} {repository_url}\n",
        "else:\n",
        "  !git clone {repository_url}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nEKTgJGg_DGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 4.2. Download dataset (.zip)\n",
        "\n",
        "#@markdown ### Define download parameter\n",
        "zipfile_url = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-tag/resolve/30e18a12b2e42dfe0b9252d85a36ae32251981d4/train_data.zip\" #@param {'type': 'string'}\n",
        "zipfile_path = '/content/train_data.zip' #@param{'type':'string'}\n",
        "\n",
        "try:\n",
        "  # Download dataset\n",
        "  if zipfile_url.startswith(\"https://drive.google.com\"):\n",
        "    # Use gdown to download file from Google Drive\n",
        "    !gdown -o {zipfile_path} --fuzzy {zipfile_url}\n",
        "  elif zipfile_url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    # Use aria2c to download file from magnet link\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o {zipfile_path} {zipfile_url}\n",
        "  elif zipfile_url.startswith(\"https://huggingface.co/\"):\n",
        "    user_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    # Use wget to download file from URL\n",
        "    !wget -c --header={user_header} {zipfile_url} -O {zipfile_path} \n",
        "  else:\n",
        "    !wget -c -O {zipfile_path} {zipfile_url}\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while downloading the file:\", e)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eFFHVTWNZGbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 4.2.1. Unzip dataset (.zip)\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "#@markdown ### Define unzip parameter\n",
        "zipfile_src = '/content/train_data.zip' #@param{'type':'string'}\n",
        "zipfile_dst = '/content/dreambooth/train_illustration/5_masabodo Illustration' #@param{'type':'string'}\n",
        "unzip_module = \"use_7zip\" #@param [\"use_unzip\",\"use_7zip\",\"use_Zipfile\"]\n",
        "\n",
        "#@markdown ### Delete zipfile after unzip process done\n",
        "delete_zipfile = True #@param{'type':'boolean'}\n",
        "\n",
        "if zipfile_src == '':\n",
        "  if zipfile_path != '':\n",
        "    zipfile_src = zipfile_path\n",
        "\n",
        "try:   \n",
        "  if unzip_module == \"use_7zip\":\n",
        "    !7z x $zipfile_src -o$zipfile_dst\n",
        "  elif unzip_module == \"use_unzip\":\n",
        "    !unzip $zipfile_src -d $zipfile_dst\n",
        "  elif unzip_module == \"use_Zipfile\":\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(zipfile_src, 'r') as zip_ref:\n",
        "      zip_ref.extractall(zipfile_dst)\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while unzipping the file:\", e)\n",
        "\n",
        "if delete_zipfile:\n",
        "  path_obj = Path(zipfile_src)\n",
        "  zipfile_name = path_obj.parts[-1]\n",
        "  \n",
        "  if os.path.isdir(zipfile_src):\n",
        "    print(\"\\nThis zipfile doesn't exist or has been deleted \\n\")\n",
        "  else:\n",
        "    os.remove(zipfile_src)\n",
        "    print(f\"\\n{zipfile_name} has been deleted\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iSw3krdkHLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A0t1dfnU5Xkq"
      },
      "outputs": [],
      "source": [
        "#@title ## 4.3. Simple Booru Scraper\n",
        "#@markdown Use gallery-dl to scrape images from a booru site using the specified tags\n",
        "import os\n",
        "import html\n",
        "\n",
        "%cd /content\n",
        "\n",
        "# Set configuration options\n",
        "booru = \"Gelbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "tag1 = \"masabodo\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "download_tags = False #@param {type: \"boolean\"}\n",
        "# Construct the search query\n",
        "if tag2 != \"\":\n",
        "  tags = tag1 + \"+\" + tag2\n",
        "else:\n",
        "  tags = tag1\n",
        "\n",
        "if download_tags == True:\n",
        "  write_tags = \"--write-tags\"\n",
        "else:\n",
        "  write_tags = \"\"\n",
        "\n",
        "# Scrape images from the specified booru site using the given tags\n",
        "if booru.lower() == \"danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tags}\" {write_tags} -D \"{train_data_dir}\"\n",
        "elif booru.lower() == \"gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tags}\" {write_tags} -D \"{train_data_dir}\"\n",
        "else:\n",
        "  print(f\"Unknown booru site: {booru}\")\n",
        "\n",
        "if download_tags == True: \n",
        "  # Get a list of all the .txt files in the folder\n",
        "  files = [f for f in os.listdir(train_data_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "  # Loop through each file\n",
        "  for file in files:\n",
        "      file_path = os.path.join(train_data_dir, file)\n",
        "\n",
        "      # Read the contents of the file\n",
        "      with open(file_path, \"r\") as f:\n",
        "          contents = f.read()\n",
        "\n",
        "      # Decode HTML entities and replace _ with a space\n",
        "      contents = html.unescape(contents)\n",
        "      contents = contents.replace(\"_\", \" \")\n",
        "\n",
        "      # Split the contents on newline characters and join with commas\n",
        "      contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "      # Write the modified contents back to the file\n",
        "      with open(file_path, \"w\") as f:\n",
        "          f.write(contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V. Regularization Image (`OPTIONAL`)\n",
        "You can skip this step and continue your dreambooth training. But you still need to register `reg_folder` later, even though it's empty. It is not necessary, but it can be powerful in preventing overfitting. Additionally, it is useful if your training data is limited."
      ],
      "metadata": {
        "id": "A1-6Tn54YKaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5.1. Download Reg Images\n",
        "#@markdown Download Reg Images provided by community, this will automatically extracted to `reg_data_dir`folder\n",
        "\n",
        "# Function to download and unzip Reg images\n",
        "def reg_images(url):\n",
        "  hf_token = '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' #@param\n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  \n",
        "  # Use wget to download the zip file\n",
        "  !wget -c --header={user_header} \"{url}\" -O \"{reg_data_dir}/reg_image.zip\"\n",
        "\n",
        "  zip_src = os.path.join(f'{reg_data_dir}', f'reg_image.zip')\n",
        "  zip_dst = os.path.join(f'{reg_data_dir}')\n",
        "  # Unzip the downloaded file using shutil\n",
        "  !unzip -j {zip_src} -d {zip_dst}\n",
        "  \n",
        "  # Remove the zip file after extracting\n",
        "  os.remove(os.path.join(f'{reg_data_dir}', f'reg_image.zip'))\n",
        "\n",
        "category = \"1.5k-girl-reg-images\" #@param [\"\", \"1.5k-girl-reg-images\", \"1.5k-boy-reg-images\"]\n",
        "#@markdown Or you can use the file manager on the left panel to upload (drag and drop) to `reg_images` folder (it uploads faster)\n",
        "if category != \"\":\n",
        "  if category == \"1.5k-girl-reg-images\":\n",
        "    reg_images(\"https://huggingface.co/datasets/andite/regularization-images/resolve/main/1.5k-girl-reg-images.zip\")\n",
        "  if category == \"1.5k-boy-reg-images\":\n",
        "    reg_images(\"https://huggingface.co/datasets/andite/regularization-images/resolve/main/1.5k-boy-reg-images.zip\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "p78y_hwOaEsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 5.2. Generate Reg Images\n",
        "V2 = \"none\" #@param [\"none\", \"V2_base\", \"V2_768_v\"] {allow-input: false}\n",
        "prompt = \"masterpiece, best quality, 1girl, solo\" #@param {type: \"string\"}\n",
        "negative = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type: \"string\"}\n",
        "model = \"/content/pre_trained_model/Anything-V3-better-vae.ckpt\" #@param {type: \"string\"}\n",
        "vae = \"\" #@param {type: \"string\"}\n",
        "if vae == \"\":\n",
        "  load_vae =\"\"\n",
        "else:\n",
        "  load_vae =\"--vae \" + str(vae)\n",
        "\n",
        "if V2 == \"V2_base\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model= \"\"\n",
        "elif V2 == \"V2_768_v\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model = \"--v2_parameterization\"\n",
        "else:\n",
        "  v2_model = \"\"\n",
        "  v2_768v_model = \"\"\n",
        "\n",
        "train_num_images = sum(os.path.isfile(os.path.join(train_data_dir, name)) for name in os.listdir(train_data_dir))\n",
        "print(\"You have \" + str(train_num_images) + \" training data.\")\n",
        "\n",
        "if reg_count == 0:\n",
        "  reg_num_images = 0\n",
        "elif train_num_images > 0:\n",
        "  reg_num_images = sum(os.path.isfile(os.path.join(reg_data_dir, name)) for name in os.listdir(reg_data_dir))\n",
        "  print(\"You have \" + str(reg_num_images) + \" regularization images.\")\n",
        "  reg_num_images = (train_count * train_num_images) // reg_count - reg_num_images\n",
        "  print(\"You need \" + str(reg_num_images) + \" regularization images.\")\n",
        "  print(\"This process will generate \" + str(reg_num_images) + \" images left and place them in your regularization image path.\")\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "!python gen_img_diffusers.py\\\n",
        "  {v2_model} \\\n",
        "  {v2_768v_model} \\\n",
        "  --ckpt {model} \\\n",
        "  --outdir {reg_data_dir} \\\n",
        "  --xformers \\\n",
        "  {load_vae} \\\n",
        "  --fp16 \\\n",
        "  --W 768 \\\n",
        "  --H 768 \\\n",
        "  --clip_skip 2 \\\n",
        "  --scale 11 \\\n",
        "  --sampler=\"ddim\" \\\n",
        "  --steps 28 \\\n",
        "  --max_embeddings_multiples 3 \\\n",
        "  --batch_size 4 \\\n",
        "  --images_per_prompt {reg_num_images} \\\n",
        "  --prompt \"{prompt} --n {negative}\"\n",
        "  "
      ],
      "metadata": {
        "cellView": "form",
        "id": "HHjTV_1HKRbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VI. Data Preprocessing"
      ],
      "metadata": {
        "id": "zUiL2sLg7swG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 6.1. Data Cleaning\n",
        "#@markdown This will delete unnecessary files and unsupported media like `.mp4`, `.webm`, and `.gif`\n",
        "\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "\n",
        "#@markdown I recommend to `keep_metadata` especially if you're doing resume training and you have metadata and bucket latents file from previous training like `.npz`, `.txt`, `.caption`, and `json`.\n",
        "keep_metadata = True #@param {'type':'boolean'}\n",
        "\n",
        "# List of supported file types\n",
        "if keep_metadata == True:\n",
        "  supported_types = [\".jpg\", \".jpeg\", \".png\", \".caption\", \".npz\", \".txt\", \"json\"]\n",
        "else:\n",
        "  supported_types = [\".jpg\", \".jpeg\", \".png\"]\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for item in test:\n",
        "    # Extract the file extension from the file name\n",
        "    file_ext = os.path.splitext(item)[1]\n",
        "    # If the file extension is not in the list of supported types, delete the file\n",
        "    if file_ext not in supported_types:\n",
        "        # Print a message indicating the name of the file being deleted\n",
        "        print(f\"Deleting file {item} from {train_data_dir}\")\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(train_data_dir, item))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ug648uiOvUZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 6.2. Data Annotation\n",
        "%cd /content/kohya-trainer/finetune\n",
        "\n",
        "#@markdown We're using [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) for image captioning and [Waifu Diffusion 1.4 Tagger](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) for image tagging like danbooru.\n",
        "\n",
        "start_labeling = \"WD_1_4_Tagger\" #@param [\"BLIP_Captioning\", \"WD_1_4_Tagger\"]\n",
        "\n",
        "#@markdown BLIP Captioning example: <br>\n",
        "#@markdown `a girl with long hair holding a cellphone`\n",
        "\n",
        "#@markdown Waifu Diffusion 1.4 Tagger example : <br>\n",
        "#@markdown `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background, shirt, black_hair, white_background, closed_mouth, choker, hair_over_one_eye, head_tilt, grey_eyes, black_shirt, floating_hair, black_choker, eyes_visible_through_hair, portrait`\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "if start_labeling == \"BLIP_Captioning\":\n",
        "  !python make_captions.py \\\n",
        "    \"{train_data_dir}\" \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .caption\n",
        "elif start_labeling == \"WD_1_4_Tagger\":\n",
        "  !python tag_images_by_wd14_tagger.py \\\n",
        "    \"{train_data_dir}\" \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .txt\n",
        "else:\n",
        "  pass\n",
        "    "
      ],
      "metadata": {
        "cellView": "form",
        "id": "nvPyH-G_Qdha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VII. Training Model\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNbl3O_NSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.1. Define Important folder\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "V2 = \"none\" #@param [\"none\", \"V2_base\", \"V2_768_v\"] {allow-input: false}\n",
        "pre_trained_model_path =\"/content/pre_trained_model/Anything-V3-better-vae.ckpt\" #@param {'type':'string'}\n",
        "vae_to_replace = \"\" #@param {'type': 'string'}\n",
        "#@markdown You need to register parent folder and not where `train_data_dir` or `reg_data_dir` located\n",
        "train_folder_directory = \"/content/dreambooth/train_illustration\" #@param {'type':'string'}\n",
        "reg_folder_directory = \"/content/dreambooth/reg_illustration\" #@param {'type':'string'}\n",
        "output_dir = \"/content/dreambooth/output\" #@param {'type':'string'}\n",
        "\n",
        "#@markdown This will ignore `output_dir` defined above, and changed to `/content/drive/MyDrive/fine_tune/output` by default\n",
        "output_to_drive = False #@param {'type':'boolean'}\n",
        "\n",
        "if output_to_drive:\n",
        "  drive.mount('/content/drive')\n",
        "  output_dir = \"/content/drive/MyDrive/fine_tune/output\"\n",
        "\n",
        "# List of important folder paths\n",
        "folder_paths = [\n",
        "    pre_trained_model_path,\n",
        "    vae_to_replace,\n",
        "    train_folder_directory,\n",
        "    reg_folder_directory,\n",
        "    output_dir,\n",
        "]\n",
        "\n",
        "# Check if each folder exists\n",
        "for folder_path in folder_paths:\n",
        "    if folder_path:\n",
        "        try:\n",
        "            if os.path.exists(folder_path):\n",
        "                print(f'{folder_path} can be used, located at {os.path.dirname(folder_path)}')\n",
        "            else:\n",
        "                pass\n",
        "        except:\n",
        "            print(f'An error occurred while checking if {folder_path} exists')\n",
        "    else:\n",
        "        print('Empty folder path')\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "inference_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/\"\n",
        "\n",
        "if V2 == \"V2_base\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model= \"\"\n",
        "  inference_url += \"v2-inference.yaml\"\n",
        "elif V2 == \"V2_768_v\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model = \"--v2_parameterization\"\n",
        "  inference_url += \"v2-inference-v.yaml\"\n",
        "else:\n",
        "  v2_model = \"\"\n",
        "  v2_768v_model = \"\"\n",
        "\n",
        "try:\n",
        "  if V2 != \"none\":\n",
        "    !wget {inference_url} -O {output_dir}/last.yaml\n",
        "    print(\"File successfully downloaded\")\n",
        "except:\n",
        "  print(\"There was an error downloading the file. Please check the URL and try again.\")\n",
        "\n",
        "if vae_to_replace == \"\":\n",
        "  vae_value =\"\"\n",
        "else:\n",
        "  vae_value =\"--vae \" + str(vae_to_replace)\n",
        "\n"
      ],
      "metadata": {
        "id": "H_Q23fUEJhnC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.2. Define Specific LoRA Training parameter\n",
        "#@markdown ## LoRA - Low Rank Adaptation Dreambooth\n",
        "#@markdown If you're following `https://rentry.org/lora_train` guide, they set `network_dim` to `128`, you can change it yourself or use default parameter\n",
        "network_dim = 128 #@param {'type':'number'}\n",
        "network_module = \"networks.lora\" #@param {'type':'string'}\n",
        "#@markdown `Specify network_weights for resume training`\n",
        "network_weights = \"\" #@param {'type':'string'}\n",
        "network_train_on = \"all\" #@param ['all','unet_only', 'text_encoder_only'] {'type':'string'}\n",
        "#@markdown When neither `--network_train_unet_only` nor `--network_train_text_encoder_only` is specified (default), both Text Encoder and U-Net LoRA modules are enabled.\n",
        "\n",
        "unet_lr = 0 #@param {'type':'number'}\n",
        "text_encoder_lr = 5e-5 #@param {'type':'number'}\n",
        "#@markdown Leave the value to 0 (zero) to use default learning rate. Some people recommend to set `text_encoder_lr` at lower learning rate such as `5e-5`\n",
        "\n",
        "print(\"Load network module :\", network_module)\n",
        "print(f\"{network_module} dim set to :\", network_dim)\n",
        "\n",
        "if network_weights == \"\":\n",
        "  network_weights_value =\"\"\n",
        "  print(\"No LoRA weight loaded\")\n",
        "else:\n",
        "  # Check if directory exists\n",
        "  if os.path.exists(network_weights):\n",
        "    # Create  if it doesn't exist\n",
        "    network_weights_value =\"--network_weights \" + str(network_weights)\n",
        "    print(\"Load LoRA weight: \", network_weights)\n",
        "  else:\n",
        "    network_weights_value =\"\"\n",
        "    print(f\"{network_weights} didn't exist\")\n",
        "\n",
        "if network_train_on == \"unet_only\":\n",
        "  lora_module_to_train = \"--network_train_unet_only\"\n",
        "  print(\"Enable LoRA for U-Net\")\n",
        "  print(\"Disable LoRA for Text Encoder\")\n",
        "elif network_train_on == \"text_encoder_only\":\n",
        "  lora_module_to_train = \"--network_train_text_encoder_only\"\n",
        "  print(\"Disable LoRA for U-Net\")\n",
        "  print(\"Enable LoRA for Text Encoder\")\n",
        "else:\n",
        "  lora_module_to_train = \"\"\n",
        "  print(\"Enable LoRA for U-Net\")\n",
        "  print(\"Enable LoRA for Text Encoder\")\n",
        "\n",
        "if unet_lr == 0:\n",
        "  unet_lr_value = \"\"\n",
        "else:\n",
        "  unet_lr_value = \"--unet_lr\" + \"=\" + \"{}\".format(unet_lr)\n",
        "\n",
        "if text_encoder_lr == 0:\n",
        "  text_encoder_lr_value = \"\"\n",
        "else:\n",
        "  text_encoder_lr_value = \"--text_encoder_lr\" + \"=\" + \"{}\".format(text_encoder_lr)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5P-QVvHMUrFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.3. Start LoRA Dreambooth\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'number'}\n",
        "caption_extension = '.txt' #@param {'type':'string'}\n",
        "resolution = 512 #@param {'type':'number'}\n",
        "train_batch_size = 4 #@param {'type': 'slider', min: 1, max: 10}\n",
        "learning_rate = 1e-4 #@param {'type':'number'}\n",
        "num_epochs = 10 #@param {'type':'number'}\n",
        "mixed_precision = 'fp16' #@param ['fp16', 'bf16'] {'type':'string'}\n",
        "save_precision = 'fp16' #@param ['none','float', 'fp16', 'bf16'] {'type':'string'}\n",
        "save_every_n_epochs = 1 #@param {'type':'number'}\n",
        "save_model_as = 'safetensors' #@param ['default', 'ckpt', 'pt', 'safetensors'] {'type':'string'}\n",
        "clip_skip = 2 #@param {'type': 'slider', min: 1, max: 10}\n",
        "max_token_length = 225 #@param {'type':'number'}\n",
        "lr_scheduler = 'constant' #@param ['linear', 'cosine', 'cosine_with_restarts', 'polynomial', 'constant', 'constant_with_warmup'] {'type':'string'}\n",
        "gradient_accumulation_steps = 1 #@param {'type': 'slider', min: 1, max: 10}\n",
        "#@markdown ### Log And Debug\n",
        "log_prefix = 'LoRA-dreambooth-style1' #@param {'type':'string'}\n",
        "logs_dst = '/content/dreambooth/training_logs' #@param {'type':'string'}\n",
        "debug_mode = False #@param {'type':'boolean'}\n",
        "\n",
        "# Hidden config, for resume state, good for reproducibility\n",
        "save_state = False\n",
        "resume_path = \"\" \n",
        "# End of Hidden config\n",
        "\n",
        "if resume_path == \"\":\n",
        "  resume_value = \"\"\n",
        "else:\n",
        "  resume_value = \"--resume \" + str(resume_path)\n",
        "\n",
        "if V2 == \"none\":\n",
        "  penultimate_layer = \"--clip_skip\" + \"=\" + \"{}\".format(clip_skip)\n",
        "else:\n",
        "  penultimate_layer = \"\"\n",
        "  \n",
        "save_state_value_mapping = {True: \"--save_state\", False: \"\"}\n",
        "save_state_value = save_state_value_mapping[save_state]\n",
        "\n",
        "save_precision_value_mapping = {\n",
        "    \"none\": \"\",\n",
        "    \"float\": \"--save_precision=float\",\n",
        "    \"fp16\": \"--save_precision=fp16\",\n",
        "    \"bf16\": \"--save_precision=bf16\"\n",
        "}\n",
        "save_precision_value = save_precision_value_mapping[save_precision]\n",
        "\n",
        "save_model_as_value_mapping = {\n",
        "    \"default\": \"\",\n",
        "    \"ckpt\": \"--save_model_as=ckpt\",\n",
        "    \"pt\": \"--save_model_as=pt\",\n",
        "    \"safetensors\": \"--save_model_as=safetensors\"\n",
        "}\n",
        "save_model_as_value = save_model_as_value_mapping[save_model_as]\n",
        "\n",
        "debug_mode_value_mapping = {True: \"--debug\", False: \"\"}\n",
        "debug_mode_value = debug_mode_value_mapping[debug_mode]\n",
        "\n",
        "# Calculate max_train_steps\n",
        "print(\"Measuring folders:\")\n",
        "total = 0\n",
        "folders = os.listdir(train_folder_directory)\n",
        "for folder in folders:\n",
        "    parts = folder.split(\"_\")\n",
        "    if len(parts) != 2:\n",
        "        continue\n",
        "    repeats = int(parts[0])\n",
        "    images = [f for f in os.listdir(os.path.join(train_folder_directory, folder)) if f.endswith((\".png\", \".bmp\", \".gif\", \".jpg\", \".jpeg\", \".webp\"))]\n",
        "    img_repeats = repeats * len(images)\n",
        "    print(f\"\\t{parts[1]}: {repeats} repeats * {len(images)} images = {img_repeats}\")\n",
        "    total += img_repeats\n",
        "print(f\"Total images with repeats: {total}\")\n",
        "max_train_steps = int(total / train_batch_size * num_epochs)\n",
        "print(f\"Max training steps {total} / {train_batch_size} * {num_epochs} = {max_train_steps}\")\n",
        "\n",
        "%cd /content/kohya-trainer/\n",
        "!accelerate launch \\\n",
        "  --config_file \"{accelerate_config}\" \\\n",
        "  --num_cpu_threads_per_process {num_cpu_threads_per_process} \\\n",
        "  train_network.py \\\n",
        "  {v2_model} \\\n",
        "  {v2_768v_model} \\\n",
        "  --network_module={network_module} \\\n",
        "  --network_dim {network_dim} \\\n",
        "  {network_weights_value} \\\n",
        "  {lora_module_to_train} \\\n",
        "  {unet_lr_value} \\\n",
        "  {text_encoder_lr_value} \\\n",
        "  --pretrained_model_name_or_path=\"{pre_trained_model_path}\" \\\n",
        "  --train_data_dir=\"{train_folder_directory}\" \\\n",
        "  --reg_data_dir=\"{reg_folder_directory}\" \\\n",
        "  {vae_value} \\\n",
        "  --output_dir=\"{output_dir}\" \\\n",
        "  --caption_extension \"{caption_extension}\" \\\n",
        "  --shuffle_caption \\\n",
        "  --prior_loss_weight=1.0 \\\n",
        "  --resolution={resolution} \\\n",
        "  --enable_bucket \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  --max_train_step={max_train_steps} \\\n",
        "  --mixed_precision=\"{mixed_precision}\" \\\n",
        "  {save_state_value} \\\n",
        "  {resume_value} \\\n",
        "  {save_precision_value} \\\n",
        "  --use_8bit_adam \\\n",
        "  --xformers \\\n",
        "  --save_every_n_epochs {save_every_n_epochs} \\\n",
        "  {save_model_as_value} \\\n",
        "  --clip_skip {clip_skip} \\\n",
        "  --max_token_length {max_token_length} \\\n",
        "  --cache_latents \\\n",
        "  --lr_scheduler \"{lr_scheduler}\" \\\n",
        "  {debug_mode_value} \\\n",
        "  --logging_dir \"{logs_dst}\" \\\n",
        "  --log_prefix \"{log_prefix}\" \\\n",
        "  --gradient_accumulation_steps {gradient_accumulation_steps}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GIvfcS1pOrGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIII. Testing"
      ],
      "metadata": {
        "id": "reMcN0bM_o53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 8.1 Inference\n",
        "#@markdown LoRA Config\n",
        "network_dim = 128 #@param {'type':'number'}\n",
        "network_weights = \"/content/dreambooth/output/last.safetensors\" #@param {'type':'string'}\n",
        "#@markdown `Choose range from 0 to 1.0`\n",
        "network_mul = 1.0 #@param {'type':'number'}\n",
        "\n",
        "#@markdown Other Config\n",
        "V2 = \"none\" #@param [\"none\", \"V2_base\", \"V2_768_v\"] {allow-input: false}\n",
        "prompt = \"masterpiece, best quality, masabodo, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\" #@param {type: \"string\"}\n",
        "negative = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type: \"string\"}\n",
        "model = \"/content/pre_trained_model/Anything-V3-better-vae.ckpt\" #@param {type: \"string\"}\n",
        "vae = \"\" #@param {type: \"string\"}\n",
        "output_folder = \"/content/tmp\" #@param {type: \"string\"}\n",
        "scale = 12 #@param {type: \"slider\", min: 1, max: 40}\n",
        "sampler = \"ddim\" #@param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "steps = 28 #@param {type: \"slider\", min: 1, max: 100}\n",
        "precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "width = 768 #@param {type: \"integer\"}\n",
        "height = 768 #@param {type: \"integer\"}\n",
        "images_per_prompt = 4 #@param {type: \"integer\"}\n",
        "batch_size = 4 #@param {type: \"integer\"}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 40}\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "\n",
        "if vae == \"\":\n",
        "  load_vae =\"\"\n",
        "else:\n",
        "  load_vae =\"--vae \" + str(vae)\n",
        "\n",
        "if V2 == \"V2_base\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model= \"\"\n",
        "elif V2 == \"V2_768_v\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model = \"--v2_parameterization\"\n",
        "else:\n",
        "  v2_model = \"\"\n",
        "  v2_768v_model = \"\"\n",
        "\n",
        "if V2 == \"none\":\n",
        "  penultimate_layer = \"--clip_skip\" + \"=\" + \"{}\".format(clip_skip)\n",
        "else:\n",
        "  penultimate_layer = \"\"\n",
        "\n",
        "if seed <= 0:\n",
        "  seed_number = \"\"\n",
        "else:\n",
        "  seed_number = \"--seed\" + \"=\" + \"{}\".format(seed)\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "!python gen_img_diffusers.py \\\n",
        "  {v2_model} \\\n",
        "  {v2_768v_model} \\\n",
        "  --ckpt {model} \\\n",
        "  --outdir {output_folder} \\\n",
        "  --xformers \\\n",
        "  {load_vae} \\\n",
        "  --{precision} \\\n",
        "  --W {width} \\\n",
        "  --H {height} \\\n",
        "  {seed_number} \\\n",
        "  --scale {scale} \\\n",
        "  --sampler {sampler} \\\n",
        "  --steps {steps} \\\n",
        "  --max_embeddings_multiples 3 \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --images_per_prompt {images_per_prompt} \\\n",
        "  {penultimate_layer} \\\n",
        "  --network_module=networks.lora \\\n",
        "  --network_weight=\"{network_weights}\" \\\n",
        "  --network_mul 1.0 \\\n",
        "  --network_dim {network_dim} \\\n",
        "  --prompt \"{prompt} --n {negative}\"\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x6t8PbnF0gbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 8.2. Visualize loss graph (Optional)\n",
        "training_logs_path = \"/content/dreambooth/training_logs\" #@param {type : \"string\"}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {training_logs_path}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rt7CKCog_4tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IX. Extras"
      ],
      "metadata": {
        "id": "N6ckzE2GWudi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 9.1. Compressing model or dataset\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "zip_module = \"zipfile\" #@param [\"zipfile\", \"shutil\", \"pyminizip\", \"zip\"]\n",
        "directory_to_zip = '/content/dreambooth/output' #@param {type: \"string\"}\n",
        "output_filename = '/content/output.zip' #@param {type: \"string\"}\n",
        "password = \"\" #@param {type: \"string\"}\n",
        "\n",
        "if zip_module == \"zipfile\":\n",
        "    with zipfile.ZipFile(output_filename, 'w') as zip:\n",
        "        for directory_to_zip, dirs, files in os.walk(directory_to_zip):\n",
        "            for file in files:\n",
        "                zip.write(os.path.join(directory_to_zip, file))\n",
        "elif zip_module == \"shutil\":\n",
        "    shutil.make_archive(output_filename, 'zip', directory_to_zip)\n",
        "elif zip_module == \"pyminizip\":\n",
        "    !pip install pyminizip\n",
        "    import pyminizip\n",
        "    for root, dirs, files in os.walk(directory_to_zip):\n",
        "        for file in files:\n",
        "            pyminizip.compress(os.path.join(root, file), \"\", os.path.join(\"*\",output_filename), password, 5)\n",
        "elif zip_module == \"zip\":\n",
        "    !zip -rv -q -j {output_filename} {directory_to_zip}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rLdEpPKTbI1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X. Deployment"
      ],
      "metadata": {
        "id": "nyIl9BhNXKUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 10.1. Define your Huggingface Repo\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown #### If your model/dataset repo didn't exist, it will automatically create your repo.\n",
        "model_name = \"test-model\" #@param{type:\"string\"}\n",
        "dataset_name = \"test-dataset\" #@param{type:\"string\"}\n",
        "make_this_model_private = False #@param{type:\"boolean\"}\n",
        "clone_with_git = True #@param{type:\"boolean\"}\n",
        "\n",
        "model_repo = user['name']+\"/\"+model_name.strip()\n",
        "datasets_repo = user['name']+\"/\"+dataset_name.strip()\n",
        "\n",
        "validate_repo_id(model_repo)\n",
        "validate_repo_id(datasets_repo)\n",
        "\n",
        "if make_this_model_private:\n",
        "  private_repo = True\n",
        "else:\n",
        "  private_repo = False\n",
        "\n",
        "if model_name != \"\":\n",
        "  try:\n",
        "      api.create_repo(repo_id=model_repo, \n",
        "                      private=private_repo)\n",
        "      print(\"Model Repo didn't exists, creating repo\")\n",
        "      print(\"Model Repo: \",model_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Model Repo: {model_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "if dataset_name != \"\":\n",
        "  try:\n",
        "      api.create_repo(repo_id=datasets_repo,\n",
        "                      repo_type=\"dataset\",\n",
        "                      private=private_repo)\n",
        "      print(\"Dataset Repo didn't exists, creating repo\")\n",
        "      print(\"Dataset Repo\",datasets_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Dataset repo: {datasets_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "if clone_with_git:\n",
        "  !git lfs uninstall\n",
        "\n",
        "  if model_name != \"\":\n",
        "    !git clone https://huggingface.co/{model_repo} /content/{model_name}\n",
        "  \n",
        "  if dataset_name != \"\":\n",
        "    !git clone https://huggingface.co/datasets/{datasets_repo} /content/{dataset_name}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTXsM170GUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2. Upload to Huggingface"
      ],
      "metadata": {
        "id": "yUNkWbMHcbiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 10.2.1. Commit using Git \n",
        "%cd /content/\n",
        "\n",
        "#@markdown Tick which repo you want to commit\n",
        "commit_model = True #@param {'type': 'boolean'}\n",
        "commit_dataset = True #@param {'type': 'boolean'}\n",
        "\n",
        "#@markdown Set **git commit identity**\n",
        "email = \"your-email\" #@param {'type': 'string'}\n",
        "name = \"your-username\" #@param {'type': 'string'}\n",
        "#@markdown Set **commit message**\n",
        "commit_m = \"feat: upload prototype model\" #@param {'type': 'string'}\n",
        "\n",
        "!git lfs install\n",
        "\n",
        "!git config --global user.email \"{email}\"\n",
        "!git config --global user.name \"{name}\"\n",
        "\n",
        "if commit_model:\n",
        "  %cd /content/{model_name}\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "if commit_dataset:\n",
        "  %cd /content/{dataset_name}\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7bJev4PzOFFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 10.2.2. Quick Upload to Huggingface\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown #### This will be uploaded to model repo\n",
        "model_path = \"/content/dreambooth/output/last.safetensors\" #@param {type :\"string\"}\n",
        "#@markdown #### This will be uploaded to datasets repo, leave it empty if not necessary\n",
        "train_data_path = \"/content/dreambooth/train_illustration\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown ##### `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/dreambooth/training_logs\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"feat: upload 2 epoch and the last-state\" #@param {type :\"string\"}\n",
        "\n",
        "if model_path != \"\":\n",
        "  path_obj = Path(model_path)\n",
        "  trained_model = path_obj.parts[-1]\n",
        "\n",
        "  if model_path.endswith(\".ckpt\") or model_path.endswith(\".safetensors\") or model_path.endswith(\".pt\"):\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=model_path,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "    )\n",
        "    \n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/blob/main/\"+trained_model+\"\\n\")\n",
        "    \n",
        "  else:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=model_path,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\"\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/tree/main/\"+trained_model+\"\\n\")\n",
        "\n",
        "if train_data_path != \"\":\n",
        "  path_obj = Path(train_data_path)\n",
        "  train_data_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {train_data_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=train_data_path,\n",
        "      path_in_repo=train_data_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+train_data_folder+\"\\n\")\n",
        "\n",
        "if logs_path != \"\":\n",
        "  path_obj = Path(logs_path)\n",
        "  logs_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {logs_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=logs_path,\n",
        "      path_in_repo=logs_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+logs_folder+\"\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pSUhgYLYdT2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}