{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/experimental/kohya-trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "# Kohya Trainer V6 - VRAM 12GB\n",
        "### The Best Way for People Without Good GPUs to Fine-Tune the Stable Diffusion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      },
      "source": [
        "This notebook has been adapted for use in Google Colab based on the [Kohya Guide](https://note.com/kohya_ss/n/nbf7ce8d80f29#c9d7ee61-5779-4436-b4e6-9053741c46bb). </br>\n",
        "This notebook was adapted by [Linaqruf](https://github.com/Linaqruf)</br>\n",
        "You can find the latest update to the notebook [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# Install Kohya Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_u3q60di584x"
      },
      "outputs": [],
      "source": [
        "#@title Clone Kohya Trainer\n",
        "#@markdown Clone the Kohya Trainer repository from GitHub and check for updates\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "def clone_kohya_trainer():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir('/content/kohya-trainer'):\n",
        "    %cd /content/kohya-trainer\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/Linaqruf/kohya-trainer\n",
        "    \n",
        "\n",
        "# Clone or update the Kohya Trainer repository\n",
        "clone_kohya_trainer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nj8fNQZNESyT"
      },
      "outputs": [],
      "source": [
        "#@title Install Diffuser Fine Tuning\n",
        "\n",
        "# Change the current working directory to \"/content/kohya-trainer\".\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "# Import `shutil` and `os` modules.\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Initialize an empty list `custom_versions`.\n",
        "custom_versions = []\n",
        "\n",
        "# Initialize a list `version_urls` containing URLs of different versions of the `diffusers_fine_tuning` file.\n",
        "version_urls = [\"\",\\\n",
        "              \"https://github.com/Linaqruf/kohya-trainer/releases/download/v6/diffusers_fine_tuning_v6.zip\", \\\n",
        "              \"https://github.com/Linaqruf/kohya-trainer/releases/download/v5/diffusers_fine_tuning_v5.zip\", \\\n",
        "              \"https://github.com/Linaqruf/kohya-trainer/releases/download/v4/diffusers_fine_tuning_v4.zip\", \\\n",
        "              \"https://github.com/Linaqruf/kohya-trainer/releases/download/v3/diffusers_fine_tuning_v3.zip\", \\\n",
        "              \"https://github.com/Linaqruf/kohya-trainer/releases/download/v2/diffusers_fine_tuning_v2.zip\", \\\n",
        "              \"https://github.com/Linaqruf/kohya-trainer/releases/download/v1/diffusers_fine_tuning_v1.zip\"]\n",
        "\n",
        "# Initialize a list `version_names` containing names of different versions of the `diffusers_fine_tuning` file.\n",
        "version_names = [\"latest_version\", \\\n",
        "               \"diffusers_fine_tuning_v6\", \\\n",
        "               \"diffusers_fine_tuning_v5\", \\\n",
        "               \"diffusers_fine_tuning_v4\", \\\n",
        "               \"diffusers_fine_tuning_v3\", \\\n",
        "               \"diffusers_fine_tuning_v2\", \\\n",
        "               \"diffusers_fine_tuning_v1\"]\n",
        "\n",
        "# Initialize a variable `selected_version` to the selected version of the `diffusers_fine_tuning` file.\n",
        "selected_version = \"latest_version\" #@param [\"latest_version\", \"diffusers_fine_tuning_v6\", \"diffusers_fine_tuning_v5\", \"diffusers_fine_tuning_v4\", \"diffusers_fine_tuning_v3\", \"diffusers_fine_tuning_v2\", \"diffusers_fine_tuning_v1\"]\n",
        "\n",
        "# Append a tuple to `custom_versions`, containing `selected_version` and the corresponding item\n",
        "# in `version_urls`.\n",
        "custom_versions.append((selected_version, version_urls[version_names.index(selected_version)]))\n",
        "\n",
        "# Define `download` function to download a file from the given URL and save it with\n",
        "# the given name.\n",
        "def download(name, url):\n",
        "  !wget -c \"{url}\" -O /content/{name}.zip\n",
        "\n",
        "# Define `unzip` function to unzip a file with the given name to a specified\n",
        "# directory.\n",
        "def unzip(name):\n",
        "  !unzip /content/{name}.zip -d /content/kohya-trainer/diffuser_fine_tuning\n",
        "\n",
        "# Define `download_version` function to download and unzip a file from `custom_versions`,\n",
        "# unless `selected_version` is \"latest_version\".\n",
        "def download_version():\n",
        "  if selected_version != \"latest_version\":\n",
        "    for zip in custom_versions:\n",
        "      download(zip[0], zip[1])\n",
        "\n",
        "      # Rename the existing `diffuser_fine_tuning` directory to the `tmp` directory and delete any existing `tmp` directory.\n",
        "      if os.path.exists(\"/content/kohya-trainer/tmp\"):\n",
        "        shutil.rmtree(\"/content/kohya-trainer/tmp\")\n",
        "      os.rename(\"/content/kohya-trainer/diffuser_fine_tuning\", \"/content/kohya-trainer/tmp\")\n",
        "\n",
        "      # Create a new empty `diffuser_fine_tuning` directory.\n",
        "      os.makedirs(\"/content/kohya-trainer/diffuser_fine_tuning\")\n",
        "      \n",
        "      # Unzip the downloaded file to the new `diffuser_fine_tuning` directory.\n",
        "      unzip(zip[0])\n",
        "      \n",
        "      # Delete the downloaded and unzipped file.\n",
        "      os.remove(\"/content/{}.zip\".format(zip[0]))\n",
        "      \n",
        "      # Inform the user that the existing `diffuser_fine_tuning` directory has been renamed to the `tmp` directory\n",
        "      # and a new empty `diffuser_fine_tuning` directory has been created.\n",
        "      print(\"Renamed existing 'diffuser_fine_tuning' directory to 'tmp' directory and created new empty 'diffuser_fine_tuning' directory.\")\n",
        "  else:\n",
        "    # Do nothing if `selected_version` is \"latest_version\".\n",
        "    pass\n",
        "\n",
        "# Call `download_version` function.\n",
        "download_version()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WNn0g1pnHfk5"
      },
      "outputs": [],
      "source": [
        "#@title Installing Dependencies\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "def install_dependencies():\n",
        "  #@markdown Install required Python packages\n",
        "  !pip install --upgrade -r script/requirements.txt\n",
        "  !pip install -U gallery-dl\n",
        "  !pip install tensorflow\n",
        "  !pip install huggingface_hub\n",
        "\n",
        "  # Install xformers\n",
        "  !pip install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "  !pip install timm==0.4.12\n",
        "  !pip install fairscale==0.4.4\n",
        "\n",
        "# Install convert_diffusers_to_original_stable_diffusion.py script\n",
        "if not os.path.isfile('/content/kohya-trainer/convert_diffusers_to_original_stable_diffusion.py'):\n",
        "  !wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "\n",
        "# Install dependencies\n",
        "install_dependencies()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VZOXwDv3utpx"
      },
      "outputs": [],
      "source": [
        "#@title Set config for `!Accelerate`\n",
        "#@markdown #Hint\n",
        "\n",
        "#@markdown 1. **In which compute environment are you running?** ([0] This machine, [1] AWS (Amazon SageMaker)): `0`\n",
        "#@markdown 2. **Which type of machine are you using?** ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU [4] MPS): `0`\n",
        "#@markdown 3. **Do you want to run your training on CPU only (even if a GPU is available)?** [yes/NO]: `NO`\n",
        "#@markdown 4. **Do you want to use DeepSpeed?** [yes/NO]: `NO`\n",
        "#@markdown 5. **What GPU(s) (by id) should be used for training on this machine as a comma-seperated list?** [all] = `all`\n",
        "#@markdown 6. **Do you wish to use FP16 or BF16 (mixed precision)?** [NO/fp16/bf16]: `fp16`\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "!accelerate config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0fzmhtywk_u"
      },
      "source": [
        "# Prepare Cloud Storage (Huggingface/GDrive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cwIJdhEcwk_u"
      },
      "outputs": [],
      "source": [
        "#@title Login to Huggingface hub\n",
        "\n",
        "#@markdown ## Instructions:\n",
        "#@markdown 1. Of course, you need a Huggingface account first.\n",
        "#@markdown 2. To create a huggingface token, go to `Profile > Access Tokens > New Token > Create a new access token` with the `Write` role.\n",
        "#@markdown 3. By default, all cells below are marked as `opt-out`, so you need to uncheck them if you want to run the cells.\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "from huggingface_hub import login\n",
        "login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jVgHUUK_wk_v"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "mount_drive = True #@param {'type':'boolean'}\n",
        "\n",
        "if mount_drive:\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# Collecting datasets\n",
        "\n",
        "You can either upload your datasets to this notebook or use the image scraper below to bulk download images from Danbooru.\n",
        "\n",
        "If you want to use your own datasets, you can upload to colab `local files`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Datasets Repo From Huggingface (Skip if you dont have it)\n",
        "\n",
        "%cd /content\n",
        "username = \"your-username\" #@param {'type': 'string'}\n",
        "datasets_repo = \"your-datasets-repo-name\" #@param {'type': 'string'}\n",
        "\n",
        "Repository_url = f\"https://huggingface.co/datasets/{username}/{datasets_repo}\"\n",
        "!git lfs install\n",
        "!git clone {Repository_url}\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lJP8l3VQTOqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Train Data\n",
        "#@markdown Define where your train data will be located. This cell will also create a folder based on your input. \n",
        "#@markdown This folder will be used as the target folder for scraping, tagging, bucketing, and training in the next cell.\n",
        "\n",
        "import os\n",
        "\n",
        "train_data_dir = \"/content/tarte-midjourney/train-data\" #@param {'type' : 'string'}\n",
        "\n",
        "if not os.path.exists(train_data_dir):\n",
        "    os.makedirs(train_data_dir)\n",
        "else:\n",
        "    print(f\"{train_data_dir} already exists\\n\")\n",
        "\n",
        "print(f\"Your train data directory : {train_data_dir}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nXNk0NOwzWw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Kt1GzntK_apb"
      },
      "outputs": [],
      "source": [
        "#@title Booru Scraper\n",
        "#@markdown Use gallery-dl to scrape images from a booru site using the specified tags\n",
        "\n",
        "%cd /content\n",
        "\n",
        "# Set configuration options\n",
        "booru = \"Danbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "tag1 = \"hito_komoru\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "\n",
        "# Construct the search query\n",
        "if tag2 != \"\":\n",
        "  tags = tag1 + \"+\" + tag2\n",
        "else:\n",
        "  tags = tag1\n",
        "\n",
        "# Scrape images from the specified booru site using the given tags\n",
        "if booru.lower() == \"danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tags}\" -D {train_data_dir}\n",
        "elif booru.lower() == \"gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tags}\" -D {train_data_dir}\n",
        "else:\n",
        "  print(f\"Unknown booru site: {booru}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu"
      },
      "outputs": [],
      "source": [
        "#@title Datasets cleaner\n",
        "#@markdown This will delete unnecessary files and unsupported media like `.mp4`, `.webm`, and `.gif`\n",
        "\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "test = os.listdir(train_data_dir)\n",
        "\n",
        "# List of supported file types\n",
        "supported_types = [\".jpg\", \".jpeg\", \".png\"]\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for item in test:\n",
        "    # Extract the file extension from the file name\n",
        "    file_ext = os.path.splitext(item)[1]\n",
        "    # If the file extension is not in the list of supported types, delete the file\n",
        "    if file_ext not in supported_types:\n",
        "        # Print a message indicating the name of the file being deleted\n",
        "        print(f\"Deleting file {item} from {train_data_dir}\")\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(train_data_dir, item))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `(NEW)`BLIP Captioning"
      ],
      "metadata": {
        "id": "YkRg6g5FqYvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Spaces\n",
        "%cd /content/kohya-trainer\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/spaces/Salesforce/BLIP\n",
        "\n",
        "import shutil\n",
        "\n",
        "BLIP_weight_src = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth'\n",
        "BLIP_weight_dst = '/content/kohya-trainer/BLIP/model_large_caption.pth'\n",
        "\n",
        "make_caption_src = '/content/kohya-trainer/diffuser_fine_tuning/make_captions.py'\n",
        "make_caption_dst = '/content/kohya-trainer/BLIP/make_captions.py'\n",
        "\n",
        "!wget -c {BLIP_weight_src} -O {BLIP_weight_dst}\n",
        "\n",
        "shutil.move(make_caption_src, make_caption_dst)\n"
      ],
      "metadata": {
        "id": "RrCJI2AbqX2E",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Auto-captioning\n",
        "%cd /content/kohya-trainer/BLIP\n",
        "\n",
        "#@markdown ### Command-line Arguments\n",
        "#@markdown The following command-line arguments are available:\n",
        "#@markdown - `train_data_dir` : directory for training images\n",
        "#@markdown - `caption_weights` : BLIP caption weights (model_large_caption.pth)\n",
        "#@markdown - `--caption_extention` : extension of caption file (for backward compatibility)\n",
        "#@markdown - `--caption_extension` : extension of caption file\n",
        "#@markdown - `--beam_search` : use beam search (default Nucleus sampling)\n",
        "#@markdown - `--batch_size` : batch size in inference\n",
        "#@markdown - `--num_beams` : num of beams in beam search\n",
        "#@markdown - `--top_p` : top_p in Nucleus sampling\n",
        "#@markdown - `--max_length` : max length of caption\n",
        "#@markdown - `--min_length` : min length of caption\n",
        "#@markdown - `--debug` : debug mode\n",
        "\n",
        "#@markdown ### Define parameter:\n",
        "batch_size = 8 #@param {'type':'integer'}\n",
        "caption_extension = \".caption\" #@param [\".txt\",\".caption\"]\n",
        "caption_weights = \"model_large_caption.pth\"\n",
        "\n",
        "!python make_captions.py \\\n",
        "  {train_data_dir} \\\n",
        "  {caption_weights} \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --caption_extension {caption_extension}"
      ],
      "metadata": {
        "id": "5kXjiW-2tWPD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoPUJaTpTusz"
      },
      "source": [
        "# `(NEW)` Waifu Diffusion 1.4 Autotagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WDSlAEHzT2Im"
      },
      "outputs": [],
      "source": [
        "#@title Download Weight\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def huggingface_dl(url, weight):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/kohya-trainer/wd14tagger-weight/{weight}\n",
        "\n",
        "def download_weight():\n",
        "  # Remove the weight directory if it exists\n",
        "  weight_dir = '/content/kohya-trainer/wd14tagger-weight/'\n",
        "  if os.path.exists(weight_dir):\n",
        "    shutil.rmtree(weight_dir)\n",
        "\n",
        "  # Create the weight directory\n",
        "  os.mkdir(weight_dir)\n",
        "\n",
        "  # Download the weight file from the specified URL\n",
        "  weight_url = \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/wd14tagger-weight/wd14Tagger.zip\"\n",
        "  huggingface_dl(weight_url, \"wd14Tagger.zip\")\n",
        "  \n",
        "  # Extract the weight file from the zip archive\n",
        "  !unzip /content/kohya-trainer/wd14tagger-weight/wd14Tagger.zip -d /content/kohya-trainer/wd14tagger-weight\n",
        "\n",
        "  # Move the weight file to the weight directory\n",
        "  shutil.move(\"script/tag_images_by_wd14_tagger.py\", weight_dir)\n",
        "\n",
        "  # Delete the zip file after it has been extracted\n",
        "  os.remove('/content/kohya-trainer/wd14tagger-weight/wd14Tagger.zip')\n",
        "\n",
        "download_weight()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hibZK5NPTjZQ"
      },
      "outputs": [],
      "source": [
        "#@title Start Autotagger\n",
        "\n",
        "# Change the working directory to the weight directory\n",
        "%cd /content/kohya-trainer/wd14tagger-weight\n",
        "\n",
        "#@markdown ### Command-line Arguments\n",
        "#@markdown The following command-line arguments are available:\n",
        "#@markdown - `train_data_dir` : directory for training images\n",
        "#@markdown - `--model` : model path to load\n",
        "#@markdown - `--tag_csv` : csv file for tag\n",
        "#@markdown - `--thresh` : threshold of confidence to add a tag\n",
        "#@markdown - `--batch_size` : batch size in inference\n",
        "#@markdown - `--caption_extension` : extension of caption file\n",
        "#@markdown - `--debug` : debug mode\n",
        "\n",
        "#@markdown ### Define parameter:\n",
        "batch_size = 4 #@param {'type':'integer'}\n",
        "caption_extension = \".txt\" #@param [\".txt\",\".caption\"]\n",
        "\n",
        "!python tag_images_by_wd14_tagger.py \\\n",
        "  {train_data_dir} \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --caption_extension .txt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create meta_clean.json \n",
        "# Change the working directory\n",
        "%cd /content/kohya-trainer/diffuser_fine_tuning\n",
        "\n",
        "#@markdown ### Define Parameters\n",
        "meta_cap_dd = \"/content/kohya-trainer/meta_cap_dd.json\" #@param {'type':'string'}\n",
        "meta_cap = \"/content/kohya-trainer/meta_cap.json\" #@param {'type':'string'}\n",
        "meta_clean = \"/content/kohya-trainer/meta_clean.json\" #@param {'type':'string'}\n",
        "\n",
        "# Create meta_cap_dd.json from tags\n",
        "if os.path.exists(train_data_dir + '.txt'):\n",
        "  !python merge_dd_tags_to_metadata.py \\\n",
        "    {train_data_dir} \\\n",
        "    {meta_cap_dd}\n",
        "\n",
        "# Create meta_cap.json from captions\n",
        "if os.path.exists(train_data_dir + '.caption'):\n",
        "  !python merge_captions_to_metadata.py \\\n",
        "    {train_data_dir} \\\n",
        "    {meta_cap}\n",
        "\n",
        "# Merge meta_cap.json to meta_cap_dd.json\n",
        "if os.path.exists(meta_cap) and os.path.exists(meta_cap_dd):\n",
        "  !python merge_dd_tags_to_metadata.py \\\n",
        "    {train_data_dir} \\\n",
        "    --in_json {meta_cap} \\\n",
        "    {meta_cap_dd}\n",
        "\n",
        "# Clean meta_cap_dd.json and store it to meta_clean.json\n",
        "if os.path.exists(meta_cap_dd):\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {train_data_dir} \\\n",
        "    {meta_cap_dd} \\\n",
        "    {meta_clean}\n",
        "elif os.path.exists(meta_cap):\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {train_data_dir} \\\n",
        "    {meta_cap} \\\n",
        "    {meta_clean}\n",
        "\n",
        "#@markdown ### Here is a description of what the code does:\n",
        "#@markdown \n",
        "#@markdown 1. It changes the working directory to the `diffuser_fine_tuning` folder inside the `kohya-trainer` folder.\n",
        "#@markdown 2. It defines the parameters `train_data_dir`, `meta_cap_dd`, `meta_cap`, and `meta_clean`.\n",
        "#@markdown 3. If the `.txt` file exists inside the `train_data_dir` folder, it creates `meta_cap_dd.json` by combining the tags from the `.txt` file with the metadata.\n",
        "#@markdown 4. If the `.caption` file exists inside the `train_data_dir` folder, it creates `meta_cap.json` by combining the captions from the `.caption` file with the metadata.\n",
        "#@markdown 5. If both `meta_cap.json` and `meta_cap_dd.json` exist, it merges the contents of `meta_cap.json` into `meta_cap_dd.json`.\n",
        "#@markdown 6. If `meta_cap_dd.json` exists, it cleans the captions and tags in `meta_cap_dd.json` and stores the result in `meta_clean.json`. If `meta_cap_dd.json` does not exist, but `meta_cap.json` exists, it cleans the captions and tags in `meta_cap.json` and stores the result in `meta_clean.json`.\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MEHNh0P8Yyxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gob9_OwTlwh"
      },
      "source": [
        "# Prepare Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SoucgZQ6jgPQ"
      },
      "outputs": [],
      "source": [
        "#@title Install Pre-trained Model \n",
        "%cd /content/kohya-trainer\n",
        "import os\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists('checkpoint'):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs('checkpoint')\n",
        "\n",
        "#@title Install Pre-trained Model \n",
        "\n",
        "installModels=[]\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available pretrained model to download:\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/modelsfw-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp16.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp32.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\" \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \\\n",
        "            \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Animesfw-final-pruned\", \\\n",
        "             \"Anything-V3.0-pruned-fp16\", \\\n",
        "             \"Anything-V3.0-pruned-fp32\", \\\n",
        "             \"Anything-V3.0-pruned\", \\\n",
        "             \"Stable-Diffusion-v1-4\", \\\n",
        "             \"Stable-Diffusion-v1-5-pruned-emaonly\", \\\n",
        "             \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "modelName = \"Anything-V3.0-pruned\" #@param [\"\", \"Animefull-final-pruned\", \"Animesfw-final-pruned\", \"Anything-V3.0-pruned-fp16\", \"Anything-V3.0-pruned-fp32\", \"Anything-V3.0-pruned\", \"Stable-Diffusion-v1-4\", \"Stable-Diffusion-v1-5-pruned-emaonly\", \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "\n",
        "#@markdown ### Custom model\n",
        "#@markdown The model URL should be a direct download link.\n",
        "customName = \"\" #@param {'type': 'string'}\n",
        "customUrl = \"\"#@param {'type': 'string'}\n",
        "\n",
        "# Check if user has specified a custom model\n",
        "if customName != \"\" and customUrl != \"\":\n",
        "  # Add custom model to list of models to install\n",
        "  installModels.append((customName, customUrl))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if modelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "def install_aria():\n",
        "  # Install aria2 if it is not already installed\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    # Use gdown to download file from Google Drive\n",
        "    !gdown --fuzzy -O \"/content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\" \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    # Use aria2c to download file from magnet link\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt \"{url}\"\n",
        "  else:\n",
        "    user_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    # Use wget to download file from URL\n",
        "    !wget -c --header={user_header} \"{url}\" -O /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  # Iterate through list of models to install\n",
        "  for model in installModels:\n",
        "    # Call install function for each model\n",
        "    install(model[0], model[1])\n",
        "\n",
        "# Call install_checkpoint function to download all models in the list\n",
        "install_checkpoint()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IQwpRDVIbDB9"
      },
      "outputs": [],
      "source": [
        "#@title Emergency downgrade\n",
        "#@markdown Tick this if you are facing issues on the cell below, such as high ram usage or cells not running\n",
        "\n",
        "diffuser_0_7_2 = True #@param {'type':'boolean'}\n",
        "\n",
        "# Check if user wants to downgrade diffusers\n",
        "if diffuser_0_7_2:\n",
        "  # Install diffusers 0.7.2\n",
        "  !pip install diffusers[torch]==0.7.2\n",
        "else:\n",
        "  # Install latest version of diffusers\n",
        "  !pip install diffusers[torch]==0.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hhgatqF3leHJ"
      },
      "outputs": [],
      "source": [
        "#@title Aspect Ratio Bucketing\n",
        "\n",
        "# Change working directory\n",
        "%cd /content/kohya-trainer/diffuser_fine_tuning\n",
        "\n",
        "#@markdown ### Command-line Arguments\n",
        "#@markdown The following command-line arguments are available:\n",
        "#@markdown * `train_data_dir`: directory for train images.\n",
        "#@markdown * `in_json`: metadata file to input.\n",
        "#@markdown * `out_json`: metadata file to output.\n",
        "#@markdown * `model_name_or_path`: model name or path to encode latents.\n",
        "#@markdown * `--v2`: load Stable Diffusion v2.0 model.\n",
        "#@markdown * `--batch_size`: batch size in inference.\n",
        "#@markdown * `--max_resolution`: max resolution in fine tuning (width,height).\n",
        "#@markdown * `--min_bucket_reso`: minimum resolution for buckets.\n",
        "#@markdown * `--max_bucket_reso`: maximum resolution for buckets.\n",
        "#@markdown * `--mixed_precision`: use mixed precision.\n",
        "\n",
        "#@markdown ### Define parameters\n",
        "in_json = \"/content/kohya-trainer/meta_clean.json\" #@param {'type' : 'string'} \n",
        "out_json = \"/content/kohya-trainer/meta_lat.json\" #@param {'type' : 'string'} \n",
        "model_dir = \"/content/kohya-trainer/checkpoint/Anything-V3.0-pruned.ckpt\" #@param {'type' : 'string'} \n",
        "batch_size = 4 #@param {'type':'integer'}\n",
        "max_resolution = \"768,768\" #@param [\"512,512\", \"768,768\"] {allow-input: false}\n",
        "mixed_precision = \"no\" #@param [\"no\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "\n",
        "# Run script to prepare buckets and latents\n",
        "!python prepare_buckets_latents.py \\\n",
        "  {train_data_dir} \\\n",
        "  {in_json} \\\n",
        "  {out_json} \\\n",
        "  {model_dir} \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --max_resolution {max_resolution} \\\n",
        "  --mixed_precision {mixed_precision}\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNbl3O_NSS0"
      },
      "source": [
        "# Start Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X_Rd3Eh07xlA"
      },
      "outputs": [],
      "source": [
        "#@title Training begin\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'integer'}\n",
        "pre_trained_model_path =\"/content/kohya-trainer/checkpoint/Anything-V3.0-pruned.ckpt\" #@param {'type':'string'}\n",
        "meta_lat_json_dir = \"/content/kohya-trainer/meta_lat.json\" #@param {'type':'string'}\n",
        "train_data_dir = \"/content/tarte-midjourney/train-data\" #@param {'type':'string'}\n",
        "output_dir =\"/content/kohya-trainer/fine_tuned\" #@param {'type':'string'}\n",
        "# resume_path = \"/content/kohya-trainer/last-state\" #@param {'type':'string'}\n",
        "train_batch_size = 1  #@param {type: \"slider\", min: 1, max: 10}\n",
        "learning_rate =\"2e-6\" #@param {'type':'string'}\n",
        "max_token_length = \"225\" #@param  [\"150\", \"225\"] {allow-input: false}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 10}\n",
        "mixed_precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "max_train_steps = 5000 #@param {'type':'integer'}\n",
        "save_precision = \"fp16\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs = 50 #@param {'type':'integer'}\n",
        "gradient_accumulation_steps = 1 #@param {type: \"slider\", min: 1, max: 10}\n",
        "\n",
        "%cd /content/kohya-trainer/diffuser_fine_tuning\n",
        "!accelerate launch --num_cpu_threads_per_process {num_cpu_threads_per_process} fine_tune.py \\\n",
        "  --pretrained_model_name_or_path={pre_trained_model_path} \\\n",
        "  --in_json {meta_lat_json_dir} \\\n",
        "  --train_data_dir={train_data_dir} \\\n",
        "  --output_dir={output_dir} \\\n",
        "  --shuffle_caption \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  --logging_dir=logs \\\n",
        "  --max_token_length={max_token_length} \\\n",
        "  --clip_skip={clip_skip} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --max_train_steps={max_train_steps} \\\n",
        "  --use_8bit_adam \\\n",
        "  --xformers \\\n",
        "  --gradient_checkpointing \\\n",
        "  --save_state \\\n",
        "  --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
        "  --save_precision={save_precision}\n",
        "  # --resume {resume_path} \\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqfgyL-thgdw"
      },
      "source": [
        "# Miscellaneous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nOhJCs3BeR_Q"
      },
      "outputs": [],
      "source": [
        "#@title Convert diffuser model to ckpt (Optional)\n",
        "\n",
        "#@markdown If you're using diffuser weight, this cell will convert output weight to checkpoint file so it can be used in Web UI like Auto1111's\n",
        "\n",
        "# Use a more descriptive variable name\n",
        "diffuser_weights_dir = \"/content/drive/MyDrive/fine_tuned/last\" #@param {'type':'string'}\n",
        "\n",
        "# Use a more descriptive variable name\n",
        "use_fp16 = False #@param {type: \"boolean\"}\n",
        "\n",
        "# Add a comment to explain what the code is doing\n",
        "# Convert the diffuser weights to a checkpoint file\n",
        "ckpt_path = diffuser_weights_dir + \"/model.ckpt\"\n",
        "\n",
        "# Use a more descriptive variable name\n",
        "half_precision_arg = \"\"\n",
        "if use_fp16:\n",
        "    # Use a more descriptive variable name\n",
        "    half_precision_arg = \"--half\"\n",
        "\n",
        "# Add a comment to explain what the code is doing\n",
        "# Run the conversion script\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $diffuser_weights_dir  --checkpoint_path $ckpt_path $half_precision_arg\n",
        "\n",
        "# Use string formatting and a more descriptive variable name\n",
        "print(f\"[*] Converted checkpoint saved at {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LUOG7BzQVLKp"
      },
      "outputs": [],
      "source": [
        "#@title Model Pruner (Optional)\n",
        "\n",
        "##Lopho\n",
        "\n",
        "#@markdown Do you want to Prune a model?\n",
        "%cd /content/ \n",
        "\n",
        "# Use a more descriptive variable name\n",
        "prune = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--fp16` argument\n",
        "fp16 = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--ema` argument\n",
        "ema = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--no-clip` argument\n",
        "no_clip = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--no-vae` argument\n",
        "no_vae = False #@param {'type':'boolean'}\n",
        "\n",
        "# Use a more descriptive variable name\n",
        "input = \"/content/kohya-trainer/fine_tuned/last.ckpt\" #@param {'type' : 'string'}\n",
        "\n",
        "# Use a more descriptive variable name\n",
        "output = \"/content/kohya-trainer/fine_tuned/last-pruned.ckpt\" #@param {'type' : 'string'}\n",
        "\n",
        "if prune:\n",
        "  import os\n",
        "  if os.path.isfile('/content/prune.py'):\n",
        "    pass\n",
        "  else:\n",
        "    # Add a comment to explain what the code is doing\n",
        "    # Download the pruning script if it doesn't already exist\n",
        "    !wget https://raw.githubusercontent.com/lopho/stable-diffusion-prune/main/prune.py\n",
        "\n",
        "\n",
        "# Add a comment to explain what the code is doing\n",
        "# Run the pruning script with the specified arguments\n",
        "!python3 prune.py {input} {output} {'--fp16' if fp16 else ''} {'--ema' if ema else ''} {'--no-clip' if no_clip else ''} {'--no-vae' if no_vae else ''}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jypUkLWc48R_"
      },
      "source": [
        "## Commit trained model to Huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvZgRSmKVSRw"
      },
      "source": [
        "### To Commit models:\n",
        "1. Create a huggingface repository for your model.\n",
        "2. Clone your model to this Colab session.\n",
        "3. Move the necessary files to your repository to save your trained model to huggingface. These files are located in `fine-tuned` folder:\n",
        "   - `epoch-nnnnn.ckpt` and/or\n",
        "   - `last.ckpt`\n",
        "4. Commit your model to huggingface.\n",
        "\n",
        "### To Commit datasets:\n",
        "1. Create a huggingface repository for your datasets.\n",
        "2. Clone your datasets to this Colab session.\n",
        "3. Move the necessary files to your repository so that you can resume training without rebuilding your dataset with this notebook:\n",
        "  - The `train_data` folder.\n",
        "  - The `meta_lat.json` file.\n",
        "  - The `last-state` folder.\n",
        "4. Commit your datasets to huggingface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "cellView": "form",
        "id": "182Law9oUiYN",
        "outputId": "39a92103-188f-4675-a158-157a604c7374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Global Git LFS configuration has been removed.\n",
            "Cloning into 'tarte'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "#@title Clone Model or Datasets\n",
        "\n",
        "#@markdown Type of item to clone (model or dataset)\n",
        "type_of_item = \"model\" #@param [\"model\", \"dataset\"]\n",
        "\n",
        "#@markdown Install or uninstall git lfs\n",
        "install_git_lfs = False #@param {'type':'boolean'}\n",
        "\n",
        "%cd /content\n",
        "username = \"your-huggingface-username\" #@param {'type': 'string'}\n",
        "model_repo = \"your-huggingface-model-repo\" #@param {'type': 'string'}\n",
        "datasets_repo = \"your-huggingface-datasets-repo\" #@param {'type': 'string'}\n",
        "\n",
        "if type_of_item == \"model\":\n",
        "  Repository_url = f\"https://huggingface.co/{username}/{model_repo}\"\n",
        "elif type_of_item == \"dataset\":\n",
        "  Repository_url = f\"https://huggingface.co/datasets/{username}/{datasets_repo}\"\n",
        "\n",
        "if install_git_lfs:\n",
        "  !git lfs install\n",
        "else:\n",
        "  !git lfs uninstall\n",
        "!git clone {Repository_url}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "87wG7QIZbtZE",
        "outputId": "96dc2455-a8db-4811-b366-2ddd40fe90c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/tarte-midjourney\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Local repo set up for largefiles\n",
            "Sorry, no usage text found for \"git-lfs\"\n",
            "[main c8577d3] feat: upload captions and tags\n",
            " 606 files changed, 1755 insertions(+), 570 deletions(-)\n",
            " delete mode 100644 tarte-5000-state/optimizer.bin\n",
            " delete mode 100644 tarte-5000-state/pytorch_model.bin\n",
            " delete mode 100644 tarte-5000-state/random_states_0.pkl\n",
            " delete mode 100644 tarte-5000-state/scaler.pt\n",
            " delete mode 100644 tarte-5000-state/scheduler.bin\n",
            " create mode 100644 train-data/100145978_p0.caption\n",
            " create mode 100644 train-data/100145978_p0.npz\n",
            " create mode 100644 train-data/100145978_p0.txt\n",
            " create mode 100644 train-data/100145978_p1.caption\n",
            " create mode 100644 train-data/100145978_p1.npz\n",
            " create mode 100644 train-data/100145978_p1.txt\n",
            " create mode 100644 train-data/100145978_p2.caption\n",
            " create mode 100644 train-data/100145978_p2.npz\n",
            " create mode 100644 train-data/100145978_p2.txt\n",
            " create mode 100644 train-data/100145978_p3.caption\n",
            " create mode 100644 train-data/100145978_p3.npz\n",
            " create mode 100644 train-data/100145978_p3.txt\n",
            " create mode 100644 train-data/100170580_p0.caption\n",
            " create mode 100644 train-data/100170580_p0.npz\n",
            " create mode 100644 train-data/100170580_p0.txt\n",
            " create mode 100644 train-data/100170580_p1.caption\n",
            " create mode 100644 train-data/100170580_p1.npz\n",
            " create mode 100644 train-data/100170580_p1.txt\n",
            " create mode 100644 train-data/100170580_p2.caption\n",
            " create mode 100644 train-data/100170580_p2.npz\n",
            " create mode 100644 train-data/100170580_p2.txt\n",
            " create mode 100644 train-data/100170580_p3.caption\n",
            " create mode 100644 train-data/100170580_p3.npz\n",
            " create mode 100644 train-data/100170580_p3.txt\n",
            " create mode 100644 train-data/100216754_p0.caption\n",
            " create mode 100644 train-data/100216754_p0.npz\n",
            " create mode 100644 train-data/100216754_p0.txt\n",
            " create mode 100644 train-data/100216754_p1.caption\n",
            " create mode 100644 train-data/100216754_p1.npz\n",
            " create mode 100644 train-data/100216754_p1.txt\n",
            " create mode 100644 train-data/100216754_p2.caption\n",
            " create mode 100644 train-data/100216754_p2.npz\n",
            " create mode 100644 train-data/100216754_p2.txt\n",
            " create mode 100644 train-data/100216754_p3.caption\n",
            " create mode 100644 train-data/100216754_p3.npz\n",
            " create mode 100644 train-data/100216754_p3.txt\n",
            " create mode 100644 train-data/100240810_p0.caption\n",
            " create mode 100644 train-data/100240810_p0.npz\n",
            " create mode 100644 train-data/100240810_p0.txt\n",
            " create mode 100644 train-data/100240810_p1.caption\n",
            " create mode 100644 train-data/100240810_p1.npz\n",
            " create mode 100644 train-data/100240810_p1.txt\n",
            " create mode 100644 train-data/100240810_p2.caption\n",
            " create mode 100644 train-data/100240810_p2.npz\n",
            " create mode 100644 train-data/100240810_p2.txt\n",
            " create mode 100644 train-data/100240810_p3.caption\n",
            " create mode 100644 train-data/100240810_p3.npz\n",
            " create mode 100644 train-data/100240810_p3.txt\n",
            " create mode 100644 train-data/100263499_p0.caption\n",
            " create mode 100644 train-data/100263499_p0.npz\n",
            " create mode 100644 train-data/100263499_p0.txt\n",
            " create mode 100644 train-data/100263499_p1.caption\n",
            " create mode 100644 train-data/100263499_p1.npz\n",
            " create mode 100644 train-data/100263499_p1.txt\n",
            " create mode 100644 train-data/100263499_p2.caption\n",
            " create mode 100644 train-data/100263499_p2.npz\n",
            " create mode 100644 train-data/100263499_p2.txt\n",
            " create mode 100644 train-data/100263499_p3.caption\n",
            " create mode 100644 train-data/100263499_p3.npz\n",
            " create mode 100644 train-data/100263499_p3.txt\n",
            " create mode 100644 train-data/100291378_p0.caption\n",
            " create mode 100644 train-data/100291378_p0.npz\n",
            " create mode 100644 train-data/100291378_p0.txt\n",
            " create mode 100644 train-data/100291378_p1.caption\n",
            " create mode 100644 train-data/100291378_p1.npz\n",
            " create mode 100644 train-data/100291378_p1.txt\n",
            " create mode 100644 train-data/100291378_p2.caption\n",
            " create mode 100644 train-data/100291378_p2.npz\n",
            " create mode 100644 train-data/100291378_p2.txt\n",
            " create mode 100644 train-data/100291378_p3.caption\n",
            " create mode 100644 train-data/100291378_p3.npz\n",
            " create mode 100644 train-data/100291378_p3.txt\n",
            " create mode 100644 train-data/100348345_p0.caption\n",
            " create mode 100644 train-data/100348345_p0.npz\n",
            " create mode 100644 train-data/100348345_p0.txt\n",
            " create mode 100644 train-data/100348345_p1.caption\n",
            " create mode 100644 train-data/100348345_p1.npz\n",
            " create mode 100644 train-data/100348345_p1.txt\n",
            " create mode 100644 train-data/100348345_p2.caption\n",
            " create mode 100644 train-data/100348345_p2.npz\n",
            " create mode 100644 train-data/100348345_p2.txt\n",
            " create mode 100644 train-data/100348345_p3.caption\n",
            " create mode 100644 train-data/100348345_p3.npz\n",
            " create mode 100644 train-data/100348345_p3.txt\n",
            " create mode 100644 train-data/100348351_p0.caption\n",
            " create mode 100644 train-data/100348351_p0.npz\n",
            " create mode 100644 train-data/100348351_p0.txt\n",
            " create mode 100644 train-data/100348351_p1.caption\n",
            " create mode 100644 train-data/100348351_p1.npz\n",
            " create mode 100644 train-data/100348351_p1.txt\n",
            " create mode 100644 train-data/100372302_p0.caption\n",
            " create mode 100644 train-data/100372302_p0.npz\n",
            " create mode 100644 train-data/100372302_p0.txt\n",
            " create mode 100644 train-data/100372302_p1.caption\n",
            " create mode 100644 train-data/100372302_p1.npz\n",
            " create mode 100644 train-data/100372302_p1.txt\n",
            " create mode 100644 train-data/100372302_p2.caption\n",
            " create mode 100644 train-data/100372302_p2.npz\n",
            " create mode 100644 train-data/100372302_p2.txt\n",
            " create mode 100644 train-data/100372302_p3.caption\n",
            " create mode 100644 train-data/100372302_p3.npz\n",
            " create mode 100644 train-data/100372302_p3.txt\n",
            " create mode 100644 train-data/100396592_p0.caption\n",
            " create mode 100644 train-data/100396592_p0.npz\n",
            " create mode 100644 train-data/100396592_p0.txt\n",
            " create mode 100644 train-data/100396592_p1.caption\n",
            " create mode 100644 train-data/100396592_p1.npz\n",
            " create mode 100644 train-data/100396592_p1.txt\n",
            " create mode 100644 train-data/100396592_p2.caption\n",
            " create mode 100644 train-data/100396592_p2.npz\n",
            " create mode 100644 train-data/100396592_p2.txt\n",
            " create mode 100644 train-data/100396592_p3.caption\n",
            " create mode 100644 train-data/100396592_p3.npz\n",
            " create mode 100644 train-data/100396592_p3.txt\n",
            " create mode 100644 train-data/100447647_p1.caption\n",
            " create mode 100644 train-data/100447647_p1.npz\n",
            " create mode 100644 train-data/100447647_p1.txt\n",
            " create mode 100644 train-data/100447647_p2.caption\n",
            " create mode 100644 train-data/100447647_p2.npz\n",
            " create mode 100644 train-data/100447647_p2.txt\n",
            " create mode 100644 train-data/100447647_p3.caption\n",
            " create mode 100644 train-data/100447647_p3.npz\n",
            " create mode 100644 train-data/100447647_p3.txt\n",
            " create mode 100644 train-data/100473479_p0.caption\n",
            " create mode 100644 train-data/100473479_p0.npz\n",
            " create mode 100644 train-data/100473479_p0.txt\n",
            " create mode 100644 train-data/100473479_p1.caption\n",
            " create mode 100644 train-data/100473479_p1.npz\n",
            " create mode 100644 train-data/100473479_p1.txt\n",
            " create mode 100644 train-data/100473479_p2.caption\n",
            " create mode 100644 train-data/100473479_p2.npz\n",
            " create mode 100644 train-data/100473479_p2.txt\n",
            " create mode 100644 train-data/100473479_p3.caption\n",
            " create mode 100644 train-data/100473479_p3.npz\n",
            " create mode 100644 train-data/100473479_p3.txt\n",
            " create mode 100644 train-data/100520072_p0.caption\n",
            " create mode 100644 train-data/100520072_p0.npz\n",
            " create mode 100644 train-data/100520072_p0.txt\n",
            " create mode 100644 train-data/100520072_p1.caption\n",
            " create mode 100644 train-data/100520072_p1.npz\n",
            " create mode 100644 train-data/100520072_p1.txt\n",
            " create mode 100644 train-data/100520072_p2.caption\n",
            " create mode 100644 train-data/100520072_p2.npz\n",
            " create mode 100644 train-data/100520072_p2.txt\n",
            " create mode 100644 train-data/100520072_p3.caption\n",
            " create mode 100644 train-data/100520072_p3.npz\n",
            " create mode 100644 train-data/100520072_p3.txt\n",
            " create mode 100644 train-data/100549860_p0.caption\n",
            " create mode 100644 train-data/100549860_p0.npz\n",
            " create mode 100644 train-data/100549860_p0.txt\n",
            " create mode 100644 train-data/100549860_p1.caption\n",
            " create mode 100644 train-data/100549860_p1.npz\n",
            " create mode 100644 train-data/100549860_p1.txt\n",
            " create mode 100644 train-data/100549860_p2.caption\n",
            " create mode 100644 train-data/100549860_p2.npz\n",
            " create mode 100644 train-data/100549860_p2.txt\n",
            " create mode 100644 train-data/100549860_p3.caption\n",
            " create mode 100644 train-data/100549860_p3.npz\n",
            " create mode 100644 train-data/100549860_p3.txt\n",
            " create mode 100644 train-data/100597148_p0.caption\n",
            " create mode 100644 train-data/100597148_p0.npz\n",
            " create mode 100644 train-data/100597148_p0.txt\n",
            " create mode 100644 train-data/100597148_p1.caption\n",
            " create mode 100644 train-data/100597148_p1.npz\n",
            " create mode 100644 train-data/100597148_p1.txt\n",
            " create mode 100644 train-data/100597148_p2.caption\n",
            " create mode 100644 train-data/100597148_p2.npz\n",
            " create mode 100644 train-data/100597148_p2.txt\n",
            " create mode 100644 train-data/100597148_p3.caption\n",
            " create mode 100644 train-data/100597148_p3.npz\n",
            " create mode 100644 train-data/100597148_p3.txt\n",
            " create mode 100644 train-data/100622551_p0.caption\n",
            " create mode 100644 train-data/100622551_p0.npz\n",
            " create mode 100644 train-data/100622551_p0.txt\n",
            " create mode 100644 train-data/100622551_p1.caption\n",
            " create mode 100644 train-data/100622551_p1.npz\n",
            " create mode 100644 train-data/100622551_p1.txt\n",
            " create mode 100644 train-data/100622551_p2.caption\n",
            " create mode 100644 train-data/100622551_p2.npz\n",
            " create mode 100644 train-data/100622551_p2.txt\n",
            " create mode 100644 train-data/100622551_p3.caption\n",
            " create mode 100644 train-data/100622551_p3.npz\n",
            " create mode 100644 train-data/100622551_p3.txt\n",
            " create mode 100644 train-data/100678134_p0.caption\n",
            " create mode 100644 train-data/100678134_p0.npz\n",
            " create mode 100644 train-data/100678134_p0.txt\n",
            " create mode 100644 train-data/100678134_p1.caption\n",
            " create mode 100644 train-data/100678134_p1.npz\n",
            " create mode 100644 train-data/100678134_p1.txt\n",
            " create mode 100644 train-data/100678134_p2.caption\n",
            " create mode 100644 train-data/100678134_p2.npz\n",
            " create mode 100644 train-data/100678134_p2.txt\n",
            " create mode 100644 train-data/100678134_p3.caption\n",
            " create mode 100644 train-data/100678134_p3.npz\n",
            " create mode 100644 train-data/100678134_p3.txt\n",
            " create mode 100644 train-data/100701568_p0.caption\n",
            " create mode 100644 train-data/100701568_p0.npz\n",
            " create mode 100644 train-data/100701568_p0.txt\n",
            " create mode 100644 train-data/100701568_p1.caption\n",
            " create mode 100644 train-data/100701568_p1.npz\n",
            " create mode 100644 train-data/100701568_p1.txt\n",
            " create mode 100644 train-data/100701568_p2.caption\n",
            " create mode 100644 train-data/100701568_p2.npz\n",
            " create mode 100644 train-data/100701568_p2.txt\n",
            " create mode 100644 train-data/100701568_p3.caption\n",
            " create mode 100644 train-data/100701568_p3.npz\n",
            " create mode 100644 train-data/100701568_p3.txt\n",
            " create mode 100644 train-data/100746113_p0.caption\n",
            " create mode 100644 train-data/100746113_p0.npz\n",
            " create mode 100644 train-data/100746113_p0.txt\n",
            " create mode 100644 train-data/100746113_p1.caption\n",
            " create mode 100644 train-data/100746113_p1.npz\n",
            " create mode 100644 train-data/100746113_p1.txt\n",
            " create mode 100644 train-data/100746113_p2.caption\n",
            " create mode 100644 train-data/100746113_p2.npz\n",
            " create mode 100644 train-data/100746113_p2.txt\n",
            " create mode 100644 train-data/100746113_p3.caption\n",
            " create mode 100644 train-data/100746113_p3.npz\n",
            " create mode 100644 train-data/100746113_p3.txt\n",
            " create mode 100644 train-data/100746114_p0.caption\n",
            " create mode 100644 train-data/100746114_p0.npz\n",
            " create mode 100644 train-data/100746114_p0.txt\n",
            " create mode 100644 train-data/100746114_p1.caption\n",
            " create mode 100644 train-data/100746114_p1.npz\n",
            " create mode 100644 train-data/100746114_p1.txt\n",
            " create mode 100644 train-data/100746114_p2.caption\n",
            " create mode 100644 train-data/100746114_p2.npz\n",
            " create mode 100644 train-data/100746114_p2.txt\n",
            " create mode 100644 train-data/100746114_p3.caption\n",
            " create mode 100644 train-data/100746114_p3.npz\n",
            " create mode 100644 train-data/100746114_p3.txt\n",
            " create mode 100644 train-data/100767903_p0.caption\n",
            " create mode 100644 train-data/100767903_p0.npz\n",
            " create mode 100644 train-data/100767903_p0.txt\n",
            " create mode 100644 train-data/100767903_p1.caption\n",
            " create mode 100644 train-data/100767903_p1.npz\n",
            " create mode 100644 train-data/100767903_p1.txt\n",
            " create mode 100644 train-data/100767903_p2.caption\n",
            " create mode 100644 train-data/100767903_p2.npz\n",
            " create mode 100644 train-data/100767903_p2.txt\n",
            " create mode 100644 train-data/100767903_p3.caption\n",
            " create mode 100644 train-data/100767903_p3.npz\n",
            " create mode 100644 train-data/100767903_p3.txt\n",
            " create mode 100644 train-data/100767907_p0.caption\n",
            " create mode 100644 train-data/100767907_p0.npz\n",
            " create mode 100644 train-data/100767907_p0.txt\n",
            " create mode 100644 train-data/100767907_p1.caption\n",
            " create mode 100644 train-data/100767907_p1.npz\n",
            " create mode 100644 train-data/100767907_p1.txt\n",
            " create mode 100644 train-data/100767907_p2.caption\n",
            " create mode 100644 train-data/100767907_p2.npz\n",
            " create mode 100644 train-data/100767907_p2.txt\n",
            " create mode 100644 train-data/100767907_p3.caption\n",
            " create mode 100644 train-data/100767907_p3.npz\n",
            " create mode 100644 train-data/100767907_p3.txt\n",
            " create mode 100644 train-data/100843574_p0.caption\n",
            " create mode 100644 train-data/100843574_p0.npz\n",
            " create mode 100644 train-data/100843574_p0.txt\n",
            " create mode 100644 train-data/100843574_p1.caption\n",
            " create mode 100644 train-data/100843574_p1.npz\n",
            " create mode 100644 train-data/100843574_p1.txt\n",
            " create mode 100644 train-data/100843574_p2.caption\n",
            " create mode 100644 train-data/100843574_p2.npz\n",
            " create mode 100644 train-data/100843574_p2.txt\n",
            " create mode 100644 train-data/100843574_p3.caption\n",
            " create mode 100644 train-data/100843574_p3.npz\n",
            " create mode 100644 train-data/100843574_p3.txt\n",
            " create mode 100644 train-data/100865274_p0.caption\n",
            " create mode 100644 train-data/100865274_p0.npz\n",
            " create mode 100644 train-data/100865274_p0.txt\n",
            " create mode 100644 train-data/100865274_p1.caption\n",
            " create mode 100644 train-data/100865274_p1.npz\n",
            " create mode 100644 train-data/100865274_p1.txt\n",
            " create mode 100644 train-data/100865274_p2.caption\n",
            " create mode 100644 train-data/100865274_p2.npz\n",
            " create mode 100644 train-data/100865274_p2.txt\n",
            " create mode 100644 train-data/100865274_p3.caption\n",
            " create mode 100644 train-data/100865274_p3.npz\n",
            " create mode 100644 train-data/100865274_p3.txt\n",
            " create mode 100644 train-data/100865279_p0.caption\n",
            " create mode 100644 train-data/100865279_p0.npz\n",
            " create mode 100644 train-data/100865279_p0.txt\n",
            " create mode 100644 train-data/100865279_p1.caption\n",
            " create mode 100644 train-data/100865279_p1.npz\n",
            " create mode 100644 train-data/100865279_p1.txt\n",
            " create mode 100644 train-data/100865279_p2.caption\n",
            " create mode 100644 train-data/100865279_p2.npz\n",
            " create mode 100644 train-data/100865279_p2.txt\n",
            " create mode 100644 train-data/100865279_p3.caption\n",
            " create mode 100644 train-data/100865279_p3.npz\n",
            " create mode 100644 train-data/100865279_p3.txt\n",
            " create mode 100644 train-data/100910899_p0.caption\n",
            " create mode 100644 train-data/100910899_p0.npz\n",
            " create mode 100644 train-data/100910899_p0.txt\n",
            " create mode 100644 train-data/100910899_p1.caption\n",
            " create mode 100644 train-data/100910899_p1.npz\n",
            " create mode 100644 train-data/100910899_p1.txt\n",
            " create mode 100644 train-data/100910899_p2.caption\n",
            " create mode 100644 train-data/100910899_p2.npz\n",
            " create mode 100644 train-data/100910899_p2.txt\n",
            " create mode 100644 train-data/100910899_p3.caption\n",
            " create mode 100644 train-data/100910899_p3.npz\n",
            " create mode 100644 train-data/100910899_p3.txt\n",
            " create mode 100644 train-data/100914727_p0.caption\n",
            " create mode 100644 train-data/100914727_p0.npz\n",
            " create mode 100644 train-data/100914727_p0.txt\n",
            " create mode 100644 train-data/100914727_p1.caption\n",
            " create mode 100644 train-data/100914727_p1.npz\n",
            " create mode 100644 train-data/100914727_p1.txt\n",
            " create mode 100644 train-data/100914727_p2.caption\n",
            " create mode 100644 train-data/100914727_p2.npz\n",
            " create mode 100644 train-data/100914727_p2.txt\n",
            " create mode 100644 train-data/100914727_p3.caption\n",
            " create mode 100644 train-data/100914727_p3.npz\n",
            " create mode 100644 train-data/100914727_p3.txt\n",
            " create mode 100644 train-data/100915486_p0.caption\n",
            " create mode 100644 train-data/100915486_p0.npz\n",
            " create mode 100644 train-data/100915486_p0.txt\n",
            " create mode 100644 train-data/100915486_p1.caption\n",
            " create mode 100644 train-data/100915486_p1.npz\n",
            " create mode 100644 train-data/100915486_p1.txt\n",
            " create mode 100644 train-data/100915486_p2.caption\n",
            " create mode 100644 train-data/100915486_p2.npz\n",
            " create mode 100644 train-data/100915486_p2.txt\n",
            " create mode 100644 train-data/100915486_p3.caption\n",
            " create mode 100644 train-data/100915486_p3.npz\n",
            " create mode 100644 train-data/100915486_p3.txt\n",
            " create mode 100644 train-data/100937066_p0.caption\n",
            " create mode 100644 train-data/100937066_p0.npz\n",
            " create mode 100644 train-data/100937066_p0.txt\n",
            " create mode 100644 train-data/100937066_p1.caption\n",
            " create mode 100644 train-data/100937066_p1.npz\n",
            " create mode 100644 train-data/100937066_p1.txt\n",
            " create mode 100644 train-data/100937066_p2.caption\n",
            " create mode 100644 train-data/100937066_p2.npz\n",
            " create mode 100644 train-data/100937066_p2.txt\n",
            " create mode 100644 train-data/100937066_p3.caption\n",
            " create mode 100644 train-data/100937066_p3.npz\n",
            " create mode 100644 train-data/100937066_p3.txt\n",
            " create mode 100644 train-data/100937068_p0.caption\n",
            " create mode 100644 train-data/100937068_p0.npz\n",
            " create mode 100644 train-data/100937068_p0.txt\n",
            " create mode 100644 train-data/100937068_p1.caption\n",
            " create mode 100644 train-data/100937068_p1.npz\n",
            " create mode 100644 train-data/100937068_p1.txt\n",
            " create mode 100644 train-data/100937068_p2.caption\n",
            " create mode 100644 train-data/100937068_p2.npz\n",
            " create mode 100644 train-data/100937068_p2.txt\n",
            " create mode 100644 train-data/100937068_p3.caption\n",
            " create mode 100644 train-data/100937068_p3.npz\n",
            " create mode 100644 train-data/100937068_p3.txt\n",
            " create mode 100644 train-data/101012802_p0.caption\n",
            " create mode 100644 train-data/101012802_p0.npz\n",
            " create mode 100644 train-data/101012802_p0.txt\n",
            " create mode 100644 train-data/101012802_p1.caption\n",
            " create mode 100644 train-data/101012802_p1.npz\n",
            " create mode 100644 train-data/101012802_p1.txt\n",
            " create mode 100644 train-data/101012802_p2.caption\n",
            " create mode 100644 train-data/101012802_p2.npz\n",
            " create mode 100644 train-data/101012802_p2.txt\n",
            " create mode 100644 train-data/101012802_p3.caption\n",
            " create mode 100644 train-data/101012802_p3.npz\n",
            " create mode 100644 train-data/101012802_p3.txt\n",
            " create mode 100644 train-data/101012804_p0.caption\n",
            " create mode 100644 train-data/101012804_p0.npz\n",
            " create mode 100644 train-data/101012804_p0.txt\n",
            " create mode 100644 train-data/101012804_p1.caption\n",
            " create mode 100644 train-data/101012804_p1.npz\n",
            " create mode 100644 train-data/101012804_p1.txt\n",
            " create mode 100644 train-data/101012804_p2.caption\n",
            " create mode 100644 train-data/101012804_p2.npz\n",
            " create mode 100644 train-data/101012804_p2.txt\n",
            " create mode 100644 train-data/101012804_p3.caption\n",
            " create mode 100644 train-data/101012804_p3.npz\n",
            " create mode 100644 train-data/101012804_p3.txt\n",
            " create mode 100644 train-data/101026771_p0.caption\n",
            " create mode 100644 train-data/101026771_p0.npz\n",
            " create mode 100644 train-data/101026771_p0.txt\n",
            " create mode 100644 train-data/101026771_p1.caption\n",
            " create mode 100644 train-data/101026771_p1.npz\n",
            " create mode 100644 train-data/101026771_p1.txt\n",
            " create mode 100644 train-data/101026771_p2.caption\n",
            " create mode 100644 train-data/101026771_p2.npz\n",
            " create mode 100644 train-data/101026771_p2.txt\n",
            " create mode 100644 train-data/101026771_p3.caption\n",
            " create mode 100644 train-data/101026771_p3.npz\n",
            " create mode 100644 train-data/101026771_p3.txt\n",
            " create mode 100644 train-data/101035262_p0.caption\n",
            " create mode 100644 train-data/101035262_p0.npz\n",
            " create mode 100644 train-data/101035262_p0.txt\n",
            " create mode 100644 train-data/101035262_p1.caption\n",
            " create mode 100644 train-data/101035262_p1.npz\n",
            " create mode 100644 train-data/101035262_p1.txt\n",
            " create mode 100644 train-data/101035262_p2.caption\n",
            " create mode 100644 train-data/101035262_p2.npz\n",
            " create mode 100644 train-data/101035262_p2.txt\n",
            " create mode 100644 train-data/101035262_p3.caption\n",
            " create mode 100644 train-data/101035262_p3.npz\n",
            " create mode 100644 train-data/101035262_p3.txt\n",
            " create mode 100644 train-data/101057037_p0.caption\n",
            " create mode 100644 train-data/101057037_p0.npz\n",
            " create mode 100644 train-data/101057037_p0.txt\n",
            " create mode 100644 train-data/101057037_p1.caption\n",
            " create mode 100644 train-data/101057037_p1.npz\n",
            " create mode 100644 train-data/101057037_p1.txt\n",
            " create mode 100644 train-data/101057037_p2.caption\n",
            " create mode 100644 train-data/101057037_p2.npz\n",
            " create mode 100644 train-data/101057037_p2.txt\n",
            " create mode 100644 train-data/101057037_p3.caption\n",
            " create mode 100644 train-data/101057037_p3.npz\n",
            " create mode 100644 train-data/101057037_p3.txt\n",
            " create mode 100644 train-data/101070445_p0.caption\n",
            " create mode 100644 train-data/101070445_p0.npz\n",
            " create mode 100644 train-data/101070445_p0.txt\n",
            " create mode 100644 train-data/101070445_p1.caption\n",
            " create mode 100644 train-data/101070445_p1.npz\n",
            " create mode 100644 train-data/101070445_p1.txt\n",
            " create mode 100644 train-data/101070445_p2.caption\n",
            " create mode 100644 train-data/101070445_p2.npz\n",
            " create mode 100644 train-data/101070445_p2.txt\n",
            " create mode 100644 train-data/101070445_p3.caption\n",
            " create mode 100644 train-data/101070445_p3.npz\n",
            " create mode 100644 train-data/101070445_p3.txt\n",
            " create mode 100644 train-data/101078216_p0.caption\n",
            " create mode 100644 train-data/101078216_p0.npz\n",
            " create mode 100644 train-data/101078216_p0.txt\n",
            " create mode 100644 train-data/101078216_p1.caption\n",
            " create mode 100644 train-data/101078216_p1.npz\n",
            " create mode 100644 train-data/101078216_p1.txt\n",
            " create mode 100644 train-data/101078216_p2.caption\n",
            " create mode 100644 train-data/101078216_p2.npz\n",
            " create mode 100644 train-data/101078216_p2.txt\n",
            " create mode 100644 train-data/101078216_p3.caption\n",
            " create mode 100644 train-data/101078216_p3.npz\n",
            " create mode 100644 train-data/101078216_p3.txt\n",
            " create mode 100644 train-data/101091445_p0.caption\n",
            " create mode 100644 train-data/101091445_p0.npz\n",
            " create mode 100644 train-data/101091445_p0.txt\n",
            " create mode 100644 train-data/101091445_p1.caption\n",
            " create mode 100644 train-data/101091445_p1.npz\n",
            " create mode 100644 train-data/101091445_p1.txt\n",
            " create mode 100644 train-data/101091445_p2.caption\n",
            " create mode 100644 train-data/101091445_p2.npz\n",
            " create mode 100644 train-data/101091445_p2.txt\n",
            " create mode 100644 train-data/101091445_p3.caption\n",
            " create mode 100644 train-data/101091445_p3.npz\n",
            " create mode 100644 train-data/101091445_p3.txt\n",
            " create mode 100644 train-data/101099450_p0.caption\n",
            " create mode 100644 train-data/101099450_p0.npz\n",
            " create mode 100644 train-data/101099450_p0.txt\n",
            " create mode 100644 train-data/101099450_p1.caption\n",
            " create mode 100644 train-data/101099450_p1.npz\n",
            " create mode 100644 train-data/101099450_p1.txt\n",
            " create mode 100644 train-data/101099450_p2.caption\n",
            " create mode 100644 train-data/101099450_p2.npz\n",
            " create mode 100644 train-data/101099450_p2.txt\n",
            " create mode 100644 train-data/101099450_p3.caption\n",
            " create mode 100644 train-data/101099450_p3.npz\n",
            " create mode 100644 train-data/101099450_p3.txt\n",
            " create mode 100644 train-data/101101543_p0.caption\n",
            " create mode 100644 train-data/101101543_p0.npz\n",
            " create mode 100644 train-data/101101543_p0.txt\n",
            " create mode 100644 train-data/101101543_p1.caption\n",
            " create mode 100644 train-data/101101543_p1.npz\n",
            " create mode 100644 train-data/101101543_p1.txt\n",
            " create mode 100644 train-data/101101543_p2.caption\n",
            " create mode 100644 train-data/101101543_p2.npz\n",
            " create mode 100644 train-data/101101543_p2.txt\n",
            " create mode 100644 train-data/101101543_p3.caption\n",
            " create mode 100644 train-data/101101543_p3.npz\n",
            " create mode 100644 train-data/101101543_p3.txt\n",
            " create mode 100644 train-data/101113352_p0.caption\n",
            " create mode 100644 train-data/101113352_p0.npz\n",
            " create mode 100644 train-data/101113352_p0.txt\n",
            " create mode 100644 train-data/101113352_p1.caption\n",
            " create mode 100644 train-data/101113352_p1.npz\n",
            " create mode 100644 train-data/101113352_p1.txt\n",
            " create mode 100644 train-data/101113352_p2.caption\n",
            " create mode 100644 train-data/101113352_p2.npz\n",
            " create mode 100644 train-data/101113352_p2.txt\n",
            " create mode 100644 train-data/101113352_p3.caption\n",
            " create mode 100644 train-data/101113352_p3.npz\n",
            " create mode 100644 train-data/101113352_p3.txt\n",
            " create mode 100644 train-data/101122547_p0.caption\n",
            " create mode 100644 train-data/101122547_p0.npz\n",
            " create mode 100644 train-data/101122547_p0.txt\n",
            " create mode 100644 train-data/101122547_p1.caption\n",
            " create mode 100644 train-data/101122547_p1.npz\n",
            " create mode 100644 train-data/101122547_p1.txt\n",
            " create mode 100644 train-data/101122547_p2.caption\n",
            " create mode 100644 train-data/101122547_p2.npz\n",
            " create mode 100644 train-data/101122547_p2.txt\n",
            " create mode 100644 train-data/101122547_p3.caption\n",
            " create mode 100644 train-data/101122547_p3.npz\n",
            " create mode 100644 train-data/101122547_p3.txt\n",
            " create mode 100644 train-data/101174576_p0.caption\n",
            " create mode 100644 train-data/101174576_p0.npz\n",
            " create mode 100644 train-data/101174576_p0.txt\n",
            " create mode 100644 train-data/101174576_p1.caption\n",
            " create mode 100644 train-data/101174576_p1.npz\n",
            " create mode 100644 train-data/101174576_p1.txt\n",
            " create mode 100644 train-data/101174576_p2.caption\n",
            " create mode 100644 train-data/101174576_p2.npz\n",
            " create mode 100644 train-data/101174576_p2.txt\n",
            " create mode 100644 train-data/101174576_p3.caption\n",
            " create mode 100644 train-data/101174576_p3.npz\n",
            " create mode 100644 train-data/101174576_p3.txt\n",
            " create mode 100644 train-data/101188440_p0.caption\n",
            " create mode 100644 train-data/101188440_p0.npz\n",
            " create mode 100644 train-data/101188440_p0.txt\n",
            " create mode 100644 train-data/101188440_p1.caption\n",
            " create mode 100644 train-data/101188440_p1.npz\n",
            " create mode 100644 train-data/101188440_p1.txt\n",
            " create mode 100644 train-data/101188440_p2.caption\n",
            " create mode 100644 train-data/101188440_p2.npz\n",
            " create mode 100644 train-data/101188440_p2.txt\n",
            " create mode 100644 train-data/101188440_p3.caption\n",
            " create mode 100644 train-data/101188440_p3.npz\n",
            " create mode 100644 train-data/101188440_p3.txt\n",
            " create mode 100644 train-data/101230384_p0.caption\n",
            " create mode 100644 train-data/101230384_p0.npz\n",
            " create mode 100644 train-data/101230384_p0.txt\n",
            " create mode 100644 train-data/101230384_p1.caption\n",
            " create mode 100644 train-data/101230384_p1.npz\n",
            " create mode 100644 train-data/101230384_p1.txt\n",
            " create mode 100644 train-data/101230384_p2.caption\n",
            " create mode 100644 train-data/101230384_p2.npz\n",
            " create mode 100644 train-data/101230384_p2.txt\n",
            " create mode 100644 train-data/101230384_p3.caption\n",
            " create mode 100644 train-data/101230384_p3.npz\n",
            " create mode 100644 train-data/101230384_p3.txt\n",
            " create mode 100644 train-data/101333961_p0.caption\n",
            " create mode 100644 train-data/101333961_p0.npz\n",
            " create mode 100644 train-data/101333961_p0.txt\n",
            " create mode 100644 train-data/101333961_p1.caption\n",
            " create mode 100644 train-data/101333961_p1.npz\n",
            " create mode 100644 train-data/101333961_p1.txt\n",
            " create mode 100644 train-data/101333961_p2.caption\n",
            " create mode 100644 train-data/101333961_p2.npz\n",
            " create mode 100644 train-data/101333961_p2.txt\n",
            " create mode 100644 train-data/101333961_p3.caption\n",
            " create mode 100644 train-data/101333961_p3.npz\n",
            " create mode 100644 train-data/101333961_p3.txt\n",
            " create mode 100644 train-data/101344054_p0.caption\n",
            " create mode 100644 train-data/101344054_p0.npz\n",
            " create mode 100644 train-data/101344054_p0.txt\n",
            " create mode 100644 train-data/101344054_p1.caption\n",
            " create mode 100644 train-data/101344054_p1.npz\n",
            " create mode 100644 train-data/101344054_p1.txt\n",
            " create mode 100644 train-data/101344054_p2.caption\n",
            " create mode 100644 train-data/101344054_p2.npz\n",
            " create mode 100644 train-data/101344054_p2.txt\n",
            " create mode 100644 train-data/101344054_p3.caption\n",
            " create mode 100644 train-data/101344054_p3.npz\n",
            " create mode 100644 train-data/101344054_p3.txt\n",
            " create mode 100644 train-data/101351557_p0.caption\n",
            " create mode 100644 train-data/101351557_p0.npz\n",
            " create mode 100644 train-data/101351557_p0.txt\n",
            " create mode 100644 train-data/101351557_p1.caption\n",
            " create mode 100644 train-data/101351557_p1.npz\n",
            " create mode 100644 train-data/101351557_p1.txt\n",
            " create mode 100644 train-data/101351557_p2.caption\n",
            " create mode 100644 train-data/101351557_p2.npz\n",
            " create mode 100644 train-data/101351557_p2.txt\n",
            " create mode 100644 train-data/101360008_p0.caption\n",
            " create mode 100644 train-data/101360008_p0.npz\n",
            " create mode 100644 train-data/101360008_p0.txt\n",
            " create mode 100644 train-data/101360008_p1.caption\n",
            " create mode 100644 train-data/101360008_p1.npz\n",
            " create mode 100644 train-data/101360008_p1.txt\n",
            " create mode 100644 train-data/101360008_p2.caption\n",
            " create mode 100644 train-data/101360008_p2.npz\n",
            " create mode 100644 train-data/101360008_p2.txt\n",
            " create mode 100644 train-data/101360008_p3.caption\n",
            " create mode 100644 train-data/101360008_p3.npz\n",
            " create mode 100644 train-data/101360008_p3.txt\n",
            " create mode 100644 train-data/101373082_p0.caption\n",
            " create mode 100644 train-data/101373082_p0.npz\n",
            " create mode 100644 train-data/101373082_p0.txt\n",
            " create mode 100644 train-data/101373082_p1.caption\n",
            " create mode 100644 train-data/101373082_p1.npz\n",
            " create mode 100644 train-data/101373082_p1.txt\n",
            " create mode 100644 train-data/101373082_p2.caption\n",
            " create mode 100644 train-data/101373082_p2.npz\n",
            " create mode 100644 train-data/101373082_p2.txt\n",
            " create mode 100644 train-data/101373082_p3.caption\n",
            " create mode 100644 train-data/101373082_p3.npz\n",
            " create mode 100644 train-data/101373082_p3.txt\n",
            " create mode 100644 train-data/101373102_p0.caption\n",
            " create mode 100644 train-data/101373102_p0.npz\n",
            " create mode 100644 train-data/101373102_p0.txt\n",
            " create mode 100644 train-data/101373102_p1.caption\n",
            " create mode 100644 train-data/101373102_p1.npz\n",
            " create mode 100644 train-data/101373102_p1.txt\n",
            " create mode 100644 train-data/101373102_p2.caption\n",
            " create mode 100644 train-data/101373102_p2.npz\n",
            " create mode 100644 train-data/101373102_p2.txt\n",
            " create mode 100644 train-data/101373102_p3.caption\n",
            " create mode 100644 train-data/101373102_p3.npz\n",
            " create mode 100644 train-data/101373102_p3.txt\n",
            "Git LFS: (200 of 200 files) 11.68 MB / 11.68 MB\n",
            "Counting objects: 603, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (508/508), done.\n",
            "Writing objects: 100% (603/603), 81.98 KiB | 3.73 MiB/s, done.\n",
            "Total 603 (delta 7), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (7/7), done.\u001b[K\n",
            "remote: Scanning LFS files for validity, may be slow...\u001b[K\n",
            "remote: LFS file scan complete.\u001b[K\n",
            "To https://huggingface.co/datasets/Linaqruf/tarte-midjourney\n",
            "   fe2b2a1..c8577d3  main -> main\n"
          ]
        }
      ],
      "source": [
        "#@title Commit Model or Datasets to Huggingface\n",
        "\n",
        "#@markdown Type of item to commit (model or dataset)\n",
        "type_of_item = \"model\" #@param [\"model\", \"dataset\"]\n",
        "\n",
        "%cd /content\n",
        "#@markdown Go to your model or dataset path\n",
        "item_path = \"your-cloned-model-or-datasets-repo\" #@param {'type': 'string'}\n",
        "\n",
        "#@markdown #Git Commit\n",
        "\n",
        "#@markdown Set **git commit identity**\n",
        "email = \"your-email\" #@param {'type': 'string'}\n",
        "name = \"your-username\" #@param {'type': 'string'}\n",
        "#@markdown Set **commit message**\n",
        "commit_m = \"feat: upload 6 epochs model\" #@param {'type': 'string'}\n",
        "\n",
        "%cd {item_path}\n",
        "!git lfs install\n",
        "!huggingface-cli lfs-enable-largefiles .\n",
        "!git add .\n",
        "!git lfs help smudge\n",
        "!git config --global user.email \"{email}\"\n",
        "!git config --global user.name \"{name}\"\n",
        "!git commit -m \"{commit_m}\"\n",
        "!git push\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}