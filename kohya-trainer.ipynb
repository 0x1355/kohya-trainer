{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/dev/kohya-trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "# Kohya Trainer V11 - VRAM 12GB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      },
      "source": [
        "This notebook has been adapted for use in Google Colab based on [kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts). </br>\n",
        "This notebook was adapted by [Linaqruf](https://github.com/Linaqruf)</br>\n",
        "You can find the latest update to the notebook [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# I. Install Kohya Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.1. Clone Kohya Trainer\n",
        "#@markdown Clone Kohya Trainer from GitHub and check for updates. Use textbox below if you want to checkout other branch or old commit. Leave it empty to stay the HEAD on main.\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# Check GPU Availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Define path\n",
        "root_dir = \"/content\"\n",
        "%store root_dir\n",
        "repo_dir = str(root_dir)+\"/kohya-trainer\"\n",
        "%store repo_dir\n",
        "tools_dir = str(root_dir)+\"/kohya-trainer/tools\"\n",
        "%store tools_dir \n",
        "finetune_dir = str(root_dir)+\"/kohya-trainer/finetune\"\n",
        "%store finetune_dir\n",
        "\n",
        "# Define identifier\n",
        "branch = \"dev\" #@param {type: \"string\"}\n",
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "def clone_repo():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir(repo_dir):\n",
        "    %cd {repo_dir}\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    if branch != \"\":\n",
        "      !git pull origin {branch} \n",
        "    else:\n",
        "      !git pull\n",
        "  else:\n",
        "    !git clone {repo_url}\n",
        "\n",
        "def checkout_repo(branch_or_commit):\n",
        "  %cd {repo_dir}\n",
        "  !git checkout {branch_or_commit}\n",
        "\n",
        "# Clone or update the Kohya Trainer repository\n",
        "clone_repo()\n",
        "\n",
        "# Checkout to the specified branch or commit\n",
        "if branch != \"\":\n",
        "  checkout_repo(branch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.2. Installing Dependencies\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "#@markdown This will install required Python packages\n",
        "\n",
        "# Define variable\n",
        "accelerate_config = str(repo_dir)+\"/accelerate_config/config.yaml\"\n",
        "%store accelerate_config\n",
        "colab_ram_patch = True #@param {'type':'boolean'}\n",
        "install_xformers = True #@param {'type':'boolean'}\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "def install_dependencies():\n",
        "\n",
        "  if colab_ram_patch:\n",
        "    !sed -i \"s@cpu@cuda@\" \\\n",
        "    {repo_dir}/train_db.py \\\n",
        "    {repo_dir}/train_network.py \\\n",
        "    {repo_dir}/fine_tune.py \\\n",
        "    {repo_dir}/library/model_util.py \\\n",
        "    {repo_dir}/library/train_util.py \n",
        "\n",
        "    !sed -i \"s@cuda_count@cpu_count@\" \\\n",
        "    {repo_dir}/train_db.py \\\n",
        "    {repo_dir}/train_network.py \\\n",
        "    {repo_dir}/fine_tune.py \\\n",
        "    {repo_dir}/library/model_util.py \\\n",
        "    {repo_dir}/library/train_util.py \n",
        "  \n",
        "  !pip -qqqq install --upgrade -r requirements.txt\n",
        "  !pip -qqqq install --upgrade gallery-dl\n",
        "  !pip -qqqq install --upgrade --no-cache-dir gdown\n",
        "  !apt -qqqq install liblz4-tool aria2\n",
        "\n",
        "  if install_xformers:\n",
        "    !pip -qqqq install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  from accelerate.utils import write_basic_config\n",
        "  if not os.path.exists(accelerate_config):\n",
        "    write_basic_config(save_location = accelerate_config) # Write a config file\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "# Install dependencies\n",
        "install_dependencies()\n",
        "\n",
        "#@markdown After Accelerate updated its version to 0.15.0, you can't manually input the config using\n",
        "#@markdown `!accelerate config` in Google Colab. Instead, a `config.yaml` file will be generated by\n",
        "#@markdown the `write_basic_config()` function. You can find the file [here](/content/kohya-trainer/accelerate_config/config.yaml) after installation.\n",
        "#@markdown if you want to modify it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Sign-in to Cloud Service"
      ],
      "metadata": {
        "id": "qt9EJv5gQXuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 1.3.1. Login to Huggingface hub\n",
        "from huggingface_hub import login\n",
        "%store -r\n",
        "\n",
        "#@markdown 1. Of course, you need a Huggingface account first.\n",
        "#@markdown 2. To create a huggingface token, go to [this link](https://huggingface.co/settings/tokens), then `create new token` or copy available token with the `Write` role.\n",
        "\n",
        "write_token = \"your-write-token-here\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n",
        "\n",
        "%store write_token\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rl2zERHbBQ9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 1.3.2. Mount Drive\n",
        "from google.colab import drive\n",
        "\n",
        "mount_drive = True #@param {type: \"boolean\"}\n",
        "\n",
        "if mount_drive:\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sKL38-WmQsLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gob9_OwTlwh"
      },
      "source": [
        "# II. Pretrained Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 2.1. Download Available Model \n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "installModels = []\n",
        "installv2Models = []\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available model to download:\n",
        "\n",
        "#@markdown ### SD1.x model\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-V3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3-better-vae/resolve/main/any-v3-fp32-better-vae.ckpt\", \\\n",
        "            \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.5-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Rasgeath/self_made_sauce/resolve/main/Kani-anime-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/hesw23168/SD-Elysium-Model/resolve/main/Elysium_Anime_V2.ckpt\", \\\n",
        "            \"https://huggingface.co/prompthero/openjourney-v2/resolve/main/openjourney-v2.ckpt\", \\\n",
        "            \"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/resolve/main/dreamlike-diffusion-1.0.ckpt\", \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Anything-v3-pruned\", \\\n",
        "             \"Anything-v3-better-vae\", \\\n",
        "             \"Anything-v4-pruned\", \\\n",
        "             \"Anything-v4-5-pruned\", \\\n",
        "             \"Kani-anime-pruned\", \\\n",
        "             \"Elysium-anime-V2\", \\\n",
        "             \"OpenJourney-V2\", \\\n",
        "             \"Dreamlike-diffusion-V1-0\", \\\n",
        "             \"Stable-Diffusion-v1-5\"]\n",
        "modelName = \"Anything-v3-better-vae\" #@param [\"\", \"Animefull-final-pruned\", \"Anything-v3-pruned\", \"Anything-v3-better-vae\", \"Anything-v4-pruned\", \"Anything-v4-5-pruned\", \"Kani-anime-pruned\", \"Elysium-anime-V2\", \"OpenJourney-V2\", \"Dreamlike-diffusion-V1-0\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "#@markdown ### SD2.x model\n",
        "v2ModelUrl = [\"\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e1.ckpt\", \\\n",
        "              \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\"]\n",
        "v2ModelList = [\"\", \\\n",
        "              \"stable-diffusion-2-1-base\", \\\n",
        "              \"stable-diffusion-2-1-768v\", \\\n",
        "              \"waifu-diffusion-1-4-anime-e1\", \\\n",
        "              \"waifu-diffusion-1-4-anime-e2\"]\n",
        "v2ModelName = \"\" #@param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"waifu-diffusion-1-4-anime-e1\", \"waifu-diffusion-1-4-anime-e2\"]\n",
        "\n",
        "# Check if user has selected a model\n",
        "if modelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if v2ModelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  hf_token = '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' \n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {root_dir}/pre_trained_model -o {checkpoint_name}.ckpt \"{url}\"\n",
        "\n",
        "def install_checkpoint():\n",
        "  # Iterate through list of models to install\n",
        "  for model in installModels:\n",
        "    # Call install function for each model\n",
        "    install(model[0], model[1])\n",
        "\n",
        "  # Iterate through list of models to install\n",
        "  for v2model in installv2Models:\n",
        "    # Call install function for each v2model\n",
        "    install(v2model[0], v2model[1])\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wmnsZwClN1XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 2.2. Download Custom Model\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "#@markdown ### Custom model\n",
        "modelUrl = \"\" #@param {'type': 'string'}\n",
        "dst = str(root_dir)+\"/pre_trained_model\"\n",
        "\n",
        "if not os.path.exists(dst):\n",
        "    os.makedirs(dst)\n",
        "\n",
        "def install(url):\n",
        "\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    %cd {dst}\n",
        "    !gdown --fuzzy {url}\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in url:\n",
        "      url = url.replace('/blob/', '/resolve/')\n",
        "    #@markdown Change this part with your own huggingface token if you need to download your private model\n",
        "    hf_token = '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' #@param {type:\"string\"}\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst} -Z {url}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst} -Z {url}\n",
        "\n",
        "install(modelUrl)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3LWn6GzNQ4j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SoucgZQ6jgPQ"
      },
      "outputs": [],
      "source": [
        "#@title ## 2.3. Download Available VAE\n",
        "%store -r \n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "installVae = []\n",
        "#@markdown ### Available VAE\n",
        "#@markdown Select one of the VAEs to download, select `none` for not download VAE:\n",
        "vaeUrl = [\"\", \\\n",
        "          \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animevae/animevae.pt\", \\\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\", \\\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "vaeList = [\"none\", \\\n",
        "           \"anime.vae.pt\", \\\n",
        "           \"waifudiffusion.vae.pt\", \\\n",
        "           \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"anime.vae.pt\" #@param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "def install(vae_name, url):\n",
        "  hf_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -o vae/{vae_name} \"{url}\"\n",
        "\n",
        "def install_vae():\n",
        "  if vaeName != \"none\":\n",
        "    for vae in installVae:\n",
        "      install(vae[0], vae[1])\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "install_vae()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# III. Data Acquisition\n",
        "\n",
        "You can either upload your dataset to this notebook or use the image scraper below to bulk download images from Danbooru.\n",
        "\n",
        "If you want to use your own dataset, you can upload to colab `local files`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.1. Define Train Data Directory\n",
        "#@markdown Define where your train data will be located. This cell will also create a folder based on your input. \n",
        "#@markdown This folder will be used as the target folder for scraping, tagging, bucketing, and training in the next cell.\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {'type' : 'string'}\n",
        "%store train_data_dir\n",
        "\n",
        "if not os.path.exists(train_data_dir):\n",
        "    os.makedirs(train_data_dir)\n",
        "else:\n",
        "    print(f\"{train_data_dir} already exists\\n\")\n",
        "\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T95ErCuCSCDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.2. Clone Dataset Repository (Optional)\n",
        "#@markdown *Optional but can be useful for resume training process, because you will need that `last-state` folder*\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "#@markdown ### Define Parameters\n",
        "repository_url = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-tag-v2\"  #@param {'type': 'string'}\n",
        "\n",
        "#@markdown ### Leave it empty if your datasets is on `main` branch\n",
        "branch = \"\" #@param {'type': 'string'}\n",
        "\n",
        "!git lfs install\n",
        "if branch != \"\":\n",
        "  !git clone --branch {branch} {repository_url}\n",
        "else:\n",
        "  !git clone {repository_url}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nEKTgJGg_DGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 3.3. Download dataset (.zip)\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "%store -r\n",
        "\n",
        "#@markdown ### Define download parameter\n",
        "zipfile_url = \"https://huggingface.co/datasets/Linaqruf/anijourneydb/resolve/main/anijourneydbv1_512.zip\" #@param {'type': 'string'}\n",
        "zipfile_path = str(root_dir)+\"/train_data.zip\"\n",
        "\n",
        "dirname = os.path.dirname(zipfile_path)\n",
        "basename = os.path.basename(zipfile_path)\n",
        "\n",
        "try:\n",
        "  if zipfile_url.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy  {zipfile_url}\n",
        "  elif zipfile_url.startswith(\"magnet:?\"):\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 {zipfile_url}\n",
        "  elif zipfile_url.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in zipfile_url:\n",
        "      zipfile_url = zipfile_url.replace('/blob/', '/resolve/')\n",
        "\n",
        "    #@markdown Change this part with your own huggingface token if you need to download your private model\n",
        "    hf_token = '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' #@param {type:\"string\"}\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dirname} -o {basename} {zipfile_url}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dirname} -o {basename} {zipfile_url}\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while downloading the file:\", e)\n",
        "\n",
        "#@markdown Tick this if you want to extract all files directly to `train_data_dir`, and automatically delete the zip to save the memory\n",
        "auto_unzip_and_delete = True #@param{'type':'boolean'}\n",
        "\n",
        "if auto_unzip_and_delete:\n",
        "  !unzip -j {zipfile_path} -d {train_data_dir}\n",
        "\n",
        "  # directory to check for files\n",
        "  # JSON files to move\n",
        "  files_to_move = (\"meta_cap.json\", \\\n",
        "                   \"meta_cap_dd.json\", \\\n",
        "                   \"meta_lat.json\", \\\n",
        "                   \"meta_clean.json\")\n",
        "\n",
        "  # check each file in the directory\n",
        "  for filename in os.listdir(train_data_dir):\n",
        "      # get the full file path\n",
        "      file_path = os.path.join(train_data_dir, filename)\n",
        "      if filename in files_to_move:\n",
        "          # move the file to the parent directory\n",
        "          shutil.move(file_path, os.path.dirname(train_data_dir))\n",
        "  \n",
        "  path_obj = Path(zipfile_path)\n",
        "  zipfile_name = path_obj.parts[-1]\n",
        "  \n",
        "  if os.path.isdir(zipfile_path):\n",
        "    print(\"\\nThis zipfile doesn't exist or has been deleted \\n\")\n",
        "  else:\n",
        "    os.remove(zipfile_path)\n",
        "    print(f\"\\n{zipfile_name} has been deleted\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eFFHVTWNZGbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 3.3.1. Unzip dataset (.zip)\n",
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "#@markdown ### Define unzip parameter\n",
        "zipfile_src = '/content/train_data.zip' #@param{'type':'string'}\n",
        "zipfile_dst = '/content/fine_tune/train_data' #@param{'type':'string'}\n",
        "\n",
        "#@markdown ### Delete zipfile after unzip process done\n",
        "delete_zipfile = True #@param{'type':'boolean'}\n",
        "\n",
        "try:   \n",
        "  !unzip -j {zipfile_src} -d {zipfile_dst}\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while unzipping the file:\", e)\n",
        "\n",
        "# directory to check for files\n",
        "  # JSON files to move\n",
        "files_to_move = (\"meta_cap.json\", \\\n",
        "                 \"meta_cap_dd.json\", \\\n",
        "                 \"meta_lat.json\", \\\n",
        "                 \"meta_clean.json\")\n",
        "\n",
        "  # check each file in the directory\n",
        "for filename in os.listdir(zipfile_dst):\n",
        "  # get the full file path\n",
        "  file_path = os.path.join(zipfile_dst, filename)\n",
        "  if filename in files_to_move:\n",
        "    # move the file to the parent director\n",
        "    shutil.move(file_path, os.path.dirname(zipfile_dst))\n",
        "  \n",
        "if delete_zipfile:\n",
        "  path_obj = Path(zipfile_src)\n",
        "  zipfile_name = path_obj.parts[-1]\n",
        "  \n",
        "  if os.path.isdir(zipfile_src):\n",
        "    print(\"\\nThis zipfile doesn't exist or has been deleted \\n\")\n",
        "  else:\n",
        "    os.remove(zipfile_src)\n",
        "    print(f\"\\n{zipfile_name} has been deleted\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iSw3krdkHLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt1GzntK_apb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## 3.4. Simple Booru Scraper\n",
        "#@markdown Use gallery-dl to scrape images from a booru site using the specified tags\n",
        "import os\n",
        "import html\n",
        "%store -r \n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "# Set configuration options\n",
        "booru = \"Gelbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "tag1 = \"hito_komoru\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "download_tags = False #@param {type: \"boolean\"}\n",
        "# Construct the search query\n",
        "if tag2 != \"\":\n",
        "  tags = tag1 + \"+\" + tag2\n",
        "else:\n",
        "  tags = tag1\n",
        "\n",
        "if download_tags == True:\n",
        "  write_tags = \"--write-tags\"\n",
        "else:\n",
        "  write_tags = \"\"\n",
        "\n",
        "# Scrape images from the specified booru site using the given tags\n",
        "if booru.lower() == \"danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tags}\" {write_tags} -D {train_data_dir}\n",
        "elif booru.lower() == \"gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tags}\" {write_tags} -D {train_data_dir}\n",
        "else:\n",
        "  print(f\"Unknown booru site: {booru}\")\n",
        "\n",
        "if download_tags == True: \n",
        "  # Get a list of all the .txt files in the folder\n",
        "  files = [f for f in os.listdir(train_data_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "  # Loop through each file\n",
        "  for file in files:\n",
        "      file_path = os.path.join(train_data_dir, file)\n",
        "\n",
        "      # Read the contents of the file\n",
        "      with open(file_path, \"r\") as f:\n",
        "          contents = f.read()\n",
        "\n",
        "      # Decode HTML entities and replace _ with a space\n",
        "      contents = html.unescape(contents)\n",
        "      contents = contents.replace(\"_\", \" \")\n",
        "\n",
        "      # Split the contents on newline characters and join with commas\n",
        "      contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "      # Write the modified contents back to the file\n",
        "      with open(file_path, \"w\") as f:\n",
        "          f.write(contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. Data Preprocessing"
      ],
      "metadata": {
        "id": "T-0qKyEgTchp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu"
      },
      "outputs": [],
      "source": [
        "#@title ## 4.1. Data Cleaning\n",
        "#@markdown This will delete unnecessary files and unsupported media like `.mp4`, `.webm`, and `.gif`\n",
        "%store -r\n",
        "\n",
        "import os\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "\n",
        "#@markdown I recommend to `keep_metadata` especially if you're doing resume training and you have metadata and bucket latents file from previous training like `.npz`, `.txt`, `.caption`, and `json`.\n",
        "keep_metadata = True #@param {'type':'boolean'}\n",
        "\n",
        "# List of supported file types\n",
        "if keep_metadata == True:\n",
        "  supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".caption\", \".npz\", \".txt\", \".json\"]\n",
        "else:\n",
        "  supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\"]\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for item in test:\n",
        "    # Extract the file extension from the file name\n",
        "    file_ext = os.path.splitext(item)[1]\n",
        "    # If the file extension is not in the list of supported types, delete the file\n",
        "    if file_ext not in supported_types:\n",
        "        # Print a message indicating the name of the file being deleted\n",
        "        print(f\"Deleting file {item} from {train_data_dir}\")\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(train_data_dir, item))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 4.2. Data Annotation\n",
        "%store -r\n",
        "%cd {finetune_dir}\n",
        "\n",
        "#@markdown We're using [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) for image captioning and [Waifu Diffusion 1.4 Tagger](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) for image tagging like danbooru.\n",
        "\n",
        "#@markdown Tick this if you want to label your dataset with natural language like this: <br>\n",
        "#@markdown `a girl with long hair holding a cellphone`\n",
        "\n",
        "Start_BLIP_Captioning = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown or Tick this if you want to label your dataset with danbooru tag like this: <br>\n",
        "#@markdown `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background, shirt, black_hair, white_background, closed_mouth, choker, hair_over_one_eye, head_tilt, grey_eyes, black_shirt, floating_hair, black_choker, eyes_visible_through_hair, portrait`\n",
        "\n",
        "Start_WD_1_4_Tagger = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown or you can use them both\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "if Start_BLIP_Captioning == True:\n",
        "  !python make_captions.py \\\n",
        "    {train_data_dir} \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .caption\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if Start_WD_1_4_Tagger == True:\n",
        "  !python tag_images_by_wd14_tagger.py \\\n",
        "    {train_data_dir} \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .txt\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "RrCJI2AbqX2E",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 4.2.1. Append Custom Tag (Optional)\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "def clone_random_repo():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir(str(root_dir)+\"/cafe-aesthetic-scorer/\"):\n",
        "    %cd {root_dir}/cafe-aesthetic-scorer/\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/Linaqruf/cafe-aesthetic-scorer/\n",
        "\n",
        "clone_random_repo()\n",
        "\n",
        "%cd {root_dir}/cafe-aesthetic-scorer/\n",
        "#@markdown If you want to append custom tag, you can do that here. This cell will add custom tag at the beginning of lines\n",
        "custom_tag = \"masterpiece\" #@param {type:\"string\"}\n",
        "caption_extension = \"txt\" #@param [\"txt\",\"caption\"]\n",
        "#@markdown Tick this if you want to append custom tag at the end of lines instead\n",
        "append = False #@param {type: \"boolean\"}\n",
        "\n",
        "if append:\n",
        "  append_tag = \"--append\"\n",
        "else:\n",
        "  append_tag = \"\"\n",
        "\n",
        "!python custom_tagger.py \\\n",
        "  {train_data_dir} \\\n",
        "  {caption_extension} \\\n",
        "  {custom_tag} \\\n",
        "  {append_tag}   "
      ],
      "metadata": {
        "id": "_mLVURhM9PFE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 4.3. Create JSON file for Finetuning\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# Change the working directory\n",
        "%cd {finetune_dir}\n",
        "\n",
        "#@markdown ### Define Parameter\n",
        "meta_clean = \"/content/fine_tune/meta_clean.json\" #@param {type:\"string\"}\n",
        "#@markdown This cell will merge all dataset label from captioning, tagging, and custom tagging into one JSON file, and later it will be used as input JSON for bucketing section.\n",
        "\n",
        "parent_folder = os.path.dirname(meta_clean)\n",
        "meta_cap_dd = f\"{parent_folder}/meta_cap_dd.json\"\n",
        "meta_cap = f\"{parent_folder}/meta_cap.json\"\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(parent_folder):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs(parent_folder)\n",
        "\n",
        "# Check if the train_data_dir exists and is a directory\n",
        "if os.path.isdir(train_data_dir):\n",
        "  # Check if there are any .caption files in the train_data_dir\n",
        "  if any(file.endswith('.caption') for file in os.listdir(train_data_dir)):\n",
        "    # Create meta_cap.json from captions\n",
        "    !python merge_captions_to_metadata.py \\\n",
        "      {train_data_dir} \\\n",
        "      {meta_cap}\n",
        "\n",
        "  # Check if there are any .txtn files in the train_data_dir\n",
        "  if any(file.endswith('.txt') for file in os.listdir(train_data_dir)):\n",
        "    # Create meta_cap_dd.json from tags\n",
        "    !python merge_dd_tags_to_metadata.py \\\n",
        "      {train_data_dir} \\\n",
        "      {meta_cap_dd}\n",
        "else:\n",
        "  print(\"train_data_dir does not exist or is not a directory.\")\n",
        "\n",
        "# Merge meta_cap.json to meta_cap_dd.json\n",
        "if os.path.exists(meta_cap) and os.path.exists(meta_cap_dd):\n",
        "  !python merge_dd_tags_to_metadata.py \\\n",
        "    {train_data_dir} \\\n",
        "    --in_json {meta_cap} \\\n",
        "    {meta_cap_dd}\n",
        "\n",
        "# Clean meta_cap_dd.json and store it to meta_clean.json\n",
        "if os.path.exists(meta_cap_dd):\n",
        "  # Clean captions and tags in meta_cap_dd.json and store the result in meta_clean.json\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {meta_cap_dd} \\\n",
        "    {meta_clean}\n",
        "elif os.path.exists(meta_cap):\n",
        "  # If meta_cap_dd.json does not exist, clean meta_cap.json and store the result in meta_clean.json\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {meta_cap} \\\n",
        "    {meta_clean}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MEHNh0P8Yyxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hhgatqF3leHJ"
      },
      "outputs": [],
      "source": [
        "#@title ## 4.4. Aspect Ratio Bucketing and Cache Latents\n",
        "%store -r\n",
        "\n",
        "# Change the working directory\n",
        "%cd {finetune_dir}\n",
        "\n",
        "#@markdown ### Define parameters\n",
        "V2 = False #@param{type:\"boolean\"}\n",
        "model_dir = \"/content/pre_trained_model/Anything-v3-better-vae.ckpt\" #@param {'type' : 'string'} \n",
        "input_json = \"/content/fine_tune/meta_clean.json\" #@param {'type' : 'string'} \n",
        "output_json = \"/content/fine_tune/meta_lat.json\"#@param {'type' : 'string'} \n",
        "batch_size = 4 #@param {'type':'integer'}\n",
        "max_resolution = \"512,512\" #@param [\"512,512\", \"640,640\", \"768,768\"] {allow-input: false}\n",
        "mixed_precision = \"no\" #@param [\"no\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "flip_aug = True #@param{type:\"boolean\"}\n",
        "\n",
        "if V2:\n",
        "  SDV2 = \"--v2\"\n",
        "else:\n",
        "  SDV2 = \"\"\n",
        "\n",
        "if flip_aug:\n",
        "  flip_latents = \"--v2\"\n",
        "else:\n",
        "  flip_latents = \"--flip_aug\"\n",
        "\n",
        "# Run script to prepare buckets and latents\n",
        "!python prepare_buckets_latents.py \\\n",
        "  {train_data_dir} \\\n",
        "  {input_json} \\\n",
        "  {output_json} \\\n",
        "  {model_dir} \\\n",
        "  {SDV2} \\\n",
        "  {flip_latents} \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --max_resolution {max_resolution} \\\n",
        "  --mixed_precision {mixed_precision}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNbl3O_NSS0"
      },
      "source": [
        "# V. Training Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 5.1. Define Important folder\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "v2 = False #@param {type:\"boolean\"}\n",
        "v_parameterization = False #@param {type:\"boolean\"}\n",
        "output_name = \"hito_komoru\" #@param {type:\"string\"}\n",
        "pretrained_model_name_or_path = \"/content/pre_trained_model/Anything-v3-better-vae.ckpt\" #@param {type:\"string\"}\n",
        "vae = \"\"  #@param {type:\"string\"}\n",
        "train_data_dir = \"/content/fine_tune/train_data\"  #@param {type:\"string\"}\n",
        "%store train_data_dir\n",
        "in_json = \"/content/fine_tune/meta_lat.json\" #@param {type:\"string\"}\n",
        "output_dir = \"/content/fine_tune/output\" #@param {type:\"string\"}\n",
        "resume_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown This will ignore `output_dir` defined above, and changed to `/content/drive/MyDrive/fine_tune/output` by default\n",
        "output_to_drive = False #@param {'type':'boolean'}\n",
        "\n",
        "if output_to_drive:\n",
        "  output_dir = \"/content/drive/MyDrive/fine_tune/output\"\n",
        "\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    drive.mount('/content/drive')  \n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "#V2 Inference\n",
        "inference_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/\"\n",
        "\n",
        "if v2 and not v_parameterization:\n",
        "  inference_url += \"v2-inference.yaml\"\n",
        "if v2 and v_parameterization:\n",
        "  inference_url += \"v2-inference-v.yaml\"\n",
        "\n",
        "try:\n",
        "  if v2:\n",
        "    !wget {inference_url} -O {output_dir}/{output_name}.yaml\n",
        "    print(\"File successfully downloaded\")\n",
        "except:\n",
        "  print(\"There was an error downloading the file. Please check the URL and try again.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ur73rlY7bEef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "%store -r\n",
        "\n",
        "#@title ## 5.2. Start Fine-Tuning\n",
        "#@markdown ### Define Parameter\n",
        "train_batch_size = 1 #@param {type:\"number\"}\n",
        "train_text_encoder = False #@param {'type':'boolean'}\n",
        "max_train_steps = 5000 #@param {type:\"number\"}\n",
        "mixed_precision = \"fp16\" #@param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "save_precision = \"float\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs = 0 \n",
        "save_last_n_epochs = 0 \n",
        "save_model_as = \"ckpt\" #@param [\"ckpt\", \"safetensors\", \"diffusers\", \"diffusers_safetensors\"] {allow-input: false}\n",
        "resolution = 512 #@param {type:\"number\"}\n",
        "max_token_length = 225 #@param {type:\"number\"}\n",
        "clip_skip = 2 #@param {type:\"number\"}\n",
        "learning_rate = 2e-6 #@param {type:\"number\"}\n",
        "lr_scheduler = \"constant\" #@param  [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"] {allow-input: false}\n",
        "dataset_repeats = 1 #@param {type:\"number\"}\n",
        "seed = 1234 #@param {type:\"number\"}\n",
        "use_8bit_adam = True #@param {type:\"boolean\"}\n",
        "gradient_checkpointing = False #@param {type:\"boolean\"}\n",
        "gradient_accumulation_steps = 1 #@param {type:\"number\"}\n",
        "logging_dir = repo_dir + \"/logs\"\n",
        "additional_argument = \"--save_state --shuffle_caption --xformers\" #@param {type:\"string\"}\n",
        "print_hyperparameter = True #@param {type:\"boolean\"}\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "train_command=f\"\"\"\n",
        "accelerate launch --config_file={accelerate_config} --num_cpu_threads_per_process 8 fine_tune.py \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "  --pretrained_model_name_or_path={pretrained_model_name_or_path} \\\n",
        "  {\"--vae=\" + vae if vae else \"\"} \\\n",
        "  --train_data_dir={train_data_dir} \\\n",
        "  --in_json={in_json} \\\n",
        "  --output_dir={output_dir} \\\n",
        "  {\"--resume=\" + resume_path if resume_path else \"\"} \\\n",
        "  {\"--output_name=\" + output_name if output_name else \"\"} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --save_precision={save_precision} \\\n",
        "  {\"--save_every_n_epochs=\" + save_every_n_epochs if save_every_n_epochs != 0 else \"\"} \\\n",
        "  {\"--save_last_n_epochs=\" + save_every_n_epochs if save_last_n_epochs != 0 else \"\"} \\\n",
        "  --save_model_as={save_model_as} \\\n",
        "  --resolution={resolution} \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --max_token_length={max_token_length} \\\n",
        "  {\"--train_text_encoder\" if train_text_encoder else \"\"} \\\n",
        "  {\"--use_8bit_adam\" if use_8bit_adam else \"\"} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  --lr_scheduler={lr_scheduler} \\\n",
        "  --lr_warmup_steps={lr_warmup_steps} \\\n",
        "  --dataset_repeats={dataset_repeats} \\\n",
        "  --max_train_steps={max_train_steps} \\\n",
        "  {\"--seed=\" + format(seed) if seed else \"\"} \\\n",
        "  {\"--gradient_checkpointing\" if gradient_checkpointing else \"\"} \\\n",
        "  {\"--gradient_accumulation_steps=\" + format(gradient_accumulation_steps) } \\\n",
        "  {\"--clip_skip=\" + clip_skip if v2==\"\" else \"\"} \\\n",
        "  --logging_dir={logging_dir} \\\n",
        "  --log_prefix={output_name} \\\n",
        "  {additional_argument}\n",
        "  \"\"\"\n",
        "  \n",
        "if print_hyperparameter:\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Hyperparameter\", \"Value\"]\n",
        "    for params in debug_params:\n",
        "        if params != \"\":\n",
        "            if globals()[params] == \"\":\n",
        "                value = \"False\"\n",
        "            else:\n",
        "                value = globals()[params]\n",
        "            table.add_row([params, value])\n",
        "    table.add_row([\"train_command\", train_command])\n",
        "    table.align = \"l\"\n",
        "    print(table)\n",
        "\n",
        "f = open(\"./train.sh\", \"w\")\n",
        "f.write(train_command)\n",
        "f.close()\n",
        "!chmod +x ./train.sh\n",
        "!./train.sh"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DNYGVTkaiQPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqfgyL-thgdw"
      },
      "source": [
        "# VI. Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 6.1. Inference\n",
        "%store -r\n",
        "\n",
        "v2 = False #@param {type:\"boolean\"}\n",
        "v_parameterization = False #@param {type:\"boolean\"}\n",
        "prompt = \"masterpiece, best quality, high quality, 1girl, solo, sitting, confident expression, long blonde hair, blue eyes, formal dress, jewelry, make-up, luxury, close-up, face, upper body.\" #@param {type: \"string\"}\n",
        "negative = \"worst quality, low quality, medium quality, deleted, lowres, comic, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry\" #@param {type: \"string\"}\n",
        "model = \"/content/fine_tune/output/last.ckpt\" #@param {type: \"string\"}\n",
        "vae = \"\" #@param {type: \"string\"}\n",
        "outdir = \"/content/tmp\" #@param {type: \"string\"}\n",
        "scale = 7 #@param {type: \"slider\", min: 1, max: 40}\n",
        "sampler = \"ddim\" #@param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "steps = 28 #@param {type: \"slider\", min: 1, max: 100}\n",
        "precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "width = 512 #@param {type: \"integer\"}\n",
        "height = 768 #@param {type: \"integer\"}\n",
        "images_per_prompt = 4 #@param {type: \"integer\"}\n",
        "batch_size = 4 #@param {type: \"integer\"}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 40}\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "\n",
        "final_prompt = f\"{prompt} --n {negative}\"\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "!python gen_img_diffusers.py \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "  --ckpt={model} \\\n",
        "  --outdir={outdir} \\\n",
        "  --xformers \\\n",
        "  {\"--vae=\" + vae if vae else \"\"} \\\n",
        "  --{precision} \\\n",
        "  --W={width} \\\n",
        "  --H={height} \\\n",
        "  {\"--seed=\" + format(seed) if seed > 0 else \"\"} \\\n",
        "  --scale={scale} \\\n",
        "  --sampler={sampler} \\\n",
        "  --steps={steps} \\\n",
        "  {\"--max_embeddings_multiples=\" + format(3)} \\\n",
        "  --batch_size={batch_size} \\\n",
        "  --images_per_prompt={images_per_prompt} \\\n",
        "  {\"--clip_skip=\" + clip_skip if v2==\"\" else \"\"} \\\n",
        "  --prompt=\"{final_prompt}\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j1jJ4z3AXRO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 6.2. Visualize loss graph (Optional)\n",
        "training_logs_path = \"/content/fine_tune/training_logs\" #@param {type : \"string\"}\n",
        "\n",
        "%cd {repo_dir}\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {training_logs_path}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jgKi9y4w7tmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VII. Extras"
      ],
      "metadata": {
        "id": "N6ckzE2GWudi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.1. Convert Diffusers to `.ckpt/.safetensors`\n",
        "%store -r\n",
        "%cd {tools_dir}\n",
        "\n",
        "\n",
        "#@markdown ## Define model path\n",
        "weight = \"/content/fine_tune/output/last.ckpt\" #@param {'type': 'string'}\n",
        "weight_dir = os.path.dirname(weight)\n",
        "base_name = os.path.splitext(os.path.basename(weight))[0]\n",
        "\n",
        "convert = \"ckpt_safetensors_to_diffusers\" #@param [\"diffusers_to_ckpt_safetensors\", \"ckpt_safetensors_to_diffusers\"] {'allow-input': false}\n",
        "#@markdown ___\n",
        "#@markdown ## Conversion Config\n",
        "#@markdown ___\n",
        "#@markdown ### Diffusers to `.ckpt/.safetensors`\n",
        "use_safetensors = False #@param {'type': 'boolean'}\n",
        "\n",
        "save_precision = \"--float\" #@param [\"--fp16\",\"--bf16\",\"--float\"] {'allow-input': false}\n",
        "\n",
        "#@markdown ### `.ckpt/.safetensors` to Diffusers\n",
        "#@markdown is your model v1 or v2 based Stable Diffusion Model\n",
        "version = \"--v1\" #@param [\"--v1\",\"--v2\"] {'allow-input': false}\n",
        "diffusers = os.path.join(weight_dir, base_name)\n",
        "\n",
        "#@markdown Additional file for diffusers\n",
        "feature_extractor = True #@param {'type': 'boolean'}\n",
        "safety_checker = True #@param {'type': 'boolean'}\n",
        "\n",
        "if use_safetensors:\n",
        "    checkpoint = str(diffusers)+\".safetensors\"\n",
        "else:\n",
        "    checkpoint = str(diffusers)+\".ckpt\"\n",
        "\n",
        "if version == \"--v1\":\n",
        "  reference_model = \"runwayml/stable-diffusion-v1-5\"\n",
        "elif version == \"--v2\":\n",
        "  reference_model = \"stabilityai/stable-diffusion-2-1\"\n",
        "\n",
        "if convert == \"diffusers_to_ckpt_safetensors\":\n",
        "    if not weight.endswith(\".ckpt\") or weight.endswith(\".safetensors\"):\n",
        "        !python convert_diffusers20_original_sd.py \\\n",
        "            \"{weight}\" \\\n",
        "            \"{checkpoint}\"\" \\\n",
        "            {save_precision}\n",
        "\n",
        "else:    \n",
        "    !python convert_diffusers20_original_sd.py \\\n",
        "        \"{weight}\" \\\n",
        "        \"{diffusers}\" \\\n",
        "        {version} \\\n",
        "        --reference_model {reference_model} \n",
        "\n",
        "    url1 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/preprocessor_config.json\"\n",
        "    url2 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/config.json\"\n",
        "    url3 = \"https://huggingface.co/CompVis/stable-diffusion-safety-checker/resolve/main/pytorch_model.bin\"\n",
        "\n",
        "    if feature_extractor == True:\n",
        "      if not os.path.exists(str(diffusers)+'/feature_extractor'):\n",
        "        os.makedirs(str(diffusers)+'/feature_extractor')\n",
        "      \n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{diffusers}/feature_extractor' -Z {url1}\n",
        "\n",
        "    if safety_checker == True:\n",
        "      if not os.path.exists(str(diffusers)+'/safety_checker'):\n",
        "        os.makedirs(str(diffusers)+'/safety_checker')\n",
        "      \n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{diffusers}/safety_checker' -Z {url2}\n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d '{diffusers}/safety_checker' -Z {url3}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EHOvjWCHa-JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%store -r\n",
        "#@title ## 7.2. Model Pruner\n",
        "\n",
        "%cd {toolsdir}\n",
        "\n",
        "if os.path.exists('prune.py'):\n",
        "  pass\n",
        "else:\n",
        "  # Add a comment to explain what the code is doing\n",
        "  # Download the pruning script if it doesn't already exist\n",
        "  !wget https://raw.githubusercontent.com/lopho/stable-diffusion-prune/main/prune.py\n",
        "\n",
        "#@markdown Convert to Float16\n",
        "fp16 = False #@param {'type':'boolean'}\n",
        "#@markdown Use EMA for weights\n",
        "ema = False #@param {'type':'boolean'}\n",
        "#@markdown Strip CLIP weights\n",
        "no_clip = False #@param {'type':'boolean'}\n",
        "#@markdown Strip VAE weights\n",
        "no_vae = False #@param {'type':'boolean'}\n",
        "#@markdown Strip depth model weights\n",
        "no_depth = False #@param {'type':'boolean'}\n",
        "#@markdown Strip UNet weights\n",
        "no_unet = False #@param {'type':'boolean'}\n",
        "#@markdown You need to input model ends with `.ckpt`, because `.safetensors` model won't work.\n",
        "\n",
        "input = \"/content/fine_tune/output/last.ckpt\" #@param {'type' : 'string'}\n",
        "\n",
        "\n",
        "# Notify the user that the model is being loaded\n",
        "print(f\"Loading model from {input}\")\n",
        "\n",
        "input_path = os.path.dirname(input)\n",
        "base_name = os.path.basename(input)\n",
        "output_name = base_name.split('.')[0]\n",
        "# Notify the user of the arguments being used\n",
        "if fp16:\n",
        "    print(\"Converting to float16\")\n",
        "    output_name += '-fp16'\n",
        "if ema:\n",
        "    print(\"Using EMA for weights\")\n",
        "    output_name += '-ema'\n",
        "if no_clip:\n",
        "    print(\"Stripping CLIP weights\")\n",
        "    output_name += '-no-clip'\n",
        "if no_vae:\n",
        "    print(\"Stripping VAE weights\")\n",
        "    output_name += '-no-vae'\n",
        "if no_depth:\n",
        "    print(\"Stripping depth model weights\")\n",
        "    output_name += '-no-depth'\n",
        "if no_unet:\n",
        "    print(\"Stripping UNet weights\")\n",
        "    output_name += '-no-unet'\n",
        "output_name += '-pruned'\n",
        "output_path = os.path.join(input_path, output_name + '.ckpt')\n",
        "\n",
        "!python3 prune.py \"{input}\" \\\n",
        "  \"{output_path}\" \\\n",
        "  {'--fp16' if fp16 else ''} \\\n",
        "  {'--ema' if ema else ''} \\\n",
        "  {'--no-clip' if no_clip else ''} \\\n",
        "  {'--no-vae' if no_vae else ''} \\\n",
        "  {'--no-depth' if no_depth else ''} \\\n",
        "  {'--no-unet' if no_unet else ''}\n",
        "\n",
        "# Notify the user of the output file location\n",
        "print(f\"Saving pruned model to {output_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g5Iz_ikf29LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 7.3. Compressing model or dataset\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "zip_module = \"zipfile\" #@param [\"zipfile\", \"shutil\", \"pyminizip\", \"zip\"]\n",
        "directory_to_zip = '/content/fine_tune/train_data' #@param {type: \"string\"}\n",
        "output_filename = '/content/train_data.zip' #@param {type: \"string\"}\n",
        "password = \"\" #@param {type: \"string\"}\n",
        "\n",
        "if zip_module == \"zipfile\":\n",
        "    with zipfile.ZipFile(output_filename, 'w') as zip:\n",
        "        for directory_to_zip, dirs, files in os.walk(directory_to_zip):\n",
        "            for file in files:\n",
        "                zip.write(os.path.join(directory_to_zip, file))\n",
        "elif zip_module == \"shutil\":\n",
        "    shutil.make_archive(output_filename, 'zip', directory_to_zip)\n",
        "elif zip_module == \"pyminizip\":\n",
        "    !pip install pyminizip\n",
        "    import pyminizip\n",
        "    for root, dirs, files in os.walk(directory_to_zip):\n",
        "        for file in files:\n",
        "            pyminizip.compress(os.path.join(root, file), \"\", os.path.join(\"*\",output_filename), password, 5)\n",
        "elif zip_module == \"zip\":\n",
        "    !zip -rv -q -j {output_filename} {directory_to_zip}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rLdEpPKTbI1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIII. Deployment"
      ],
      "metadata": {
        "id": "nyIl9BhNXKUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 8.1. Define your Huggingface Repo\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown #### If your model/dataset repo didn't exist, it will automatically create your repo.\n",
        "model_name = \"your-model-name\" #@param{type:\"string\"}\n",
        "dataset_name = \"your-dataset-name\" #@param{type:\"string\"}\n",
        "make_this_model_private = True #@param{type:\"boolean\"}\n",
        "clone_with_git = True #@param{type:\"boolean\"}\n",
        "\n",
        "model_repo = user['name']+\"/\"+model_name.strip()\n",
        "datasets_repo = user['name']+\"/\"+dataset_name.strip()\n",
        "\n",
        "validate_repo_id(model_repo)\n",
        "validate_repo_id(datasets_repo)\n",
        "\n",
        "if make_this_model_private:\n",
        "  private_repo = True\n",
        "else:\n",
        "  private_repo = False\n",
        "\n",
        "if model_name != \"\":\n",
        "  try:\n",
        "      api.create_repo(repo_id=model_repo, \n",
        "                      private=private_repo)\n",
        "      print(\"Model Repo didn't exists, creating repo\")\n",
        "      print(\"Model Repo: \",model_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Model Repo: {model_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "if dataset_name != \"\":\n",
        "  try:\n",
        "      api.create_repo(repo_id=datasets_repo,\n",
        "                      repo_type=\"dataset\",\n",
        "                      private=private_repo)\n",
        "      print(\"Dataset Repo didn't exists, creating repo\")\n",
        "      print(\"Dataset Repo\",datasets_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Dataset repo: {datasets_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "if clone_with_git:\n",
        "  !sudo apt-get remove git-lfs\n",
        "\n",
        "  if model_name != \"\":\n",
        "    !git clone https://huggingface.co/{model_repo} /content/{model_name}\n",
        "  \n",
        "  if dataset_name != \"\":\n",
        "    !git clone https://huggingface.co/datasets/{datasets_repo} /content/{dataset_name}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTXsM170GUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2. Upload to Huggingface"
      ],
      "metadata": {
        "id": "yUNkWbMHcbiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 8.2.1. Commit using Git \n",
        "%cd {root_dir}\n",
        "\n",
        "#@markdown Tick which repo you want to commit\n",
        "commit_model = True #@param {'type': 'boolean'}\n",
        "commit_dataset = True #@param {'type': 'boolean'}\n",
        "\n",
        "#@markdown Set **git commit identity**\n",
        "email = \"your-email\" #@param {'type': 'string'}\n",
        "name = \"your-username\" #@param {'type': 'string'}\n",
        "#@markdown Set **commit message**\n",
        "commit_m = \"feat: upload prototype model\" #@param {'type': 'string'}\n",
        "\n",
        "!sudo apt-get install git-lfs\n",
        "\n",
        "!git config --global user.email \"{email}\"\n",
        "!git config --global user.name \"{name}\"\n",
        "\n",
        "if commit_model:\n",
        "  %cd {root_dir}/{model_name}\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "if commit_dataset:\n",
        "  %cd {root_dir}/{dataset_name}\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7bJev4PzOFFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### 8.2.2. Quick Upload to Huggingface\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown #### This will be uploaded to model repo\n",
        "model_path = \"/content/fine_tune/output/last.ckpt\" #@param {type :\"string\"}\n",
        "\n",
        "is_diffusers_model = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### This will be uploaded to datasets repo, leave it empty if not necessary\n",
        "last_state_path = \"/content/fine_tune/output/last-state\" #@param {type :\"string\"}\n",
        "train_data_path = \"/content/fine_tune/output/train_data\" #@param {type :\"string\"}\n",
        "meta_lat_path = \"/content/fine_tune/output/meta_lat_json\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown ##### `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/fine_tune/logs\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"feat: upload a model and dataset\" #@param {type :\"string\"}\n",
        "\n",
        "if model_path != \"\":\n",
        "  path_obj = Path(model_path)\n",
        "  trained_model = path_obj.parts[-1]\n",
        "\n",
        "  if model_path.endswith(\".ckpt\") or model_path.endswith(\".safetensors\") or model_path.endswith(\".pt\"):\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=model_path,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "    )\n",
        "    \n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/blob/main/\"+trained_model+\"\\n\")\n",
        "  \n",
        "  elif is_diffusers_model == True:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=model_path,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\"\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/tree/main\\n\")\n",
        "  \n",
        "  else:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=model_path,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\"\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/tree/main/\"+trained_model+\"\\n\")\n",
        "if last_state_path != \"\":\n",
        "  path_obj = Path(last_state_path)\n",
        "  last_state_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {last_state_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=last_state_path,\n",
        "      path_in_repo=last_state_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+last_state_folder+\"\\n\")\n",
        "\n",
        "\n",
        "if train_data_path != \"\":\n",
        "  path_obj = Path(train_data_path)\n",
        "  train_data_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {train_data_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=train_data_path,\n",
        "      path_in_repo=train_data_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+train_data_folder+\"\\n\")\n",
        "\n",
        "if meta_lat_path != \"\":\n",
        "  path_obj = Path(meta_lat_path)\n",
        "  meta_lat_file = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {meta_lat_file} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_file(\n",
        "      path_or_fileobj=meta_lat_path,\n",
        "      path_in_repo=meta_lat_file,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/blob/main/\"+meta_lat_file+\"\\n\")\n",
        "\n",
        "if logs_path != \"\":\n",
        "  path_obj = Path(logs_path)\n",
        "  logs_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {logs_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=logs_path,\n",
        "      path_in_repo=logs_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+logs_folder+\"\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pSUhgYLYdT2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}