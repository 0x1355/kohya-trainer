{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "# Kohya Trainer V10 - VRAM 12GB\n",
        "### The Best Way for People Without Good GPUs to Fine-Tune the Stable Diffusion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      },
      "source": [
        "This notebook has been adapted for use in Google Colab based on [kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts). </br>\n",
        "This notebook was adapted by [Linaqruf](https://github.com/Linaqruf)</br>\n",
        "You can find the latest update to the notebook [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# Install Kohya Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone Kohya Trainer\n",
        "#@markdown Clone the Kohya Trainer repository from GitHub and check for updates\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "def clone_kohya_trainer():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir('/content/kohya-trainer'):\n",
        "    %cd /content/kohya-trainer\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/Linaqruf/kohya-trainer\n",
        "\n",
        "# Clone or update the Kohya Trainer repository\n",
        "clone_kohya_trainer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Installing Dependencies\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "import os\n",
        "\n",
        "Install_xformers = True #@param {'type':'boolean'}\n",
        "  \n",
        "def install_dependencies():\n",
        "  #@markdown This will install required Python packages\n",
        "  !pip install --upgrade -r requirements.txt\n",
        "  !pip install -U gallery-dl\n",
        "\n",
        "  if Install_xformers:\n",
        "    !pip install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "# Install dependencies\n",
        "install_dependencies()\n",
        "\n",
        "#@markdown After Accelerate updated its version to 0.15.0, you can't manually input the config using\n",
        "#@markdown `!accelerate config` in Google Colab. Instead, a `config.yaml` file will be generated by\n",
        "#@markdown the `write_basic_config()` function. You can find the file [here](/content/kohya-trainer/accelerate_config/config.yaml) after installation.\n",
        "#@markdown if you want to modify it.\n",
        "\n",
        "from accelerate.utils import write_basic_config\n",
        "accelerate_config = \"/content/kohya-trainer/accelerate_config/config.yaml\"\n",
        "write_basic_config(save_location = accelerate_config) # Write a config file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login to Huggingface hub\n",
        "from huggingface_hub import login\n",
        "\n",
        "#@markdown 1. Of course, you need a Huggingface account first.\n",
        "#@markdown 2. To create a huggingface token, go to [this link](https://huggingface.co/settings/tokens), then `create new token` or copy available token with the `Write` role.\n",
        "\n",
        "write_token = \"YOUR-TOKEN-HERE\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rl2zERHbBQ9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# Collecting datasets\n",
        "\n",
        "You can either upload your datasets to this notebook or use the image scraper below to bulk download images from Danbooru.\n",
        "\n",
        "If you want to use your own datasets, you can upload to colab `local files`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Train Data Directory\n",
        "#@markdown Define where your train data will be located. This cell will also create a folder based on your input. \n",
        "#@markdown This folder will be used as the target folder for scraping, tagging, bucketing, and training in the next cell.\n",
        "\n",
        "import os\n",
        "\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {'type' : 'string'}\n",
        "\n",
        "if not os.path.exists(train_data_dir):\n",
        "    os.makedirs(train_data_dir)\n",
        "else:\n",
        "    print(f\"{train_data_dir} already exists\\n\")\n",
        "\n",
        "print(f\"Your train data directory : {train_data_dir}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T95ErCuCSCDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Dataset Repository (Optional)\n",
        "#@markdown *Optional but can be useful for resume training process, because you will need that `last-state` folder*\n",
        "%cd /content/\n",
        "\n",
        "#@markdown ### Define Parameters\n",
        "repository_url = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-dataset\"  #@param {'type': 'string'}\n",
        "\n",
        "#@markdown ### Leave it empty if your datasets is on `main` branch\n",
        "branch = \"\" #@param {'type': 'string'}\n",
        "\n",
        "!git lfs install\n",
        "if branch != \"\":\n",
        "  !git clone --branch {branch} {repository_url}\n",
        "else:\n",
        "  !git clone {repository_url}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nEKTgJGg_DGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download dataset (.zip)\n",
        "\n",
        "#@markdown ### Define download parameter\n",
        "zipfile_url = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-tag/resolve/30e18a12b2e42dfe0b9252d85a36ae32251981d4/train_data.zip\" #@param {'type': 'string'}\n",
        "zipfile_path = '/content/train_data.zip' #@param{'type':'string'}\n",
        "\n",
        "try:\n",
        "  # Download dataset\n",
        "  if zipfile_url.startswith(\"https://drive.google.com\"):\n",
        "    # Use gdown to download file from Google Drive\n",
        "    !gdown -o {zipfile_path} --fuzzy {zipfile_url}\n",
        "  elif zipfile_url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    # Use aria2c to download file from magnet link\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o {zipfile_path} {zipfile_url}\n",
        "  elif zipfile_url.startswith(\"https://huggingface.co/\"):\n",
        "    user_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    # Use wget to download file from URL\n",
        "    !wget -c --header={user_header} {zipfile_url} -O {zipfile_path} \n",
        "  else:\n",
        "    !wget -c -O {zipfile_path} {zipfile_url}\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while downloading the file:\", e)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eFFHVTWNZGbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip dataset (.zip)\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "#@markdown ### Define unzip parameter\n",
        "zipfile_src = '/content/train_data.zip' #@param{'type':'string'}\n",
        "zipfile_dst = '/content/fine_tune/train_data' #@param{'type':'string'}\n",
        "unzip_module = \"use_7zip\" #@param [\"use_unzip\",\"use_7zip\",\"use_Zipfile\"]\n",
        "\n",
        "#@markdown ### Delete zipfile after unzip process done\n",
        "delete_zipfile = True #@param{'type':'boolean'}\n",
        "\n",
        "if zipfile_src == '':\n",
        "  if zipfile_path != '':\n",
        "    zipfile_src = zipfile_path\n",
        "\n",
        "try:   \n",
        "  if unzip_module == \"use_7zip\":\n",
        "    !7z x $zipfile_src -o$zipfile_dst\n",
        "  elif unzip_module == \"use_unzip\":\n",
        "    !unzip $zipfile_src -d $zipfile_dst\n",
        "  elif unzip_module == \"use_Zipfile\":\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(zipfile_src, 'r') as zip_ref:\n",
        "      zip_ref.extractall(zipfile_dst)\n",
        "except Exception as e:\n",
        "  print(\"An error occurred while unzipping the file:\", e)\n",
        "\n",
        "if delete_zipfile:\n",
        "  path_obj = Path(zipfile_src)\n",
        "  zipfile_name = path_obj.parts[-1]\n",
        "  \n",
        "  if os.path.isdir(zipfile_src):\n",
        "    print(\"\\nThis zipfile doesn't exist or has been deleted \\n\")\n",
        "  else:\n",
        "    os.remove(zipfile_src)\n",
        "    print(f\"\\n{zipfile_name} has been deleted\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iSw3krdkHLyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt1GzntK_apb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Simple Booru Scraper\n",
        "#@markdown Use gallery-dl to scrape images from a booru site using the specified tags\n",
        "import os\n",
        "import html\n",
        "\n",
        "%cd /content\n",
        "\n",
        "# Set configuration options\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {'type' : 'string'}\n",
        "booru = \"Gelbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "tag1 = \"hito_komoru\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "download_tags = False #@param {type: \"boolean\"}\n",
        "# Construct the search query\n",
        "if tag2 != \"\":\n",
        "  tags = tag1 + \"+\" + tag2\n",
        "else:\n",
        "  tags = tag1\n",
        "\n",
        "if download_tags == True:\n",
        "  write_tags = \"--write-tags\"\n",
        "else:\n",
        "  write_tags = \"\"\n",
        "\n",
        "# Scrape images from the specified booru site using the given tags\n",
        "if booru.lower() == \"danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tags}\" {write_tags} -D {train_data_dir}\n",
        "elif booru.lower() == \"gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tags}\" {write_tags} -D {train_data_dir}\n",
        "else:\n",
        "  print(f\"Unknown booru site: {booru}\")\n",
        "\n",
        "if download_tags == True: \n",
        "  # Get a list of all the .txt files in the folder\n",
        "  files = [f for f in os.listdir(train_data_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "  # Loop through each file\n",
        "  for file in files:\n",
        "      file_path = os.path.join(train_data_dir, file)\n",
        "\n",
        "      # Read the contents of the file\n",
        "      with open(file_path, \"r\") as f:\n",
        "          contents = f.read()\n",
        "\n",
        "      # Decode HTML entities and replace _ with a space\n",
        "      contents = html.unescape(contents)\n",
        "      contents = contents.replace(\"_\", \" \")\n",
        "\n",
        "      # Split the contents on newline characters and join with commas\n",
        "      contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "      # Write the modified contents back to the file\n",
        "      with open(file_path, \"w\") as f:\n",
        "          f.write(contents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu"
      },
      "outputs": [],
      "source": [
        "#@title Dataset cleaner\n",
        "#@markdown This will delete unnecessary files and unsupported media like `.mp4`, `.webm`, and `.gif`\n",
        "\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {'type' : 'string'}\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "\n",
        "#@markdown I recommend to `keep_metadata` especially if you're doing resume training and you have metadata and bucket latents file from previous training like `.npz`, `.txt`, `.caption`, and `json`.\n",
        "keep_metadata = True #@param {'type':'boolean'}\n",
        "\n",
        "# List of supported file types\n",
        "if keep_metadata == True:\n",
        "  supported_types = [\".jpg\", \".jpeg\", \".png\", \".caption\", \".npz\", \".txt\", \"json\"]\n",
        "else:\n",
        "  supported_types = [\".jpg\", \".jpeg\", \".png\"]\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for item in test:\n",
        "    # Extract the file extension from the file name\n",
        "    file_ext = os.path.splitext(item)[1]\n",
        "    # If the file extension is not in the list of supported types, delete the file\n",
        "    if file_ext not in supported_types:\n",
        "        # Print a message indicating the name of the file being deleted\n",
        "        print(f\"Deleting file {item} from {train_data_dir}\")\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(train_data_dir, item))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Labeling"
      ],
      "metadata": {
        "id": "7phTUSOiIXWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Auto-captioning and auto-tagging\n",
        "%cd /content/kohya-trainer/finetune\n",
        "\n",
        "#@markdown We're using [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) for image captioning and [Waifu Diffusion 1.4 Tagger](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) for image tagging like danbooru.\n",
        "\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {'type' : 'string'}\n",
        "\n",
        "#@markdown Tick this if you want to label your dataset with natural language like this: <br>\n",
        "#@markdown `a girl with long hair holding a cellphone`\n",
        "\n",
        "Start_BLIP_Captioning = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown or Tick this if you want to label your dataset with danbooru tag like this: <br>\n",
        "#@markdown `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background, shirt, black_hair, white_background, closed_mouth, choker, hair_over_one_eye, head_tilt, grey_eyes, black_shirt, floating_hair, black_choker, eyes_visible_through_hair, portrait`\n",
        "\n",
        "Start_WD_1_4_Tagger = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown or you can use them both\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "if Start_BLIP_Captioning == True:\n",
        "  !python make_captions.py \\\n",
        "    {train_data_dir} \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .caption\n",
        "else:\n",
        "  pass\n",
        "\n",
        "if Start_WD_1_4_Tagger == True:\n",
        "  !python tag_images_by_wd14_tagger.py \\\n",
        "    {train_data_dir} \\\n",
        "    --batch_size {batch_size} \\\n",
        "    --caption_extension .txt\n",
        "else:\n",
        "  pass\n",
        "    "
      ],
      "metadata": {
        "id": "RrCJI2AbqX2E",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Append Custom Tag (Optional)\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "def clone_random_repo():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir('/content/cafe-aesthetic-scorer/'):\n",
        "    %cd /content/cafe-aesthetic-scorer/\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/Linaqruf/cafe-aesthetic-scorer/\n",
        "\n",
        "clone_random_repo()\n",
        "\n",
        "%cd /content/cafe-aesthetic-scorer/\n",
        "#@markdown If you want to append custom tag, you can do that here. This cell will add custom tag at the beginning of lines\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {type:\"string\"}\n",
        "custom_tag = \"fumo\" #@param {type:\"string\"}\n",
        "caption_extension = \"txt\" #@param [\"txt\",\"caption\"]\n",
        "#@markdown Tick this if you want to append custom tag at the end of lines instead\n",
        "append = False #@param {type: \"boolean\"}\n",
        "\n",
        "if append:\n",
        "  append_tag = \"--append\"\n",
        "else:\n",
        "  append_tag = \"\"\n",
        "\n",
        "!python custom_tagger.py \\\n",
        "  {train_data_dir} \\\n",
        "  {caption_extension} \\\n",
        "  {custom_tag} \\\n",
        "  {append_tag} \n",
        "  \n",
        "  "
      ],
      "metadata": {
        "cellView": "form",
        "id": "_mLVURhM9PFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create meta_clean.json \n",
        "\n",
        "# Change the working directory\n",
        "%cd /content/kohya-trainer/finetune\n",
        "\n",
        "import os\n",
        "\n",
        "#@markdown ### Define Parameter\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {type:\"string\"} \n",
        "meta_clean = \"/content/fine_tune/meta_clean.json\" #@param {type:\"string\"}\n",
        "#@markdown This cell will merge all dataset label from captioning, tagging, and custom tagging into one JSON file, and later it will be used as input JSON for bucketing section.\n",
        "\n",
        "parent_folder = os.path.dirname(meta_clean)\n",
        "meta_cap_dd = f\"{parent_folder}/meta_cap_dd.json\"\n",
        "meta_cap = f\"{parent_folder}/meta_cap.json\"\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(parent_folder):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs(parent_folder)\n",
        "\n",
        "# Check if the train_data_dir exists and is a directory\n",
        "if os.path.isdir(train_data_dir):\n",
        "  # Check if there are any .caption files in the train_data_dir\n",
        "  if any(file.endswith('.caption') for file in os.listdir(train_data_dir)):\n",
        "    # Create meta_cap.json from captions\n",
        "    !python merge_captions_to_metadata.py \\\n",
        "      {train_data_dir} \\\n",
        "      {meta_cap}\n",
        "\n",
        "  # Check if there are any .txtn files in the train_data_dir\n",
        "  if any(file.endswith('.txt') for file in os.listdir(train_data_dir)):\n",
        "    # Create meta_cap_dd.json from tags\n",
        "    !python merge_dd_tags_to_metadata.py \\\n",
        "      {train_data_dir} \\\n",
        "      {meta_cap_dd}\n",
        "else:\n",
        "  print(\"train_data_dir does not exist or is not a directory.\")\n",
        "\n",
        "# Merge meta_cap.json to meta_cap_dd.json\n",
        "if os.path.exists(meta_cap) and os.path.exists(meta_cap_dd):\n",
        "  !python merge_dd_tags_to_metadata.py \\\n",
        "    {train_data_dir} \\\n",
        "    --in_json {meta_cap} \\\n",
        "    {meta_cap_dd}\n",
        "\n",
        "# Clean meta_cap_dd.json and store it to meta_clean.json\n",
        "if os.path.exists(meta_cap_dd):\n",
        "  # Clean captions and tags in meta_cap_dd.json and store the result in meta_clean.json\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {meta_cap_dd} \\\n",
        "    {meta_clean}\n",
        "elif os.path.exists(meta_cap):\n",
        "  # If meta_cap_dd.json does not exist, clean meta_cap.json and store the result in meta_clean.json\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {meta_cap} \\\n",
        "    {meta_clean}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MEHNh0P8Yyxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gob9_OwTlwh"
      },
      "source": [
        "# Prepare Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SoucgZQ6jgPQ"
      },
      "outputs": [],
      "source": [
        "#@title Install Pre-trained Model \n",
        "%cd /content/\n",
        "import os\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists('pre_trained_model'):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs('pre_trained_model')\n",
        "\n",
        "#@title Install Pre-trained Model \n",
        "\n",
        "installModels = []\n",
        "installVae = []\n",
        "installVaeArgs = []\n",
        "installv2Models = []\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available pretrained model to download:\n",
        "#@markdown ### SD1.x model\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3-better-vae/resolve/main/any-v3-fp32-better-vae.ckpt\", \\\n",
        "            \"https://huggingface.co/Rasgeath/self_made_sauce/resolve/main/Kani-anime-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/hesw23168/SD-Elysium-Model/resolve/main/Elysium_Anime_V2.ckpt\", \\\n",
        "            \"https://huggingface.co/prompthero/openjourney-v2/resolve/main/openjourney-v2.ckpt\", \\\n",
        "            \"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/resolve/main/dreamlike-diffusion-1.0.ckpt\", \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Anything-V3\", \\\n",
        "             \"Anything-V3-better-vae\", \\\n",
        "             \"Kani-anime\", \\\n",
        "             \"Elysium-anime-V2\", \\\n",
        "             \"OpenJourney-V2\", \\\n",
        "             \"Dreamlike-diffusion-V1-0\", \\\n",
        "             \"Stable-Diffusion-v1-5\"]\n",
        "modelName = \"Anything-V3-better-vae\" #@param [\"\", \"Animefull-final-pruned\", \"Anything-V3\", \"Anything-V3-better-vae\", \"Kani-anime\", \"Elysium-anime-V2\", \"OpenJourney-V2\", \"Dreamlike-diffusion-V1-0\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "#@markdown ### SD2.x model\n",
        "v2ModelUrl = [\"\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e1.ckpt\"]\n",
        "v2ModelList = [\"\", \\\n",
        "              \"stable-diffusion-2-1-base\", \\\n",
        "              \"stable-diffusion-2-1-768v\", \\\n",
        "              \"waifu-diffusion-1-4-anime-e-1\"]\n",
        "v2ModelName = \"\" #@param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"waifu-diffusion-1-4-anime-e-1\"]\n",
        "\n",
        "#@markdown ### Custom model\n",
        "#@markdown The model URL should be a direct download link.\n",
        "\n",
        "customName = \"\" #@param {'type': 'string'}\n",
        "customUrl = \"\" #@param {'type': 'string'}\n",
        "#@markdown Change this part with your own huggingface token to download private model\n",
        "hf_token = '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' #@param {type:\"string\"}\n",
        "user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "#@markdown Select one of the VAEs to download, select `none` for not download VAE:\n",
        "vaeUrl = [\"\", \\\n",
        "          \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animevae/animevae.pt\", \\\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\", \\\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "vaeList = [\"none\", \\\n",
        "           \"anime.vae.pt\", \\\n",
        "           \"waifudiffusion.vae.pt\", \\\n",
        "           \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"none\" #@param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "\n",
        "# Check if user has specified a custom model\n",
        "if customName != \"\" and customUrl != \"\":\n",
        "  # Add custom model to list of models to install\n",
        "  installModels.append((customName, customUrl))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if modelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if v2ModelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "def install_aria():\n",
        "  # Install aria2 if it is not already installed\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  if url.endswith(\".ckpt\"):\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name) + \".ckpt\"\n",
        "  elif url.endswith(\".safetensors\"):\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name) + \".safetensors\"\n",
        "  elif url.endswith(\".pt\"):\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name)\n",
        "  else:\n",
        "    dst = \"/content/pre_trained_model/\" + str(checkpoint_name) + \".ckpt\"\n",
        "\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    # Use gdown to download file from Google Drive\n",
        "    !gdown --fuzzy -O  {dst} \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    # Use aria2c to download file from magnet link\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o {dst} \"{url}\"\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    # Use wget to download file from Hugging Face\n",
        "    !wget -c --header={user_header} \"{url}\" -O {dst}\n",
        "  else:\n",
        "    # Use wget to download file from URL\n",
        "    !wget -c \"{url}\" -O {dst}\n",
        "\n",
        "def install_checkpoint():\n",
        "  # Iterate through list of models to install\n",
        "  for model in installModels:\n",
        "    # Call install function for each model\n",
        "    install(model[0], model[1])\n",
        "\n",
        "  # Iterate through list of models to install\n",
        "  for v2model in installv2Models:\n",
        "    # Call install function for each v2model\n",
        "    install(v2model[0], v2model[1])\n",
        "    \n",
        "  if vaeName != \"none\":\n",
        "    for vae in installVae:\n",
        "      install(vae[0], vae[1])\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "# Call install_checkpoint function to download all models in the list\n",
        "install_checkpoint()\n",
        "\n",
        "# Troubleshooting\n",
        "\n",
        "file_path = \"/content/pre_trained_model/waifudiffusion.vae.pt.ckpt\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    # File exists, so rename it\n",
        "    new_file_path = \"/content/pre_trained_model/waifudiffusion.vae.pt\"\n",
        "    os.rename(file_path, new_file_path)\n",
        "else:\n",
        "    # File does not exist, so do nothing\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hhgatqF3leHJ"
      },
      "outputs": [],
      "source": [
        "#@title Aspect Ratio Bucketing \n",
        "\n",
        "# Change working directory\n",
        "%cd /content/kohya-trainer/finetune\n",
        "\n",
        "#@markdown ### Define parameters\n",
        "V2 = False #@param{type:\"boolean\"}\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {type:\"string\"}\n",
        "model_dir = \"/content/pre_trained_model/Anything-V3-better-vae.ckpt\" #@param {'type' : 'string'} \n",
        "input_json = \"/content/fine_tune/meta_clean.json\" #@param {'type' : 'string'} \n",
        "output_json = \"/content/fine_tune/meta_lat.json\"#@param {'type' : 'string'} \n",
        "batch_size = 4 #@param {'type':'integer'}\n",
        "max_resolution = \"512,512\" #@param [\"512,512\", \"640,640\", \"768,768\"] {allow-input: false}\n",
        "mixed_precision = \"no\" #@param [\"no\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "\n",
        "if V2:\n",
        "  SDV2 = \"--v2\"\n",
        "else:\n",
        "  SDV2 = \"\"\n",
        "# Run script to prepare buckets and latents\n",
        "!python prepare_buckets_latents.py \\\n",
        "  {train_data_dir} \\\n",
        "  {input_json} \\\n",
        "  {output_json} \\\n",
        "  {model_dir} \\\n",
        "  {SDV2} \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --max_resolution {max_resolution} \\\n",
        "  --mixed_precision {mixed_precision}\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNbl3O_NSS0"
      },
      "source": [
        "# Start Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Important folder\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "V2 = \"none\" #@param [\"none\", \"V2_base\", \"V2_768_v\"] {allow-input: false}\n",
        "pre_trained_model_path =\"/content/pre_trained_model/Anything-V3-better-vae.ckpt\" #@param {'type':'string'}\n",
        "meta_lat_json_dir = \"/content/fine_tune/meta_lat.json\" #@param {'type':'string'}\n",
        "train_data_dir = \"/content/fine_tune/train_data\" #@param {'type':'string'}\n",
        "output_dir =\"/content/fine_tune/output\" #@param {'type':'string'}\n",
        "resume_path = \"\" #@param {'type':'string'}\n",
        "\n",
        "#@markdown This will ignore `output_dir` defined above, and changed to `/content/drive/MyDrive/fine_tune/output` by default\n",
        "output_to_drive = False #@param {'type':'boolean'}\n",
        "\n",
        "if output_to_drive:\n",
        "  drive.mount('/content/drive')\n",
        "  output_dir = \"/content/drive/MyDrive/fine_tune/output\"\n",
        "\n",
        "# List of important folder paths\n",
        "folder_paths = [\n",
        "    pre_trained_model_path,\n",
        "    meta_lat_json_dir,\n",
        "    train_data_dir,\n",
        "    output_dir,\n",
        "    resume_path\n",
        "]\n",
        "\n",
        "# Check if each folder exists\n",
        "for folder_path in folder_paths:\n",
        "    if folder_path:\n",
        "        try:\n",
        "            if os.path.exists(folder_path):\n",
        "                print(f'{folder_path} can be used, located at {os.path.dirname(folder_path)}')\n",
        "            else:\n",
        "                pass\n",
        "        except:\n",
        "            print(f'An error occurred while checking if {folder_path} exists')\n",
        "    else:\n",
        "        print('Empty folder path')\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "#V2 Inference\n",
        "inference_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/\"\n",
        "\n",
        "if V2 == \"V2_base\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model= \"\"\n",
        "  inference_url += \"v2-inference.yaml\"\n",
        "elif V2 == \"V2_768_v\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model = \"--v2_parameterization\"\n",
        "  inference_url += \"v2-inference-v.yaml\"\n",
        "else:\n",
        "  v2_model = \"\"\n",
        "  v2_768v_model = \"\"\n",
        "\n",
        "try:\n",
        "  if V2 != \"none\":\n",
        "    !wget {inference_url} -O {output_dir}/last.yaml\n",
        "    print(\"File successfully downloaded\")\n",
        "except:\n",
        "  print(\"There was an error downloading the file. Please check the URL and try again.\")\n",
        "\n",
        "if resume_path == \"\":\n",
        "  resume_value = \"\"\n",
        "else:\n",
        "  resume_value = \"--resume \" + str(resume_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ur73rlY7bEef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X_Rd3Eh07xlA"
      },
      "outputs": [],
      "source": [
        "#@title Training begin\n",
        "#@markdown ### Define Parameters\n",
        "\n",
        "accelerate_config = \"/content/kohya-trainer/accelerate_config/config.yaml\"\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'integer'}\n",
        "save_state = True #@param {'type':'boolean'}\n",
        "train_batch_size = 1  #@param {type: \"slider\", min: 1, max: 10}\n",
        "learning_rate =\"2e-6\" #@param {'type':'string'}\n",
        "max_train_steps = 5000 #@param {'type':'integer'}\n",
        "train_text_encoder = False #@param {'type':'boolean'}\n",
        "lr_scheduler = \"constant\" #@param  [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"] {allow-input: false}\n",
        "max_token_length = \"225\" #@param  [\"150\", \"225\"] {allow-input: false}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 10}\n",
        "mixed_precision = \"fp16\" #@param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "save_model_as = \"ckpt\" #@param [\"default\", \"ckpt\", \"safetensors\", \"diffusers\", \"diffusers_safetensors\"] {allow-input: false}\n",
        "save_precision = \"None\" #@param [\"None\",\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs = 50 #@param {'type':'integer'}\n",
        "gradient_accumulation_steps = 1 #@param {type: \"slider\", min: 1, max: 10}\n",
        "#@markdown ### Log And Debug\n",
        "log_prefix = \"fine-tune-style1\" #@param {'type':'string'}\n",
        "logs_dst = \"/content/fine_tune/training_logs\" #@param {'type':'string'}\n",
        "debug_mode = False #@param {'type':'boolean'}\n",
        "\n",
        "if V2 == \"none\":\n",
        "  penultimate_layer = \"--clip_skip\" + \"=\" + \"{}\".format(clip_skip)\n",
        "else:\n",
        "  penultimate_layer = \"\"\n",
        "\n",
        "if save_every_n_epochs == 0 :\n",
        "  save_every_n_epochs_value = \"\"\n",
        "else:\n",
        "  save_every_n_epochs_value = \"--save_every_n_epochs\" + \"=\" + \"{}\".format(save_every_n_epochs)\n",
        "\n",
        "save_model_as_value_mapping = {\n",
        "    \"default\": \"\",\n",
        "    \"ckpt\": \"--save_model_as=ckpt\",\n",
        "    \"safetensors\": \"--save_model_as=safetensors\",\n",
        "    \"diffusers\": \"--save_model_as=diffusers\",\n",
        "    \"diffusers_safetensors\": \"--save_model_as=diffusers_safetensors\"\n",
        "}\n",
        "save_model_as_value = save_model_as_value_mapping[save_model_as]\n",
        "\n",
        "save_state_value_mapping = {True: \"--save_state\", False: \"\"}\n",
        "save_state_value = save_state_value_mapping[save_state]\n",
        "\n",
        "save_precision_value_mapping = {\n",
        "    \"None\": \"\",\n",
        "    \"float\": \"--save_precision=float\",\n",
        "    \"fp16\": \"--save_precision=fp16\",\n",
        "    \"bf16\": \"--save_precision=bf16\"\n",
        "}\n",
        "save_precision_value = save_precision_value_mapping[save_precision]\n",
        "\n",
        "debug_mode_value_mapping = {True: \"--debug\", False: \"\"}\n",
        "debug_mode_value = debug_mode_value_mapping[debug_mode]\n",
        "\n",
        "train_text_encoder_value_mapping = {True: \"--train_text_encoder\", False: \"\"}\n",
        "train_text_encoder_value = train_text_encoder_value_mapping[train_text_encoder]\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "!accelerate launch \\\n",
        "  --config_file {accelerate_config} \\\n",
        "  --num_cpu_threads_per_process {num_cpu_threads_per_process} \\\n",
        "  fine_tune.py \\\n",
        "  {v2_model} \\\n",
        "  {v2_768v_model} \\\n",
        "  --pretrained_model_name_or_path={pre_trained_model_path} \\\n",
        "  --in_json {meta_lat_json_dir} \\\n",
        "  --train_data_dir={train_data_dir} \\\n",
        "  --output_dir={output_dir} \\\n",
        "  --shuffle_caption \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  --lr_scheduler={lr_scheduler} \\\n",
        "  --max_token_length={max_token_length} \\\n",
        "  {penultimate_layer} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --max_train_steps={max_train_steps} \\\n",
        "  --use_8bit_adam \\\n",
        "  --xformers \\\n",
        "  --gradient_checkpointing \\\n",
        "  --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
        "  {save_model_as_value} \\\n",
        "  {train_text_encoder_value} \\\n",
        "  {save_state_value} \\\n",
        "  {resume_value} \\\n",
        "  {save_every_n_epochs_value} \\\n",
        "  {save_precision_value} \\\n",
        "  {debug_mode_value} \\\n",
        "  --logging_dir={logs_dst} \\\n",
        "  --log_prefix {log_prefix}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqfgyL-thgdw"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "V2 = \"none\" #@param [\"none\", \"V2_base\", \"V2_768_v\"] {allow-input: false}\n",
        "prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\" #@param {type: \"string\"}\n",
        "negative = \"low quality, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type: \"string\"}\n",
        "model = \"/content/fine_tune/output/last.ckpt\" #@param {type: \"string\"}\n",
        "vae = \"\" #@param {type: \"string\"}\n",
        "output_folder = \"/content/tmp\" #@param {type: \"string\"}\n",
        "scale = 12 #@param {type: \"slider\", min: 1, max: 40}\n",
        "sampler = \"ddim\" #@param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "steps = 28 #@param {type: \"slider\", min: 1, max: 100}\n",
        "precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "width = 512 #@param {type: \"integer\"}\n",
        "height = 768 #@param {type: \"integer\"}\n",
        "images_per_prompt = 4 #@param {type: \"integer\"}\n",
        "batch_size = 4 #@param {type: \"integer\"}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 40}\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "\n",
        "if vae == \"\":\n",
        "  load_vae =\"\"\n",
        "else:\n",
        "  load_vae =\"--vae \" + str(vae)\n",
        "\n",
        "if V2 == \"V2_base\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model= \"\"\n",
        "elif V2 == \"V2_768_v\":\n",
        "  v2_model = \"--v2\"\n",
        "  v2_768v_model = \"--v2_parameterization\"\n",
        "else:\n",
        "  v2_model = \"\"\n",
        "  v2_768v_model = \"\"\n",
        "\n",
        "if V2 == \"none\":\n",
        "  penultimate_layer = \"--clip_skip\" + \"=\" + \"{}\".format(clip_skip)\n",
        "else:\n",
        "  penultimate_layer = \"\"\n",
        "\n",
        "if seed <= 0:\n",
        "  seed_number = \"\"\n",
        "else:\n",
        "  seed_number = \"--seed\" + \"=\" + \"{}\".format(seed)\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "!python gen_img_diffusers.py \\\n",
        "  {v2_model} \\\n",
        "  {v2_768v_model} \\\n",
        "  --ckpt {model} \\\n",
        "  --outdir {output_folder} \\\n",
        "  --xformers \\\n",
        "  {load_vae} \\\n",
        "  --{precision} \\\n",
        "  --W {width} \\\n",
        "  --H {height} \\\n",
        "  {seed_number} \\\n",
        "  --scale {scale} \\\n",
        "  --sampler {sampler} \\\n",
        "  --steps {steps} \\\n",
        "  --max_embeddings_multiples 3 \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --images_per_prompt {images_per_prompt} \\\n",
        "  {penultimate_layer} \\\n",
        "  --prompt \"{prompt} --n {negative}\"\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j1jJ4z3AXRO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/kohya-trainer/tools\n",
        "\n",
        "#@title Convert Weight to Diffusers or `.ckpt/.safetensors` (Optional)\n",
        "#@markdown ## Define weight path\n",
        "weight = \"/content/fine_tune/output/last.ckpt\" #@param {'type': 'string'}\n",
        "weight_dir = os.path.dirname(weight)\n",
        "convert = \"ckpt_safetensors_to_diffusers\" #@param [\"diffusers_to_ckpt_safetensors\", \"ckpt_safetensors_to_diffusers\"] {'allow-input': false}\n",
        "\n",
        "#@markdown ## Conversion Config\n",
        "#@markdown\n",
        "#@markdown ### Diffusers to `.ckpt/.safetensors`\n",
        "use_safetensors = True #@param {'type': 'boolean'}\n",
        "\n",
        "if use_safetensors:\n",
        "    checkpoint = str(weight_dir)+\"/model.safetensors\"\n",
        "else:\n",
        "    checkpoint = str(weight_dir)+\"/model.ckpt\"\n",
        "\n",
        "save_precision = \"--float\" #@param [\"--fp16\",\"--bf16\",\"--float\"] {'allow-input': false}\n",
        "\n",
        "#@markdown ### `.ckpt/.safetensors` to Diffusers\n",
        "#@markdown is your model v1 or v2 based Stable Diffusion Model\n",
        "version = \"--v1\" #@param [\"--v1\",\"--v2\"] {'allow-input': false}\n",
        "diffusers = str(weight_dir)+\"/diffusers_model\"\n",
        "\n",
        "#@markdown Add reference model to get scheduler, optimizer, and tokenizer, because `.ckpt/.safetensors` didn't have one.\n",
        "reference_model =\"runwayml/stable-diffusion-v1-5\" #@param {'type': 'string'}\n",
        "\n",
        "if convert == \"diffusers_to_ckpt_safetensors\":\n",
        "    if not weight.endswith(\".ckpt\") or weight.endswith(\".safetensors\"):\n",
        "        !python convert_diffusers20_original_sd.py \\\n",
        "            {weight} \\\n",
        "            {checkpoint} \\\n",
        "            {save_precision}\n",
        "\n",
        "else:    \n",
        "    !python convert_diffusers20_original_sd.py \\\n",
        "        {weight} \\\n",
        "        {diffusers} \\\n",
        "        {version} \\\n",
        "        --reference_model {reference_model} \n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EHOvjWCHa-JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize loss graph (Optional)\n",
        "training_logs_path = \"/content/fine_tune/training_logs\" #@param {type : \"string\"}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {training_logs_path}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jgKi9y4w7tmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finishing"
      ],
      "metadata": {
        "id": "3HcaS3CObEIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compressing model or dataset\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "zip_module = \"zipfile\" #@param [\"zipfile\", \"shutil\", \"pyminizip\", \"zip\"]\n",
        "directory_to_zip = '/content/fine_tune/output/last-state/' #@param {type: \"string\"}\n",
        "output_filename = '/content/last-state.zip' #@param {type: \"string\"}\n",
        "password = \"\" #@param {type: \"string\"}\n",
        "\n",
        "%cd {directory_to_zip}\n",
        "\n",
        "if zip_module == \"zipfile\":\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(output_filename, 'w') as zip:\n",
        "        for root, dirs, files in os.walk(\"*\"):\n",
        "            for file in files:\n",
        "                zip.write(os.path.join(root, file))\n",
        "elif zip_module == \"shutil\":\n",
        "    import shutil\n",
        "    shutil.make_archive(output_filename, 'zip', \"*\")\n",
        "elif zip_module == \"pyminizip\":\n",
        "    !pip install pyminizip\n",
        "    import pyminizip\n",
        "    for root, dirs, files in os.walk(\"*\"):\n",
        "        for file in files:\n",
        "            pyminizip.compress(os.path.join(root, file), \"\", os.path.join(\"*\",output_filename), password, 5)\n",
        "elif zip_module == \"shell\":\n",
        "    !zip -r -q -j {output_filename} {directory_to_zip}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rLdEpPKTbI1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload to Huggingface\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "from pathlib import Path\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown #### Make sure you already logged in \n",
        "create_model_repo = \"test-model\" #@param{type:\"string\"}\n",
        "create_dataset_repo = \"test-dataset\" #@param{type:\"string\"}\n",
        "make_this_model_private = False #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown #### This will be uploaded to model repo\n",
        "model_path = \"/content/fine_tune/output/last.ckpt\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown #### This will be uploaded to datasets repo\n",
        "last_state_path = \"/content/fine_tune/output/last-state\" #@param {type :\"string\"}\n",
        "train_data_path = \"/content/fine_tune/train_data\" #@param {type :\"string\"}\n",
        "meta_lat_path = \"/content/fine_tune/meta_lat.json\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown ##### `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/fine_tune/training_logs\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"feat: upload 2 epoch and the last-state\" #@param {type :\"string\"}\n",
        "\n",
        "model_repo = user['name']+\"/\"+create_model_repo.strip()\n",
        "datasets_repo = user['name']+\"/\"+create_dataset_repo.strip()\n",
        "\n",
        "validate_repo_id(model_repo)\n",
        "validate_repo_id(datasets_repo)\n",
        "\n",
        "if make_this_model_private:\n",
        "  private_repo = True\n",
        "else:\n",
        "  private_repo = False\n",
        "\n",
        "try:\n",
        "    api.create_repo(repo_id=model_repo, \n",
        "                    private=private_repo)\n",
        "    print(\"Model Repo didn't exists, creating repo\")\n",
        "    print(\"Model Repo: \",model_repo,\"created!\\n\")\n",
        "except HfHubHTTPError as e:\n",
        "    print(f\"Model Repo: {model_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "try:\n",
        "    api.create_repo(repo_id=datasets_repo,\n",
        "                    repo_type=\"dataset\",\n",
        "                    private=private_repo)\n",
        "    print(\"Dataset Repo didn't exists, creating repo\")\n",
        "    print(\"Dataset Repo\",datasets_repo,\"created!\\n\")\n",
        "except HfHubHTTPError as e:\n",
        "    print(f\"Dataset repo: {datasets_repo} exists, skipping create repo\\n\")\n",
        " \n",
        "if model_path != \"\":\n",
        "  path_obj = Path(model_path)\n",
        "  model_file = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {model_file} to https://huggingface.co/\"+model_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_file(\n",
        "      path_or_fileobj=model_path,\n",
        "      path_in_repo=model_file,\n",
        "      repo_id=model_repo,\n",
        "      commit_message=commit_message,\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+model_repo+\"/blob/main/\"+model_file+\"\\n\")\n",
        "\n",
        "\n",
        "if last_state_path != \"\":\n",
        "  path_obj = Path(last_state_path)\n",
        "  last_state_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {last_state_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=last_state_path,\n",
        "      path_in_repo=last_state_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+last_state_folder+\"\\n\")\n",
        "\n",
        "\n",
        "if train_data_path != \"\":\n",
        "  path_obj = Path(train_data_path)\n",
        "  train_data_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {train_data_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=train_data_path,\n",
        "      path_in_repo=train_data_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+train_data_folder+\"\\n\")\n",
        "\n",
        "if meta_lat_path != \"\":\n",
        "  path_obj = Path(meta_lat_path)\n",
        "  meta_lat_file = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {meta_lat_file} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_file(\n",
        "      path_or_fileobj=meta_lat_path,\n",
        "      path_in_repo=meta_lat_file,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/blob/main/\"+meta_lat_file+\"\\n\")\n",
        "\n",
        "if logs_path != \"\":\n",
        "  path_obj = Path(logs_path)\n",
        "  logs_folder = path_obj.parts[-1]\n",
        "\n",
        "  print(f\"Uploading {logs_folder} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "  print(f\"Please wait...\")\n",
        "\n",
        "  api.upload_folder(\n",
        "      folder_path=logs_path,\n",
        "      path_in_repo=logs_folder,\n",
        "      repo_id=datasets_repo,\n",
        "      repo_type=\"dataset\",\n",
        "      commit_message=commit_message,\n",
        "      ignore_patterns=\".ipynb_checkpoints\",\n",
        "  )\n",
        "  print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+logs_folder+\"\\n\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pSUhgYLYdT2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}