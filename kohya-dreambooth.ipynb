{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/experimental/kohya-dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kohya Dreambooth V17 - VRAM 12GB"
      ],
      "metadata": {
        "id": "slgjeYgd6pWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted to Google Colab based on [Kohya Guide](https://note.com/kohya_ss/n/nee3ed1649fb6)<br>\n",
        "Adapted again from [bmaltais's Kohya Archive](https://github.com/bmaltais/kohya_ss)<br>\n",
        "Adapted to Google Colab by [Linaqruf](https://github.com/Linaqruf)<br>\n",
        "You can find latest notebook update [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-dreambooth.ipynb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Kohya Trainer"
      ],
      "metadata": {
        "id": "tTVqCAgSmie4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone Kohya Trainer\n",
        "#@markdown Clone the Kohya Trainer repository from GitHub and check for updates\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "def clone_kohya_trainer():\n",
        "  # Check if the directory already exists\n",
        "  if os.path.isdir('/content/kohya-trainer'):\n",
        "    %cd /content/kohya-trainer\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    !git pull\n",
        "  else:\n",
        "    !git clone https://github.com/Linaqruf/kohya-trainer\n",
        "    \n",
        "\n",
        "# Clone or update the Kohya Trainer repository\n",
        "clone_kohya_trainer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing Dependencies\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "def install_dependencies():\n",
        "  #@markdown Install required Python packages\n",
        "  !pip install --upgrade -r script/requirements.txt\n",
        "  !pip install -U gallery-dl\n",
        "  !pip install huggingface_hub\n",
        "\n",
        "  # Install WD1.4 Tagger dependencies\n",
        "  !pip install tensorflow\n",
        "\n",
        "  # Install xformers\n",
        "  !pip install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "  \n",
        "  # Install Anime Face Detector\n",
        "  !pip install openmim\n",
        "  !mim install mmcv-full\n",
        "  !mim install mmdet\n",
        "  !mim install mmpose\n",
        "  !pip install anime-face-detector\n",
        "  !pip install --upgrade numpy\n",
        "  \n",
        "# Install dependencies\n",
        "install_dependencies()"
      ],
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set config for `!Accelerate`\n",
        "\n",
        "#@markdown After Accelerate updated its version to 0.15.0, you can't manually input the config using\n",
        "#@markdown `!accelerate config` in Google Colab. Instead, a `config.yaml` file will be generated by\n",
        "#@markdown the `write_basic_config()` function. You can find the file [here](/content/kohya-trainer/accelerate_config/config.yaml)\n",
        "#@markdown if you want to modify it.\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "import os\n",
        "from accelerate.utils import write_basic_config\n",
        "\n",
        "accelerate_config = \"/content/kohya-trainer/accelerate_config/config.yaml\"\n",
        "write_basic_config(save_location = accelerate_config) # Write a config file\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RnjHb4wgD7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folders configuration\n",
        "\n",
        "Refer to the note to understand how to create the folder structure. In short it should look like:\n",
        "\n",
        "```\n",
        "<arbitrary folder name>\n",
        "|- <arbitrary class folder name>\n",
        "    |- <repeat count>_<class>\n",
        "|- <arbitrary training folder name>\n",
        "   |- <repeat count>_<token> <class>\n",
        "```\n",
        "\n",
        "Example for `asd dog` where `asd` is the token word and `dog` is the class. In this example the regularization `dog` class images contained in the folder will be repeated only 1 time and the `asd dog` images will be repeated 20 times:\n",
        "\n",
        "```\n",
        "my_asd_dog_dreambooth\n",
        "|- reg_dog\n",
        "    |- 1_dog\n",
        "       `- reg_image_1.png\n",
        "       `- reg_image_2.png\n",
        "       ...\n",
        "       `- reg_image_256.png\n",
        "|- train_dog\n",
        "    |- 20_asd dog\n",
        "       `- dog1.png\n",
        "       ...\n",
        "       `- dog8.png\n",
        "```"
      ],
      "metadata": {
        "id": "En9UUwGNMRMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create train and reg folder based on description above\n",
        "\n",
        "# Import the os and shutil modules\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Change the current working directory to /content\n",
        "%cd /content\n",
        "\n",
        "# Define the dreambooth_directory variable\n",
        "dreambooth_directory = \"/content/dreambooth\"\n",
        "\n",
        "# Check if the dreambooth directory already exists\n",
        "if os.path.isdir(dreambooth_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(dreambooth_directory)\n",
        "\n",
        "#@markdown ### Define the reg_folder variable\n",
        "reg_count = 1 #@param {type: \"integer\"}\n",
        "reg_class =\"kasakai_hikaru\" #@param {type: \"string\"}\n",
        "reg_folder = str(reg_count) + \"_\" + reg_class\n",
        "\n",
        "# Define the reg_directory variable\n",
        "reg_directory = f\"{dreambooth_directory}/reg_{reg_class}\"\n",
        "\n",
        "# Check if the reg directory already exists\n",
        "if os.path.isdir(reg_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(reg_directory)\n",
        "\n",
        "# Define the reg_folder_directory variable\n",
        "reg_folder_directory = f\"{reg_directory}/{reg_folder}\"\n",
        "\n",
        "# Check if the reg_folder directory already exists\n",
        "if os.path.isdir(reg_folder_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(reg_folder_directory)\n",
        "\n",
        "#@markdown ### Define the train_folder variable\n",
        "train_count = 3300 #@param {type: \"integer\"}\n",
        "train_token = \"sls\" #@param {type: \"string\"}\n",
        "train_class = \"kasakai_hikaru\" #@param {type: \"string\"}\n",
        "train_folder = str(train_count) + \"_\" + train_token + \"_\" + train_class\n",
        "\n",
        "# Define the train_directory variable\n",
        "train_directory = f\"{dreambooth_directory}/train_{train_class}\"\n",
        "\n",
        "# Check if the train directory already exists\n",
        "if os.path.isdir(train_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(train_directory)\n",
        "\n",
        "# Define the train_folder_directory variable\n",
        "train_folder_directory = f\"{train_directory}/{train_folder}\"\n",
        "\n",
        "# Check if the train_folder directory already exists\n",
        "if os.path.isdir(train_folder_directory):\n",
        "  # If the directory exists, do nothing\n",
        "  pass\n",
        "else:\n",
        "  # If the directory does not exist, create it\n",
        "  os.mkdir(train_folder_directory)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "-CVfXAJMSqRi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Datasets"
      ],
      "metadata": {
        "id": "Pz9A2bu1Cq73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare Regularization Images\n",
        "#@markdown Download regularization images provided by community\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Function to download and unzip regularization images\n",
        "def reg_images(url, name):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "\n",
        "  # Use wget to download the zip file\n",
        "  !wget -c --header={user_header} \"{url}\" -O /content/dreambooth/reg_{reg_class}/{reg_folder}/{name}.zip\n",
        "\n",
        "  # Unzip the downloaded file using shutil\n",
        "  shutil.unpack_archive(os.path.join('/content/dreambooth/reg_{reg_class}/{reg_folder}', f'{name}.zip'), os.path.join('/content/dreambooth/reg_{reg_class}/{reg_folder}'))\n",
        "\n",
        "  # Remove the zip file after extracting\n",
        "  os.remove(os.path.join('/content/dreambooth/reg_{reg_class}/{reg_folder}', f'{name}.zip'))\n",
        "\n",
        "category = \"waifu-regularization-3.3k\" #@param [\"\", \"waifu-regularization-3.3k\", \"husbando-regularization-3.5k\"]\n",
        "#@markdown Or you can use the file manager on the left panel to upload (drag and drop) to `reg_images` folder (it uploads faster)\n",
        "\n",
        "if category != \"\":\n",
        "  if category == \"waifu-regularization-3.3k\":\n",
        "    reg_images(\"https://huggingface.co/datasets/waifu-research-department/regularization/resolve/main/waifu-regularization-3.3k.zip\", \"waifu-regularization-3.3k\")\n",
        "  else:\n",
        "    reg_images(\"https://huggingface.co/datasets/waifu-research-department/regularization/resolve/main/husbando-regularization-3.5k.zip\", \"husbando-regularization-3.5k\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "R9JZSOuSzXe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Booru Scraper\n",
        "#@markdown Use gallery-dl to scrape images from a booru site using the specified tags\n",
        "\n",
        "%cd /content\n",
        "\n",
        "# Set configuration options\n",
        "booru = \"Danbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "tag1 = \"hito_komoru\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "\n",
        "# Construct the search query\n",
        "if tag2 != \"\":\n",
        "  tags = tag1 + \"+\" + tag2\n",
        "else:\n",
        "  tags = tag1\n",
        "\n",
        "# Scrape images from the specified booru site using the given tags\n",
        "if booru.lower() == \"danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tags}\" -D {train_folder_directory}\n",
        "elif booru.lower() == \"gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tags}\" -D {train_folder_directory}\n",
        "else:\n",
        "  print(f\"Unknown booru site: {booru}\")\n"
      ],
      "metadata": {
        "id": "Kt1GzntK_apb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`NEW` Detect Anime Face and Rotate\n",
        "This segment based on [this guide](https://note.com/kohya_ss/n/nad3bce9a3622)"
      ],
      "metadata": {
        "id": "E9ZxrCm4S8cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:\n",
        "\n",
        "```powershell\n",
        "!python detect_face_rotate.py --src_dir src --dst_dir dst --rotate\n",
        "```\n",
        "The image is rotated so that the character's face is roughly upright as shown below, and the face coordinates (center X, center Y, width, height) are added to the file name. The DreamBooth learning script uses this information to augment.\n",
        "\n",
        "**Face-centered cropping with original image size in mind**\n",
        "\n",
        "Specifying the cropped image size with the --crop_size option and the --resize_fit option resizes the short side of the image to fit the teacher data size and crops the image so that the face is centered on the long side (ignoring the face size).\n",
        "\n",
        "```powershell\n",
        "!python detect_face_rotate.py --src_dir src --dst_dir dst --rotate --crop_size 512,512 --resize_fit\n",
        "```\n",
        "\n",
        "**Uniform face-size cropping**\n",
        "\n",
        "If you specify the cropping image size with the --crop_size option and the face size with the --resize_face_size option, the image is resized so that the face is that size and then cropped with the specified size centered on the face.\n",
        "For example, in the following example\n",
        "\n",
        "```powershell\n",
        "!python detect_face_rotate.py --src_dir src --dst_dir dst --rotate --crop_size 512,512 --resize_face_size 192\n",
        "```\n",
        "\n",
        "**Or you can just skip these steps below and do augmentation while training instead.**\n",
        "\n",
        "New args for `detect face and rotate`\n",
        "```powershell\n",
        "!accelerate train_db_fixed_v12.py\n",
        "    --face_crop_aug_range=2.0,3.0 \\\n",
        "    --flip_aug \\\n",
        "    --color_aug \n",
        "```\n",
        "<!-- You can add it manually, note that you need to remove this args first or you will get error\n",
        "```powershell\n",
        "!accelerate train_db_fixed_v12.py\n",
        "    --cache_latents \\\n",
        "    --enable_bucket \\\n",
        "``` -->"
      ],
      "metadata": {
        "id": "7BBiH3bkg88d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Anime Face Augmentation\n",
        "%cd /content/kohya-trainer\n",
        "import shutil\n",
        "\n",
        "tmp = \"/content/dreambooth/tmp\"\n",
        "\n",
        "if os.path.isdir(tmp):\n",
        "  !rm -rf {tmp}\n",
        "  shutil.move (train_folder_directory, tmp)\n",
        "  !mkdir {train_folder_directory}\n",
        "else:\n",
        "  shutil.move (train_folder_directory, tmp)\n",
        "  !mkdir {train_folder_directory}\n",
        "\n",
        "!python script/detect_face_rotate_v3.py --src_dir {tmp} --dst_dir {train_folder_directory} --rotate\n",
        "\n",
        "#@markdown Args list:\n",
        "#@markdown - `--src_dir` : directory to load images\n",
        "#@markdown - `--dst_dir` : directory to save images\n",
        "#@markdown - `--rotate` : rotate images to align faces\n",
        "#@markdown - `--resize_fit` : resize to fit smaller side\n",
        "#@markdown - `--resize_face_size` : resize image before cropping by face size\n",
        "#@markdown - `--crop_size` : resize image before cropping by face size\n",
        "#@markdown - `--debug` : debug mode"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Med6ivroMqe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Pre-trained Model \n",
        "%cd /content/kohya-trainer\n",
        "import os\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists('checkpoint'):\n",
        "  # Create directory if it doesn't exist\n",
        "  os.makedirs('checkpoint')\n",
        "\n",
        "#@title Install Pre-trained Model \n",
        "\n",
        "installModels=[]\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available pretrained model to download:\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/modelsfw-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp16.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp32.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \\\n",
        "            \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Animesfw-final-pruned\", \\\n",
        "             \"Anything-V3.0-pruned-fp16\", \\\n",
        "             \"Anything-V3.0-pruned-fp32\", \\\n",
        "             \"Anything-V3.0-pruned\", \\\n",
        "             \"Stable-Diffusion-v1-4\", \\\n",
        "             \"Stable-Diffusion-v1-5-pruned-emaonly\", \\\n",
        "             \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "modelName = \"Anything-V3.0-pruned\" #@param [\"\", \"Animefull-final-pruned\", \"Animesfw-final-pruned\", \"Anything-V3.0-pruned-fp16\", \"Anything-V3.0-pruned-fp32\", \"Anything-V3.0-pruned\", \"Stable-Diffusion-v1-4\", \"Stable-Diffusion-v1-5-pruned-emaonly\", \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "\n",
        "#@markdown ### Custom model\n",
        "#@markdown The model URL should be a direct download link.\n",
        "customName = \"\" #@param {'type': 'string'}\n",
        "customUrl = \"\"#@param {'type': 'string'}\n",
        "\n",
        "# Check if user has specified a custom model\n",
        "if customName != \"\" and customUrl != \"\":\n",
        "  # Add custom model to list of models to install\n",
        "  installModels.append((customName, customUrl))\n",
        "\n",
        "# Check if user has selected a model\n",
        "if modelName != \"\":\n",
        "  # Map selected model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "def install_aria():\n",
        "  # Install aria2 if it is not already installed\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    # Use gdown to download file from Google Drive\n",
        "    !gdown --fuzzy -O \"/content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\" \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    # Use aria2c to download file from magnet link\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt \"{url}\"\n",
        "  else:\n",
        "    user_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    # Use wget to download file from URL\n",
        "    !wget -c --header={user_header} \"{url}\" -O /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  # Iterate through list of models to install\n",
        "  for model in installModels:\n",
        "    # Call install function for each model\n",
        "    install(model[0], model[1])\n",
        "\n",
        "# Call install_checkpoint function to download all models in the list\n",
        "install_checkpoint()\n"
      ],
      "metadata": {
        "id": "SoucgZQ6jgPQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Training\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNbl3O_NSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training begin\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'integer'}\n",
        "pre_trained_model_path =\"/content/kohya-trainer/checkpoint/Anything-V3.0-pruned-fp32.ckpt\" #@param {'type':'string'}\n",
        "train_data_dir = \"/content/dreambooth/train_kasakai_hikaru\" #@param {'type':'string'}\n",
        "reg_data_dir = \"/content/dreambooth/reg_kasakai_hikaru\" #@param {'type':'string'}\n",
        "output_dir =\"/content/dreambooth\" #@param {'type':'string'}\n",
        "train_batch_size = 1  #@param {type: \"slider\", min: 1, max: 10}\n",
        "resolution = \"512,512\" #@param [\"512,512\", \"768,768\"] {allow-input: false}\n",
        "learning_rate =\"2e-6\" #@param {'type':'string'}\n",
        "mixed_precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "max_train_steps = 5000 #@param {'type':'integer'}\n",
        "save_precision = \"fp16\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs = 10 #@param {'type':'integer'}\n",
        "\n",
        "%cd /content/kohya-trainer/train_db_fixed\n",
        "!accelerate launch --num_cpu_threads_per_process {num_cpu_threads_per_process} train_db_fixed.py \\\n",
        "    --pretrained_model_name_or_path={pre_trained_model_path} \\\n",
        "    --train_data_dir={train_data_dir} \\\n",
        "    --reg_data_dir={reg_data_dir} \\\n",
        "    --output_dir={output_dir} \\\n",
        "    --prior_loss_weight=1.0 \\\n",
        "    --resolution={resolution} \\\n",
        "    --train_batch_size={train_batch_size}\\\n",
        "    --learning_rate={learning_rate}\\\n",
        "    --max_train_steps={max_train_steps}  \\\n",
        "    --use_8bit_adam \\\n",
        "    --xformers \\\n",
        "    --mixed_precision={mixed_precision} \\\n",
        "    --gradient_checkpointing \\\n",
        "    --save_every_n_epochs={save_every_n_epochs} \\\n",
        "    --enable_bucket \\\n",
        "    --cache_latents \n",
        "    # --mem_eff_attn \\\n",
        "    # --face_crop_aug_range=2.0,3.0 \\\n",
        "    # --flip_aug \\\n",
        "    # --color_aug \n"
      ],
      "metadata": {
        "id": "X_Rd3Eh07xlA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert Weight to Diffusers or `.ckpt/.safetensors` (Optional)\n",
        "#@markdown ## Define weight path\n",
        "weight = \"/content/kohya-trainer/fine-tuned/last.ckpt\" #@param {'type': 'string'}\n",
        "weight_dir = {os.path.dirname(folder_path)}\n",
        "convert = \"diffusers_to_ckpt_safetensors\" #@param [\"diffusers_to_ckpt_safetensors\", \"ckpt_safetensors_to_diffusers\"] {'allow-input': false}\n",
        "\n",
        "#@markdown ## Conversion Config\n",
        "#@markdown\n",
        "#@markdown ### Diffusers to `.ckpt/.safetensors`\n",
        "use_safetensors = False #@param {'type': 'boolean'}\n",
        "\n",
        "if use_safetensors:\n",
        "    checkpoint = f\"{weight_dir}/model.safetensors\"\n",
        "else:\n",
        "    checkpoint = f\"{weight_dir}/model.ckpt\"\n",
        "\n",
        "save_precision = \"--fp16\" #@param [\"--fp16\",\"--bf16\",\"--float\"] {'allow-input': false}\n",
        "\n",
        "#@markdown ### `.ckpt/.safetensors` to Diffusers\n",
        "#@markdown is your model v1 or v2 based Stable Diffusion Model\n",
        "    version = \"--v1\" #@param [\"--v1\",\"--v2\"] {'allow-input': false}\n",
        "    diffusers = f\"{weight_dir}/diffusers_model\" \n",
        "\n",
        "#@markdown Add reference model to get scheduler, optimizer, and tokenizer, because `.ckpt/.safetensors` didn't have one.\n",
        "reference_model =\"\" #@param {'type': 'string'}\n",
        "\n",
        "if convert == \"diffusers_to_ckpt_safetensors\":\n",
        "    if not weight.endswith(\".ckpt\") or weight.endswith(\".safetensors\"):\n",
        "        !python convert_diffusers20_original_sd/convert_diffusers20_original_sd.py \\\n",
        "            {weight} \\\n",
        "            {checkpoint} \\\n",
        "            {save_precision}\n",
        "\n",
        "else:    \n",
        "    !python convert_diffusers20_original_sd/convert_diffusers20_original_sd.py \\\n",
        "        {weight} \\\n",
        "        {diffusers} \\ \n",
        "        {v2} \\\n",
        "        --reference_model {reference_model} \n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HPbZ0E2uNYYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Pruner (Optional)\n",
        "\n",
        "##Lopho\n",
        "\n",
        "#@markdown Do you want to Prune a model?\n",
        "%cd /content/ \n",
        "\n",
        "# Use a more descriptive variable name\n",
        "prune = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--fp16` argument\n",
        "fp16 = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--ema` argument\n",
        "ema = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--no-clip` argument\n",
        "no_clip = False #@param {'type':'boolean'}\n",
        "\n",
        "# Add a checkbox to enable/disable the `--no-vae` argument\n",
        "no_vae = False #@param {'type':'boolean'}\n",
        "\n",
        "# Use a more descriptive variable name\n",
        "input = \"/content/kohya-trainer/fine_tuned/last.ckpt\" #@param {'type' : 'string'}\n",
        "\n",
        "# Use a more descriptive variable name\n",
        "output = \"/content/kohya-trainer/fine_tuned/last-pruned.ckpt\" #@param {'type' : 'string'}\n",
        "\n",
        "if prune:\n",
        "  import os\n",
        "  if os.path.isfile('/content/prune.py'):\n",
        "    pass\n",
        "  else:\n",
        "    # Add a comment to explain what the code is doing\n",
        "    # Download the pruning script if it doesn't already exist\n",
        "    !wget https://raw.githubusercontent.com/lopho/stable-diffusion-prune/main/prune.py\n",
        "\n",
        "\n",
        "# Add a comment to explain what the code is doing\n",
        "# Run the pruning script with the specified arguments\n",
        "!python3 prune.py {input} {output} {'--fp16' if fp16 else ''} {'--ema' if ema else ''} {'--no-clip' if no_clip else ''} {'--no-vae' if no_vae else ''}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Yiskg-mZX0Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jypUkLWc48R_"
      },
      "source": [
        "## Commit trained model to Huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvZgRSmKVSRw"
      },
      "source": [
        "### To Commit models:\n",
        "1. Create a huggingface repository for your model.\n",
        "2. Clone your model to this Colab session.\n",
        "3. Move the necessary files to your repository to save your trained model to huggingface. These files are located in `fine-tuned` folder:\n",
        "   - `epoch-nnnnn.ckpt` and/or\n",
        "   - `last.ckpt`\n",
        "4. Commit your model to huggingface.\n",
        "\n",
        "### To Commit datasets:\n",
        "1. Create a huggingface repository for your datasets.\n",
        "2. Clone your datasets to this Colab session.\n",
        "3. Move the necessary files to your repository so that you can resume training without rebuilding your dataset with this notebook.\n",
        "  - The `train_folder` folder.\n",
        "4. Commit your datasets to huggingface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "182Law9oUiYN"
      },
      "outputs": [],
      "source": [
        "#@title Clone Model or Datasets\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out = True #@param {'type':'boolean'}\n",
        "\n",
        "#@markdown Type of item to clone (model or dataset)\n",
        "type_of_item = \"model\" #@param [\"model\", \"dataset\"]\n",
        "\n",
        "#@markdown Install or uninstall git lfs\n",
        "install_git_lfs = False #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  username = \"your-huggingface-username\" #@param {'type': 'string'}\n",
        "  model_repo = \"your-huggingface-model-repo\" #@param {'type': 'string'}\n",
        "  datasets_repo = \"your-huggingface-datasets-repo\" #@param {'type': 'string'}\n",
        "  \n",
        "  if type_of_item == \"model\":\n",
        "    Repository_url = f\"https://huggingface.co/{username}/{model_repo}\"\n",
        "  elif type_of_item == \"dataset\":\n",
        "    Repository_url = f\"https://huggingface.co/datasets/{username}/{datasets_repo}\"\n",
        "\n",
        "  if install_git_lfs:\n",
        "    !git lfs install\n",
        "  else:\n",
        "    !git lfs uninstall\n",
        "\n",
        "  !git clone {Repository_url}\n",
        "else:\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "87wG7QIZbtZE"
      },
      "outputs": [],
      "source": [
        "#@title Commit Model or Datasets to Huggingface\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out = True #@param {'type':'boolean'}\n",
        "\n",
        "#@markdown Type of item to commit (model or dataset)\n",
        "type_of_item = \"model\" #@param [\"model\", \"dataset\"]\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  #@markdown Go to your model or dataset path\n",
        "  item_path = \"your-cloned-model-or-datasets-repo\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "  email = \"your-email\" #@param {'type': 'string'}\n",
        "  name = \"your-username\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m = \"feat: upload 6 epochs model\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd {item_path}\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  pass"
      ]
    }
  ]
}