{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer-v3-wd-1-4-tagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kohya Trainer V3 - VRAM 12GB\n",
        "###Best way to train Stable Diffusion model for peeps who didn't have good GPU"
      ],
      "metadata": {
        "id": "slgjeYgd6pWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted to Google Colab based on [Kohya Guide](https://note.com/kohya_ss/n/nbf7ce8d80f29#c9d7ee61-5779-4436-b4e6-9053741c46bb)\n",
        "\n",
        "Adapted to Google Colab by [Linaqruf](https://github.com/Linaqruf)\n",
        "\n",
        "You can find latest notebook update [here](https://github.com/Linaqruf/DiffuserV2/blob/main/DiffuserV2%2BScraper.ipynb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is this?\n"
      ],
      "metadata": {
        "id": "v3Qxv-rCXshE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####**_Q: So what's differences between `Kohya Trainer` and other diffusers out there?_**\n",
        "#####A: **Kohya Trainer** have some new features like\n",
        "1. Using the U-Net learning\n",
        "2. Automatic captioning/tagging for every image automatically with BLIP/DeepDanbooru\n",
        "3. Read all captions/tags created and put them in metadata.json\n",
        "4. Implemented [NovelAI Aspect Ratio Bucketing Tool](https://github.com/NovelAI/novelai-aspect-ratio-bucketing) so you don't need to crop image dataset 512x512 ever again\n",
        "- Use the output of the second-to-last layer of CLIP (Text Encoder) instead of the last layer.\n",
        "- Learning at non-square resolutions (Aspect Ratio Bucketing) .\n",
        "- Extend token length from 75 to 225.\n",
        "5. By preparing a certain number of images (several hundred or more seems to be desirable), you can make learning even more flexible than with DreamBooth.\n",
        "6. It also support Hypernetwork learning\n",
        "7. `NEW!` Implemented Waifu Diffusion 1.4 Tagger for alternative DeepDanbooru to auto-tagging.\n",
        "\n",
        "#####**_Q: And what's differences between this notebook and other dreambooth notebook out there?_**\n",
        "#####A: We're adding Quality of Life features such as:\n",
        "- Install **gallery-dl** to scrap images, so you can get your own dataset fast with google bandwidth\n",
        "- Huggingface Integration, here you can login to huggingface-hub and upload your trained model/dataset to huggingface\n",
        "---"
      ],
      "metadata": {
        "id": "gSSojWxg7cFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "h3AuTNu6MFZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Diffuser\n",
        "%cd /content/\n",
        "!pip install --upgrade pip\n",
        "!pip install diffusers[torch]==0.7.2"
      ],
      "metadata": {
        "id": "Aq5cjtG5nJ3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Requirement Library\n",
        "%cd /content/\n",
        "!pip install torch\n",
        "!pip install accelerate\n",
        "!pip install transformers\n",
        "!pip install ftfy\n",
        "!pip install albumentations\n",
        "!pip install opencv-python\n",
        "!pip install einops\n",
        "!pip install pytorch_lightning\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "4bJ5O9X3pmvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Xformers (T4)\n",
        "%cd /content/\n",
        "!git clone https://github.com/openai/triton.git\n",
        "\n",
        "# Install Triton\n",
        "%cd /content/triton/python\n",
        "!pip install -e .\n",
        "\n",
        "# Install Xformers\n",
        "%pip install -qq https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.14/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "Q_DPyXcDqv8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install DiffuserV3"
      ],
      "metadata": {
        "id": "tTVqCAgSmie4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x"
      },
      "outputs": [],
      "source": [
        "#@title Cloning DiffuserV3\n",
        "%cd /content/\n",
        "!git clone https://github.com/Linaqruf/kohya-trainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install DiffuserV3 Requirement\n",
        "%cd /content/kohya-trainer\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "WNn0g1pnHfk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Danbooru Scraper"
      ],
      "metadata": {
        "id": "En9UUwGNMRMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install gallery-dl library\n",
        "!pip install -U gallery-dl"
      ],
      "metadata": {
        "id": "dBi4pk7hy-Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Danbooru Scraper\n",
        "#@markdown **How this work?**\n",
        "\n",
        "#@markdown By using **gallery-dl** we can scrap or bulk download images on Internet, on this notebook we will scrap images from Danbooru using tag1 and tag2 as target scraping.\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "tag = \"hito_komoru \" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "output_dir = \"/content/kohya-trainer/train_data\" \n",
        "\n",
        "if tag2 is not \"\":\n",
        "  tag = tag + \"+\" + tag2\n",
        "else:\n",
        "  tag = tag\n",
        "\n",
        "def danbooru_dl():\n",
        "   !gallery-dl \"https://danbooru.donmai.us/posts?tags={tag}+&z=5\" -D {output_dir}\n",
        "\n",
        "danbooru_dl()\n",
        "\n",
        "#@markdown The output directory will be on /content/kohya-trainer/train_data. We also will use this folder as target folder for training next step.\n",
        "\n"
      ],
      "metadata": {
        "id": "Kt1GzntK_apb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DeepDanbooru3 for Autotagger\n",
        "We will skip BLIP Captioning section and only used DeepDanbooru for Autotagging.\n",
        "\n",
        "If you still want to use BLIP, please refer to the original article [here](https://note.com/kohya_ss/n/nbf7ce8d80f29#c9d7ee61-5779-4436-b4e6-9053741c46bb)"
      ],
      "metadata": {
        "id": "cSbB9CeqMwbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install DeepDanbooru\n",
        "%cd /content/\n",
        "!git clone https://github.com/KichangKim/DeepDanbooru kohya-trainer/deepdanbooru\n",
        "\n",
        "%cd /content/kohya-trainer/deepdanbooru\n",
        "!pip install -r requirements.txt\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "AsLO2-REM8Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install DeepDanbooru3 Model Weight\n",
        "%cd /content/kohya-trainer/deepdanbooru\n",
        "!wget -c https://github.com/KichangKim/deepdanbooru/releases/download/v3-20211112-sgd-e28/deepdanbooru-v3-20211112-sgd-e28.zip -O deepdanbooruv3.zip\n",
        "!mkdir deepdanbooruv3\n",
        "!mv deepdanbooruv3.zip deepdanbooruv3"
      ],
      "metadata": {
        "id": "p8Y1SWWwUO26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip DeepDanbooru3 Model\n",
        "%cd /content/kohya-trainer/deepdanbooru/deepdanbooruv3\n",
        "!unzip deepdanbooruv3.zip \n",
        "!rm -rf deepdanbooruv3.zip"
      ],
      "metadata": {
        "id": "4H5vSQnFXhTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Batch Tag Interrogating and save it as (.txt)\n",
        "%cd /content/kohya-trainer/deepdanbooru/deepdanbooruv3\n",
        "!deepdanbooru evaluate /content/kohya-trainer/train_data \\\n",
        "  --project-path /content/kohya-trainer/deepdanbooru/deepdanbooruv3 \\\n",
        "  --allow-folder \\\n",
        "  --save-txt"
      ],
      "metadata": {
        "id": "hibZK5NPTjZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Metadata from tags collected\n",
        "%cd /content/kohya-trainer\n",
        "!python merge_dd_tags_to_metadata.py train_data meta_cap_dd.json"
      ],
      "metadata": {
        "id": "hz2Cmlf2ay9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean Metadata.json (not sure it works)\n",
        "%cd /content/kohya-trainer\n",
        "!python clean_captions_and_tags.py train_data meta_cap_dd.json meta_clean.json"
      ],
      "metadata": {
        "id": "WFq28pPWjLpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Checkpoint"
      ],
      "metadata": {
        "id": "3gob9_OwTlwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Checkpoint\n",
        "%cd /content/kohya-trainer\n",
        "!mkdir checkpoint\n",
        "#@title Download Available Checkpoint\n",
        "\n",
        "def huggingface_checkpoint(url, checkpoint_name):\n",
        "  #@markdown Insert your Huggingface token below\n",
        "  user_token = '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' #@param {'type': 'string'}\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def custom_checkpoint(url, checkpoint_name):\n",
        "  !wget {url} -O /checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  #@markdown Choose the models you want:\n",
        "  Animefull_Final_Pruned= False #@param {'type':'boolean'}\n",
        "  Waifu_Diffusion_V1_3 = False #@param {'type':'boolean'}\n",
        "  Anything_V3_0_Pruned = True #@param {'type':'boolean'}\n",
        "\n",
        "  if Animefull_Final_Pruned:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \"Animefull_Final_Pruned\")\n",
        "  if Waifu_Diffusion_V1_3:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\", \"Waifu_Diffusion_V1_3\")\n",
        "  if Anything_V3_0_Pruned:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \"Anything_V3_0_Pruned\")\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "id": "SoucgZQ6jgPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Custom Checkpoint\n",
        "#@markdown If your checkpoint aren't provided on the cell above, you can insert your own here.\n",
        "\n",
        "ckptName = \"\" #@param {'type': 'string'}\n",
        "ckptURL = \"\" #@param {'type': 'string'}\n",
        "\n",
        "def custom_checkpoint(url, name):\n",
        "  !wget -c {url} -O /content/DiffuserV2/{name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  if ckptName and ckptURL is not \"\" :\n",
        "    custom_checkpoint(ckptName, ckptURL)\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "id": "vrQ3_jbFTrgL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare Training"
      ],
      "metadata": {
        "id": "15xUbLvQNN28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NovelAI Aspect Ratio Bucketing Script\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "model_dir= \"/content/kohya-trainer/checkpoint/Anything_V3_0_Pruned.ckpt\" #@param {'type' : 'string'} \n",
        "\n",
        "!python prepare_buckets_latents.py train_data meta_cap_dd.json meta_lat.json {model_dir} \\\n",
        "  --batch_size 4 \\\n",
        "  --max_resolution 512,512 \\\n",
        "  --mixed_precision no"
      ],
      "metadata": {
        "id": "hhgatqF3leHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set config for Accelerate\n",
        "#@markdown #Hint\n",
        "\n",
        "#@markdown 1. **In which compute environment are you running?** ([0] This machine, [1] AWS (Amazon SageMaker)): `0`\n",
        "#@markdown 2. **Which type of machine are you using?** ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU [4] MPS): `0`\n",
        "#@markdown 3. **Do you want to run your training on CPU only (even if a GPU is available)?** [yes/NO]: `NO`\n",
        "#@markdown 4. **Do you want to use DeepSpeed?** [yes/NO]: `NO`\n",
        "#@markdown 5. **What GPU(s) (by id) should be used for training on this machine as a comma-seperated list?** [all] = `all`\n",
        "#@markdown 6. **Do you wish to use FP16 or BF16 (mixed precision)?** [NO/fp16/bf16]: `fp16`\n",
        "!accelerate config"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RnjHb4wgD7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Training\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNbl3O_NSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training begin\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'integer'}\n",
        "model_path =\"/content/kohya-trainer/checkpoint/Anything_V3_0_Pruned.ckpt\" #@param {'type':'string'}\n",
        "output_dir =\"/content/kohya-trainer/fine_tuned\" #@param {'type':'string'}\n",
        "train_batch_size = 1  #@param {type: \"slider\", min: 1, max: 10}\n",
        "learning_rate =\"2e-6\" #@param {'type':'string'}\n",
        "max_token_length = 225 #@param {'type':'integer'}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 10}\n",
        "mixed_precision = \"fp16\" #@param [\"fp16\", \"bp16\"] {allow-input: false}\n",
        "max_train_steps = 5000 #@param {'type':'integer'}\n",
        "# save_precision = \"fp16\" #@param [\"fp16\", \"bp16\", \"float\"] {allow-input: false}\n",
        "save_every_n_epochs = 10 #@param {'type':'integer'}\n",
        "gradient_accumulation_steps = 1 #@param {type: \"slider\", min: 1, max: 10}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "!accelerate launch --num_cpu_threads_per_process {num_cpu_threads_per_process} fine_tune.py \\\n",
        "  --pretrained_model_name_or_path={model_path} \\\n",
        "  --in_json meta_lat.json \\\n",
        "  --train_data_dir=train_data \\\n",
        "  --output_dir={output_dir} \\\n",
        "  --shuffle_caption \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  --max_token_length={max_token_length} \\\n",
        "  --clip_skip={clip_skip} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --max_train_steps={max_train_steps}  \\\n",
        "  --use_8bit_adam \\\n",
        "  --xformers \\\n",
        "  --gradient_checkpointing \\\n",
        "  --save_every_n_epochs={save_every_n_epochs} \\\n",
        "  --save_state #For Resume Training\n",
        "  # --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
        "  # --resume /content/kohya-trainer/checkpoint/last-state \\\n",
        "  # --save_precision={save_precision} \\\n",
        "\n"
      ],
      "metadata": {
        "id": "X_Rd3Eh07xlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Miscellaneous"
      ],
      "metadata": {
        "id": "vqfgyL-thgdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Pruner\n",
        "#@markdown Do you want to Pruning model?\n",
        "\n",
        "prune = False #@param {'type':'boolean'}\n",
        "\n",
        "model_path = \"betabeet_5000_steps_2e-6.ckpt\" #@param {'type' : 'string'}\n",
        "if prune == True:\n",
        "  import os\n",
        "  if os.path.isfile('/content/prune-ckpt.py'):\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    \n",
        "  else:\n",
        "    !wget https://raw.githubusercontent.com/prettydeep/Dreambooth-SD-ckpt-pruning/main/prune-ckpt.py\n",
        "\n",
        "\n",
        "  !python prune-ckpt.py --ckpt {model_path}\n",
        "\n"
      ],
      "metadata": {
        "id": "LUOG7BzQVLKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount to Google Drive\n",
        "mount_drive= False #@param {'type':'boolean'}\n",
        "\n",
        "if mount_drive== True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OuRqOSp2eU6t",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Huggingface_hub Integration"
      ],
      "metadata": {
        "id": "QtVP2le8PL2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instruction:\n",
        "0. Of course you need a Huggingface Account first\n",
        "1. Create your huggingface model repository\n",
        "2. Create huggingface token, go to `Profile > Access Tokens > New Token > Create a new access token` with the `Write` role.\n",
        "3. All cells below are checked `opt-out` by default so you need to uncheck it if you want to running the cells."
      ],
      "metadata": {
        "id": "tbKgmh_AO5NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login to Huggingface hub\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "#@markdown Prepare your Huggingface token\n",
        "\n",
        "saved_token= \"\" #@param {'type': 'string'}\n",
        "\n",
        "if opt_out == False:\n",
        "  from huggingface_hub import notebook_login\n",
        "  notebook_login()\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "id": "Da7awoqAPJ3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Commit trained model to Huggingface"
      ],
      "metadata": {
        "id": "jypUkLWc48R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Model\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "\n",
        "if opt_out == False:\n",
        "  !pip install huggingface_hub\n",
        "\n",
        "  %cd /content\n",
        "\n",
        "  from huggingface_hub import notebook_login\n",
        "\n",
        "  notebook_login()\n",
        "\n",
        "  Repository_url = \"https://huggingface.co/Linaqruf/hitokomoru\" #@param {'type': 'string'}\n",
        "  !git clone {Repository_url}\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "id": "182Law9oUiYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Commit to Huggingface\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  #@markdown Go to your model path\n",
        "  model_path= \"hitokomoru\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown Your path look like /content/**model_path**\n",
        "  #@markdown ___\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "\n",
        "  email= \"your-email\" #@param {'type': 'string'}\n",
        "  name= \"your-username\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m= \"Push: hitokomoru-5000\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd \"/content/{model_path}\"\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))\n"
      ],
      "metadata": {
        "id": "87wG7QIZbtZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Commit dataset to huggingface"
      ],
      "metadata": {
        "id": "olP2yaK3OKcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Zip train_data\n",
        "\n",
        "%cd /content\n",
        "!zip -r /content/train_data /content/kohya-trainer/train_data"
      ],
      "metadata": {
        "id": "BZ8Nrx4-hoQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Dataset\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "\n",
        "if opt_out == False:\n",
        "  !pip install huggingface_hub\n",
        "\n",
        "  %cd /content\n",
        "\n",
        "  Repository_url = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-tag\" #@param {'type': 'string'}\n",
        "  !git clone {Repository_url}\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "id": "QhL6UgqDOURK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Commit to Huggingface\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  #@markdown Go to your model path\n",
        "  dataset_path= \"hitokomoru-tag\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown Your path look like /content/**dataset_path**\n",
        "  #@markdown ___\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "\n",
        "  email= \"your-email\" #@param {'type': 'string'}\n",
        "  name= \"your-name\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m= \"Push: hitokomoru-tag\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd \"/content/{dataset_path}\"\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))\n"
      ],
      "metadata": {
        "id": "abHLg4I0Os5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}