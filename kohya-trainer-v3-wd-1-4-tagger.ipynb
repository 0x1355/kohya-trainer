{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer-v3-wd-1-4-tagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kohya Trainer V3 - VRAM 12GB\n",
        "###Best way to train Stable Diffusion model for peeps who didn't have good GPU"
      ],
      "metadata": {
        "id": "slgjeYgd6pWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted to Google Colab based on [Kohya Guide](https://note.com/kohya_ss/n/nbf7ce8d80f29#c9d7ee61-5779-4436-b4e6-9053741c46bb)\n",
        "\n",
        "Adapted to Google Colab by [Linaqruf](https://github.com/Linaqruf)\n",
        "\n",
        "You can find latest notebook update [here](https://github.com/Linaqruf/DiffuserV2/blob/main/DiffuserV2%2BScraper.ipynb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is this?\n"
      ],
      "metadata": {
        "id": "v3Qxv-rCXshE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####**_Q: So what's differences between `Kohya Trainer` and other diffusers out there?_**\n",
        "#####A: **Kohya Trainer** have some new features like\n",
        "1. Using the U-Net learning\n",
        "2. Automatic captioning/tagging for every image automatically with BLIP/DeepDanbooru\n",
        "3. Read all captions/tags created and put them in metadata.json\n",
        "4. Implemented [NovelAI Aspect Ratio Bucketing Tool](https://github.com/NovelAI/novelai-aspect-ratio-bucketing) so you don't need to crop image dataset 512x512 ever again\n",
        "- Use the output of the second-to-last layer of CLIP (Text Encoder) instead of the last layer.\n",
        "- Learning at non-square resolutions (Aspect Ratio Bucketing) .\n",
        "- Extend token length from 75 to 225.\n",
        "5. By preparing a certain number of images (several hundred or more seems to be desirable), you can make learning even more flexible than with DreamBooth.\n",
        "6. It also support Hypernetwork learning\n",
        "7. `NEW!` 23/11 - Implemented Waifu Diffusion 1.4 Tagger for alternative DeepDanbooru to auto-tagging.\n",
        "\n",
        "#####**_Q: And what's differences between this notebook and other dreambooth notebook out there?_**\n",
        "#####A: We're adding Quality of Life features such as:\n",
        "- Install **gallery-dl** to scrap images, so you can get your own dataset fast with google bandwidth\n",
        "- Huggingface Integration, here you can login to huggingface-hub and upload your trained model/dataset to huggingface\n",
        "---"
      ],
      "metadata": {
        "id": "gSSojWxg7cFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "h3AuTNu6MFZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Diffuser\n",
        "%cd /content/\n",
        "!pip install --upgrade pip\n",
        "!pip install diffusers[torch]==0.7.2"
      ],
      "metadata": {
        "id": "Aq5cjtG5nJ3Y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Xformers (T4)\n",
        "%cd /content/\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from IPython.display import HTML\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -qq https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.14/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl"
      ],
      "metadata": {
        "id": "Q_DPyXcDqv8J",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Kohya Trainer v3"
      ],
      "metadata": {
        "id": "tTVqCAgSmie4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Cloning Kohya Trainer v3\n",
        "%cd /content/\n",
        "!git clone https://github.com/Linaqruf/kohya-trainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install DiffuserV3 Requirement\n",
        "%cd /content/kohya-trainer\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Danbooru Scraper"
      ],
      "metadata": {
        "id": "En9UUwGNMRMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install `gallery-dl` library\n",
        "!pip install -U gallery-dl"
      ],
      "metadata": {
        "id": "dBi4pk7hy-Jg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Danbooru Scraper\n",
        "#@markdown **How this work?**\n",
        "\n",
        "#@markdown By using **gallery-dl** we can scrap or bulk download images on Internet, on this notebook we will scrap images from Danbooru using tag1 and tag2 as target scraping.\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "tag = \"cyobiro\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "output_dir = \"/content/kohya-trainer/train_data\" \n",
        "\n",
        "if tag2 is not \"\":\n",
        "  tag = tag + \"+\" + tag2\n",
        "else:\n",
        "  tag = tag\n",
        "\n",
        "def danbooru_dl():\n",
        "   !gallery-dl \"https://danbooru.donmai.us/posts?tags={tag}+&z=5\" -D {output_dir}\n",
        "\n",
        "danbooru_dl()\n",
        "\n",
        "#@markdown The output directory will be on /content/kohya-trainer/train_data. We also will use this folder as target folder for training next step.\n",
        "\n"
      ],
      "metadata": {
        "id": "Kt1GzntK_apb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`(NEW)` Waifu Diffusion 1.4 Autotagger"
      ],
      "metadata": {
        "id": "SoPUJaTpTusz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Tensorflow\n",
        "%cd /content/\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "cellView": "form",
        "id": "POJhWn28XrPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Weight\n",
        "%cd /content/kohya-trainer/\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def huggingface_dl(url, weight):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/kohya-trainer/wd14tagger-weight/{weight}\n",
        "\n",
        "def download_weight():\n",
        "  huggingface_dl(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/wd14tagger-weight/wd14Tagger.zip\", \"wd14Tagger.zip\")\n",
        "  \n",
        "  !unzip /content/kohya-trainer/wd14tagger-weight/wd14Tagger.zip -d /content/kohya-trainer/wd14tagger-weight\n",
        "\n",
        "  # Destination path \n",
        "  destination = '/content/kohya-trainer/wd14tagger-weight'\n",
        "\n",
        "  if os.path.isfile('/content/kohya-trainer/tag_images_by_wd14_tagger.py'):\n",
        "    # Move the content of \n",
        "    # source to destination \n",
        "    shutil.move(\"tag_images_by_wd14_tagger.py\", destination) \n",
        "  else:\n",
        "    pass\n",
        "\n",
        "download_weight()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WDSlAEHzT2Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Autotagger\n",
        "%cd /content/kohya-trainer/wd14tagger-weight\n",
        "!python tag_images_by_wd14_tagger.py --batch_size 4 /content/kohya-trainer/train_data"
      ],
      "metadata": {
        "id": "hibZK5NPTjZQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Metadata.json\n",
        "%cd /content/kohya-trainer\n",
        "!python merge_dd_tags_to_metadata.py train_data meta_cap_dd.json"
      ],
      "metadata": {
        "id": "hz2Cmlf2ay9w",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Checkpoint"
      ],
      "metadata": {
        "id": "3gob9_OwTlwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Checkpoint\n",
        "%cd /content/kohya-trainer\n",
        "!mkdir checkpoint\n",
        "#@title Download Available Checkpoint\n",
        "\n",
        "def huggingface_checkpoint(url, checkpoint_name):\n",
        "  #@markdown Insert your Huggingface token below\n",
        "  user_token = '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' #@param {'type': 'string'}\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def custom_checkpoint(url, checkpoint_name):\n",
        "  !wget {url} -O /checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  #@markdown Choose the models you want:\n",
        "  Animefull_Final_Pruned= False #@param {'type':'boolean'}\n",
        "  Waifu_Diffusion_V1_3 = False #@param {'type':'boolean'}\n",
        "  Anything_V3_0_Pruned = True #@param {'type':'boolean'}\n",
        "\n",
        "  if Animefull_Final_Pruned:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \"Animefull_Final_Pruned\")\n",
        "  if Waifu_Diffusion_V1_3:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\", \"Waifu_Diffusion_V1_3\")\n",
        "  if Anything_V3_0_Pruned:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \"Anything_V3_0_Pruned\")\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "id": "SoucgZQ6jgPQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Custom Checkpoint\n",
        "#@markdown If your checkpoint aren't provided on the cell above, you can insert your own here.\n",
        "\n",
        "ckptName = \"\" #@param {'type': 'string'}\n",
        "ckptURL = \"\" #@param {'type': 'string'}\n",
        "\n",
        "def custom_checkpoint(url, name):\n",
        "  !wget -c {url} -O /content/kohya-trainer/{name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  if ckptName and ckptURL is not \"\" :\n",
        "    custom_checkpoint(ckptName, ckptURL)\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "id": "vrQ3_jbFTrgL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare Training"
      ],
      "metadata": {
        "id": "15xUbLvQNN28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NovelAI Aspect Ratio Bucketing Script\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "model_dir= \"/content/kohya-trainer/checkpoint/Anything_V3_0_Pruned.ckpt\" #@param {'type' : 'string'} \n",
        "\n",
        "!python prepare_buckets_latents.py train_data meta_cap_dd.json meta_lat.json {model_dir} \\\n",
        "  --batch_size 4 \\\n",
        "  --max_resolution 512,512 \\\n",
        "  --mixed_precision no"
      ],
      "metadata": {
        "id": "hhgatqF3leHJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set config for `!Accelerate`\n",
        "#@markdown #Hint\n",
        "\n",
        "#@markdown 1. **In which compute environment are you running?** ([0] This machine, [1] AWS (Amazon SageMaker)): `0`\n",
        "#@markdown 2. **Which type of machine are you using?** ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU [4] MPS): `0`\n",
        "#@markdown 3. **Do you want to run your training on CPU only (even if a GPU is available)?** [yes/NO]: `NO`\n",
        "#@markdown 4. **Do you want to use DeepSpeed?** [yes/NO]: `NO`\n",
        "#@markdown 5. **What GPU(s) (by id) should be used for training on this machine as a comma-seperated list?** [all] = `all`\n",
        "#@markdown 6. **Do you wish to use FP16 or BF16 (mixed precision)?** [NO/fp16/bf16]: `fp16`\n",
        "!accelerate config"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RnjHb4wgD7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Training\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNbl3O_NSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training begin\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'integer'}\n",
        "model_path =\"/content/kohya-trainer/checkpoint/Anything_V3_0_Pruned.ckpt\" #@param {'type':'string'}\n",
        "output_dir =\"/content/kohya-trainer/fine_tuned\" #@param {'type':'string'}\n",
        "train_batch_size = 1  #@param {type: \"slider\", min: 1, max: 10}\n",
        "learning_rate =\"2e-6\" #@param {'type':'string'}\n",
        "max_token_length = 225 #@param {'type':'integer'}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 10}\n",
        "mixed_precision = \"fp16\" #@param [\"fp16\", \"bp16\"] {allow-input: false}\n",
        "max_train_steps = 5000 #@param {'type':'integer'}\n",
        "# save_precision = \"fp16\" #@param [\"fp16\", \"bp16\", \"float\"] {allow-input: false}\n",
        "save_every_n_epochs = 50 #@param {'type':'integer'}\n",
        "# gradient_accumulation_steps = 1 #@param {type: \"slider\", min: 1, max: 10}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "!accelerate launch --num_cpu_threads_per_process {num_cpu_threads_per_process} fine_tune.py \\\n",
        "  --pretrained_model_name_or_path={model_path} \\\n",
        "  --in_json meta_lat.json \\\n",
        "  --train_data_dir=train_data \\\n",
        "  --output_dir={output_dir} \\\n",
        "  --shuffle_caption \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  --max_token_length={max_token_length} \\\n",
        "  --clip_skip={clip_skip} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --max_train_steps={max_train_steps}  \\\n",
        "  --use_8bit_adam \\\n",
        "  --xformers \\\n",
        "  --gradient_checkpointing \\\n",
        "  --save_every_n_epochs={save_every_n_epochs} \\\n",
        "  --save_state #For Resume Training\n",
        "  # --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
        "  # --resume /content/kohya-trainer/checkpoint/last-state \\\n",
        "  # --save_precision={save_precision} \\\n",
        "\n"
      ],
      "metadata": {
        "id": "X_Rd3Eh07xlA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Miscellaneous"
      ],
      "metadata": {
        "id": "vqfgyL-thgdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Pruner\n",
        "#@markdown Do you want to Pruning model?\n",
        "\n",
        "prune = False #@param {'type':'boolean'}\n",
        "\n",
        "model_path = \"betabeet_5000_steps_2e-6.ckpt\" #@param {'type' : 'string'}\n",
        "if prune == True:\n",
        "  import os\n",
        "  if os.path.isfile('/content/prune-ckpt.py'):\n",
        "    print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "    \n",
        "  else:\n",
        "    !wget https://raw.githubusercontent.com/prettydeep/Dreambooth-SD-ckpt-pruning/main/prune-ckpt.py\n",
        "\n",
        "\n",
        "  !python prune-ckpt.py --ckpt {model_path}\n",
        "\n"
      ],
      "metadata": {
        "id": "LUOG7BzQVLKp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount to Google Drive\n",
        "mount_drive= False #@param {'type':'boolean'}\n",
        "\n",
        "if mount_drive== True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OuRqOSp2eU6t",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Huggingface_hub Integration"
      ],
      "metadata": {
        "id": "QtVP2le8PL2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instruction:\n",
        "0. Of course you need a Huggingface Account first\n",
        "1. Create huggingface token, go to `Profile > Access Tokens > New Token > Create a new access token` with the `Write` role.\n",
        "2. All cells below are checked `opt-out` by default so you need to uncheck it if you want to running the cells."
      ],
      "metadata": {
        "id": "tbKgmh_AO5NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login to Huggingface hub\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= False #@param {'type':'boolean'}\n",
        "\n",
        "#@markdown Prepare your Huggingface token\n",
        "\n",
        "saved_token= \"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\" #@param {'type': 'string'}\n",
        "\n",
        "if opt_out == False:\n",
        "  from huggingface_hub import notebook_login\n",
        "  notebook_login()\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "id": "Da7awoqAPJ3a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Commit trained model to Huggingface"
      ],
      "metadata": {
        "id": "jypUkLWc48R_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instruction:\n",
        "0. Create huggingface repository for model\n",
        "1. Clone your model to this colab session\n",
        "2. Move these necessary file to your repository to save your trained model to huggingface\n",
        "\n",
        ">in `content/kohya-trainer/fine-tuned`\n",
        "- File `epoch-nnnnn.ckpt` and/or\n",
        "- File `last.ckpt`, \n",
        "\n",
        "4. Commit your model to huggingface"
      ],
      "metadata": {
        "id": "MpzHuB6k-_L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Model\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  model_url = \"https://huggingface.co/Linaqruf/hitokomoru-tag\" #@param {'type': 'string'}\n",
        "  !git clone {model_url}\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "id": "182Law9oUiYN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Commit to Huggingface\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  #@markdown Go to your model path\n",
        "  model_path= \"hitokomoru-tag\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown Your path look like /content/**model_path**\n",
        "  #@markdown ___\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "\n",
        "  email= \"your-email\" #@param {'type': 'string'}\n",
        "  name= \"your-name\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m= \"Push: wd14tagger (backup)- colab purpose\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd \"/content/{model_path}\"\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))\n"
      ],
      "metadata": {
        "id": "87wG7QIZbtZE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Commit datasets to huggingface"
      ],
      "metadata": {
        "id": "olP2yaK3OKcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instruction:\n",
        "0. Create huggingface repository for datasets\n",
        "1. Clone your datasets to this colab session\n",
        "2. Move these necessary file to your repository so that you can do resume training next time without rebuild your dataset with this notebook\n",
        "\n",
        ">in `content/kohya-trainer`\n",
        "- Folder `train_data`\n",
        "- File `meta_cap_dd.json`\n",
        "- File `meta_lat.json`\n",
        "\n",
        ">in `content/kohya-trainer/fine-tuned`\n",
        "- Folder `last-state`\n",
        "\n",
        "4. Commit your datasets to huggingface"
      ],
      "metadata": {
        "id": "NtjvmA5V9MR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Datasets\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "\n",
        "if opt_out == False:\n",
        "  !pip install huggingface_hub\n",
        "\n",
        "  %cd /content\n",
        "\n",
        "  datasets_url = \"https://huggingface.co/datasets/Linaqruf/hitokomoru-tag\" #@param {'type': 'string'}\n",
        "  !git clone {datasets_url}\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "id": "QhL6UgqDOURK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Commit to Huggingface\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  #@markdown Go to your datasets path\n",
        "  dataset_path= \"hitokomoru-tag\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown Your path look like /content/**dataset_path**\n",
        "  #@markdown ___\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "\n",
        "  email= \"your-email\" #@param {'type': 'string'}\n",
        "  name= \"your-name\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m= \"Push: hitokomoru-tag\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd \"/content/{dataset_path}\"\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))\n"
      ],
      "metadata": {
        "id": "abHLg4I0Os5T",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}